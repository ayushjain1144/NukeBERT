{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_pretrained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushjain1144/semantic-segmentation-IGCAR/blob/master/bert_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVL9-9BKSzSF",
        "colab_type": "code",
        "outputId": "c87601d8-baa9-4c3e-a194-716090b89895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpScP8RAWvyU",
        "colab_type": "code",
        "outputId": "82d1da7c-cc11-43a3-91be-97a90b468cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/igcar_ps/ /mydrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mexRfQy7Wxvl",
        "colab_type": "code",
        "outputId": "ea768d87-e66e-40db-e0ad-b37a7e2746b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 329, done.\u001b[K\n",
            "remote: Total 329 (delta 0), reused 0 (delta 0), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (329/329), 238.99 KiB | 3.41 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ongTGudaW8jY",
        "colab_type": "code",
        "outputId": "392f9141-fbd9-44d3-fbd6-3f9ebd37e42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s : \\\n",
        "    %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    log.info(\"Using TPU runtime\")\n",
        "    USE_TPU = True\n",
        "    TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "    with tf.Session(TPU_ADDRESS) as session:\n",
        "        log.info('TPU address is ' + TPU_ADDRESS)\n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "          auth_info = json.load(f)\n",
        "        \n",
        "        tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "        \n",
        "       \n",
        "else:\n",
        "    log.warning('Not connected to TPU runtime')\n",
        "    USE_TPU = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0628 07:56:49.114778 140479545915264 deprecation_wrapper.py:119] From /content/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0628 07:57:13.865776 140479545915264 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "2019-06-28 07:57:15,062 :     Using TPU runtime\n",
            "I0628 07:57:15.062064 140479545915264 interactiveshell.py:2882] Using TPU runtime\n",
            "2019-06-28 07:57:15,071 :     TPU address is grpc://10.114.47.2:8470\n",
            "I0628 07:57:15.071345 140479545915264 interactiveshell.py:2882] TPU address is grpc://10.114.47.2:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7FefAp_6cKl",
        "colab_type": "code",
        "outputId": "4d72c6f5-444c-4b01-fded-fd3614d1b590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%cd /content/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json  bert\tgdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKMNUdjR0dqQ",
        "colab_type": "code",
        "outputId": "a0829ac5-12d6-4f83-e9a2-58072de27202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# vocabulary formation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "MODEL_PREFIX = \"tokenizer\"\n",
        "VOC_SIZE = 32000\n",
        "NUM_PLACEHOLDERS = 256\n",
        "SUBSAMPLE_SIZE = 12800000\n",
        "\n",
        "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
        "              '--vocab_size={} --input_sentence_size={} '\n",
        "              '--shuffle_input_sentence=true '\n",
        "              '--bos_id=-1 --eos_id=-1').format(\n",
        "              '1.txt', MODEL_PREFIX,\n",
        "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n",
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nMODEL_PREFIX = \"tokenizer\"\\nVOC_SIZE = 32000\\nNUM_PLACEHOLDERS = 256\\nSUBSAMPLE_SIZE = 12800000\\n\\nSPM_COMMAND = (\\'--input={} --model_prefix={} \\'\\n              \\'--vocab_size={} --input_sentence_size={} \\'\\n              \\'--shuffle_input_sentence=true \\'\\n              \\'--bos_id=-1 --eos_id=-1\\').format(\\n              \\'1.txt\\', MODEL_PREFIX,\\n               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\\nspm.SentencePieceTrainer.Train(SPM_COMMAND)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8MEcIi47rGc",
        "colab_type": "code",
        "outputId": "de44999a-4cd0-468f-e1e5-2752432ae465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.txt  adc.json  bert  gdrive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-bQpCpY23ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!head -n 10 tokenizer.vocab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5mumMCB3HH8",
        "colab_type": "code",
        "outputId": "66d382ef-2126-44df-d0ec-3f8bc5373f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  \n",
        "  with open(filepath, encoding='utf-8') as foo:\n",
        "    for line in foo:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "      \n",
        "    voc = voc[1:]\n",
        "    return voc\n",
        "  \n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef read_sentencepiece_vocab(filepath):\\n  voc = []\\n  \\n  with open(filepath, encoding=\\'utf-8\\') as foo:\\n    for line in foo:\\n      voc.append(line.split(\"\\t\")[0])\\n      \\n    voc = voc[1:]\\n    return voc\\n  \\nsnt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\\nprint(\"Learnt vocab size: {}\".format(len(snt_vocab)))\\nprint(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B_E5tRo9CyD",
        "colab_type": "code",
        "outputId": "46d79815-e573-4762-823f-0939c4933f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "def parse_sentencepiece_token(token):\n",
        "  if token.startswith(\"▁\"):\n",
        "    return token[1:]\n",
        "  else:\n",
        "    return \"##\" + token\n",
        "\"\"\"    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef parse_sentencepiece_token(token):\\n  if token.startswith(\"▁\"):\\n    return token[1:]\\n  else:\\n    return \"##\" + token\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW9QoBXg9UNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXp_Xh4l9ebB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ctrl_symbols = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "#bert_vocab = ctrl_symbols + bert_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4YNyvUz99Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
        "#print(len(bert_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMMttcfM-OWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('trained_vocab.txt', \"w\") as foo:\n",
        "#  foo.write(\"\\n\".join([word for word in bert_vocab]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QH_3A5xZ-md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from bert import modeling, optimization, tokenization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuMf4ygEcyLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert.run_pretraining\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAu7IdzPc3EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "MASKED_LM_PROB = 0.15\n",
        "MAX_PREDICTIONS = 20\n",
        "DO_LOWER_CASE = True\n",
        "PROCESSES = 2\n",
        "PRETRAINING_DIR = \"pretraining_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZEwEGutfq-I",
        "colab_type": "code",
        "outputId": "d75594ed-df42-4fa8-8e91-0eff869dbcf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!wc -w 1.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "682357 1.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj1GYeeJfun6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d '1.txt' ./shards/shard_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_4xxGjgfwaJ",
        "colab_type": "code",
        "outputId": "ee48c8d9-555b-4b6b-f6da-8a019a83a615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls ./shards/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszGK0VCKCqk",
        "colab_type": "code",
        "outputId": "a6309762-e04e-4148-ca1e-a178ee3af80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = '/mydrive/bert_uncased/' + BERT_MODEL\n",
        "print('****** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR)) \n",
        "#!ls BERT_PRETRAINED_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****** BERT pretrained directory: /mydrive/bert_uncased/uncased_L-12_H-768_A-12 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWyRoAuZL9X7",
        "colab_type": "code",
        "outputId": "45093551-f35c-4726-f4c2-0251eb76f4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "BERT_CONFIG = BERT_PRETRAINED_DIR + '/bert_config.json'\n",
        "CHKPT_DIR = BERT_PRETRAINED_DIR + '/bert_model.ckpt.*'\n",
        "VOCAB_FILE = BERT_PRETRAINED_DIR + '/vocab.txt'\n",
        "INIT_CHECKPOINT = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "!ls $CHKPT_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7A2a1Z2fyzx",
        "colab_type": "code",
        "outputId": "a9438446-2735-480d-8c3e-87792b45d378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "            \"python3 bert/create_pretraining_data.py \"\n",
        "            \"--input_file=./shards/{} \"\n",
        "            \"--output_file={}/{}.tfrecord \"\n",
        "            \"--vocab_file={} \"\n",
        "            \"--do_lower_case={} \"\n",
        "            \"--max_predictions_per_seq={} \"\n",
        "            \"--max_seq_length={} \"\n",
        "            \"--masked_lm_prob={} \"\n",
        "            \"--random_seed=108 \"\n",
        "            \"--dupe_factors=5 \")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}',\n",
        "                            PRETRAINING_DIR, '{}',\n",
        "                            VOCAB_FILE,\n",
        "                            DO_LOWER_CASE,\n",
        "                            MAX_PREDICTIONS, MAX_SEQ_LENGTH,\n",
        "                            MASKED_LM_PROB)\n",
        "\n",
        "print(XARGS_CMD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls ./shards/ | xargs -n 1 -P 2 -I{} python3 bert/create_pretraining_data.py --input_file=./shards/{} --output_file=pretraining_data/{}.tfrecord --vocab_file=/mydrive/bert_uncased/uncased_L-12_H-768_A-12/vocab.txt --do_lower_case=True --max_predictions_per_seq=20 --max_seq_length=128 --masked_lm_prob=0.15 --random_seed=108 --dupe_factors=5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZMJnUnTRc1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile.MkDir(PRETRAINING_DIR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89-dOqD0RoN7",
        "colab_type": "code",
        "outputId": "befa7966-a420-490d-a509-d0554c4cb764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!$XARGS_CMD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0628 04:50:07.696030 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0628 04:50:07.696855 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0628 04:50:07.697026 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0628 04:50:07.697160 140126984816512 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0628 04:50:07.817212 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0628 04:50:07.818064 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0628 04:50:07.818217 140126984816512 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "I0628 04:50:07.818296 140126984816512 create_pretraining_data.py:448]   ./shards/shard_0000\n",
            "I0628 04:51:33.902076 140126984816512 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "I0628 04:51:33.902353 140126984816512 create_pretraining_data.py:459]   pretraining_data/shard_0000.tfrecord\n",
            "W0628 04:51:33.902568 140126984816512 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0628 04:51:33.924923 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.925239 140126984816512 create_pretraining_data.py:151] tokens: [CLS] been [MASK] comparing with the ra ##bid code [MASK] running problems known anal ##yt ic ##al solution the original ra ##bid algorithms were [MASK] [MASK] see foot [MASK] previous page olson ra [MASK] integral trans ##par ##tt ##he ##ory code for ne ##ut ##ror [MASK] down slab cells an ##l apr broad ##group ##de ##pen ##dent [MASK] ##fine group width specified [MASK] [MASK] underway using backward new area develop acceptable variable let ##har ##gy width algorithm such capability important [MASK] mini ##mi ##zing [MASK] time for het [MASK] ##gen ##eous calculations for which the spatial collision matrix must obtained [MASK] hyper ##fine group un ##res ##olved res resolved res [MASK] ##ulated elastic matrices [SEP] wa ##d feedback power and feedback react ##ivity start run mw ##t [SEP]\n",
            "I0628 04:51:33.925396 140126984816512 create_pretraining_data.py:161] input_ids: 101 2042 103 13599 2007 1996 10958 17062 3642 103 2770 3471 2124 20302 22123 24582 2389 5576 1996 2434 10958 17062 13792 2020 103 103 2156 3329 103 3025 3931 21583 10958 103 9897 9099 19362 4779 5369 10253 3642 2005 11265 4904 29165 103 2091 17584 4442 2019 2140 19804 5041 17058 3207 11837 16454 103 23460 2177 9381 9675 103 103 14128 2478 8848 2047 2181 4503 11701 8023 2292 8167 6292 9381 9896 2107 10673 2590 103 7163 4328 6774 103 2051 2005 21770 103 6914 14769 16268 2005 2029 1996 13589 12365 8185 2442 4663 103 23760 23460 2177 4895 6072 16116 24501 10395 24501 103 8898 21274 21520 102 11333 2094 12247 2373 1998 12247 10509 7730 2707 2448 12464 2102 102\n",
            "I0628 04:51:33.925535 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.925662 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.925753 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 2 3 9 24 25 28 33 37 45 57 62 63 66 67 80 84 88 100 110 0\n",
            "I0628 04:51:33.925847 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 8885 13599 1998 2179 19528 22074 17062 4779 18068 23760 2913 2024 1996 2047 7634 7781 10624 2169 21628 0\n",
            "I0628 04:51:33.925969 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.926044 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:33.926585 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.926745 140126984816512 create_pretraining_data.py:151] tokens: [CLS] transient [MASK] melt [MASK] facility such farm ##ea some risk excess that normally encountered [MASK] must taken order acquire [MASK] data taking [MASK] precautions this risk can minimize [MASK] tentative set safety criteria are discussed below [SEP] was introduce all its react ##ivity into the reactor system less time than the time constant the driver fuel metal which approximately ms ##ec [MASK] technique dropping the stainless steel rod less [MASK] than the driver fuel can respond [MASK] initial power [MASK] was used for the first time [MASK] fig [MASK] the dynamic simulation this run retreat deal noise indicated abe the experimental data because the low rod worth however the model [MASK] ##s the clinton time response the experimental data and very [MASK] agreement with the magnitude [SEP]\n",
            "I0628 04:51:33.926880 140126984816512 create_pretraining_data.py:161] input_ids: 101 25354 103 14899 103 4322 2107 3888 5243 2070 3891 9987 2008 5373 8567 103 2442 2579 2344 9878 103 2951 2635 103 29361 2023 3891 2064 18478 103 19943 2275 3808 9181 2024 6936 2917 102 2001 8970 2035 2049 10509 7730 2046 1996 13308 2291 2625 2051 2084 1996 2051 5377 1996 4062 4762 3384 2029 3155 5796 8586 103 6028 7510 1996 18676 3886 8473 2625 103 2084 1996 4062 4762 2064 6869 103 3988 2373 103 2001 2109 2005 1996 2034 2051 103 20965 103 1996 8790 12504 2023 2448 7822 3066 5005 5393 14863 1996 6388 2951 2138 1996 2659 8473 4276 2174 1996 2944 103 2015 1996 7207 2051 3433 1996 6388 2951 1998 2200 103 3820 2007 1996 10194 102\n",
            "I0628 04:51:33.927027 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.927150 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.927231 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 2 4 15 20 23 29 53 55 62 70 71 77 80 87 89 95 111 114 122 0\n",
            "I0628 04:51:33.927313 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 3785 7698 13308 6179 5372 2094 5377 4062 1996 2051 2084 1996 4530 2448 3065 2307 16014 2236 2204 0\n",
            "I0628 04:51:33.927401 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.927474 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:33.927965 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.928114 140126984816512 create_pretraining_data.py:151] tokens: [CLS] the detector operated with this system until may when [MASK] ce ##ze ##ctor [MASK] [MASK] ##onne ##cted the [MASK] test instruments technical [MASK] reporting the test results [MASK] wide range system test being prepared [SEP] the experimental test instrument system from may until november when the [MASK] temperature was increased after reactor [MASK] the results were reported technical note an ##lc ##t the test temperature was increased november and was maintained until january when the test [MASK] was increased except for [MASK] temperature cycle december and when the test temperature was decreased for th [MASK] [MASK] maintenance the heat ##er assembly [MASK] test results covering the test [MASK] from november [MASK] were reported technical note an ##lc ##t test conditions the detector [MASK] volume center [MASK] [SEP]\n",
            "I0628 04:51:33.928240 140126984816512 create_pretraining_data.py:161] input_ids: 101 1996 19034 3498 2007 2023 2291 2127 2089 2043 103 8292 4371 16761 103 103 18256 10985 1996 103 3231 5693 4087 103 7316 1996 3231 3463 103 2898 2846 2291 3231 2108 4810 102 1996 6388 3231 6602 2291 2013 2089 2127 2281 2043 1996 103 4860 2001 3445 2044 13308 103 1996 3463 2020 2988 4087 3602 2019 15472 2102 1996 3231 4860 2001 3445 2281 1998 2001 5224 2127 2254 2043 1996 3231 103 2001 3445 3272 2005 103 4860 5402 2285 1998 2043 1996 3231 4860 2001 10548 2005 16215 103 103 6032 1996 3684 2121 3320 103 3231 3463 5266 1996 3231 103 2013 2281 103 2020 2988 4087 3602 2019 15472 2102 3231 3785 1996 19034 103 3872 2415 103 102\n",
            "I0628 04:51:33.928355 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.928472 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.928554 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 10 14 15 16 19 23 28 47 53 77 82 92 95 96 102 108 111 123 126 0\n",
            "I0628 04:51:33.928636 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 1996 2001 28667 18256 6388 3602 1996 3231 2448 4860 3178 10548 5714 3468 1996 4860 2254 7591 4179 0\n",
            "I0628 04:51:33.928722 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.928791 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:33.929277 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.929393 140126984816512 create_pretraining_data.py:151] tokens: [CLS] power and feedback react ##ivity start run mw ##t feedback dollars [SEP] roy og ##l stan shawn ##ny ##tee su ##sy moon ##ie ee ##s [MASK] [MASK] ##r [MASK] see [SEP]\n",
            "I0628 04:51:33.929517 140126984816512 create_pretraining_data.py:161] input_ids: 101 2373 1998 12247 10509 7730 2707 2448 12464 2102 12247 6363 102 6060 13958 2140 9761 13218 4890 17389 10514 6508 4231 2666 25212 2015 103 103 2099 103 2156 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.929638 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.929759 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.929839 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 6 17 26 27 29 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.930116 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 2707 2891 5869 16523 2287 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.930217 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0628 04:51:33.930291 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:33.930819 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.930999 140126984816512 create_pretraining_data.py:151] tokens: [CLS] introduction kinetic ##s studies experimental [MASK] ##er reactor describes the [MASK] ##drop method and the data ##red ##uc [MASK] methods used appendix lists [MASK] per ##tine [MASK] constant ##s used for neutron generation time and der ##ne ##ut ##ron fraction ##s and gives the number inc ##ore [MASK] sub ##asse [MASK] ##lies [MASK] experimental sub ##asse ##mb ##lies each run during which rod drops were made appendix contains the feedback [MASK] ##ct ##ivity curves for [MASK] ten ##erin ##tee ##e nes [MASK] came cane ##ees ca [MASK] [SEP] the reactor and [MASK] equipment containing radioactive materials except the shipping facility [MASK] housed within cylindrical [MASK] tank that approximately feet diameter and feet high including the hem ##is ##pher ##ical top head and eli [MASK] [MASK] bottom [SEP]\n",
            "I0628 04:51:33.931134 140126984816512 create_pretraining_data.py:161] input_ids: 101 4955 20504 2015 2913 6388 103 2121 13308 5577 1996 103 25711 4118 1998 1996 2951 5596 14194 103 4725 2109 22524 7201 103 2566 10196 103 5377 2015 2109 2005 20393 4245 2051 1998 4315 2638 4904 4948 12884 2015 1998 3957 1996 2193 4297 5686 103 4942 27241 103 11983 103 6388 4942 27241 14905 11983 2169 2448 2076 2029 8473 9010 2020 2081 22524 3397 1996 12247 103 6593 7730 10543 2005 103 2702 23282 17389 2063 24524 103 2234 11942 10285 6187 103 102 1996 13308 1998 103 3941 4820 17669 4475 3272 1996 7829 4322 103 7431 2306 18797 103 4951 2008 3155 2519 6705 1998 2519 2152 2164 1996 19610 2483 27921 7476 2327 2132 1998 12005 103 103 3953 102\n",
            "I0628 04:51:33.931258 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.931380 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.931464 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 6 11 19 24 27 36 48 51 53 56 71 76 82 87 92 101 105 124 125 0\n",
            "I0628 04:51:33.931546 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 8843 8473 3508 1996 3372 8394 4762 14905 1998 27241 16416 3216 2063 4402 2035 2024 3886 20746 2389 0\n",
            "I0628 04:51:33.931632 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.931702 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:33.932195 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.932347 140126984816512 create_pretraining_data.py:151] tokens: [CLS] the maximum ##mic cool ##ant temperature within the experiment area cooled [MASK] the [MASK] sodium temperature [MASK] the sodium exits the primary [MASK] bulk sodium [MASK] the experiments planned for inc ##ot table experiments [MASK] for inc ##ot sensor test ir [MASK] ##iation model test equipment material reactor [MASK] y [MASK] performance and [MASK] eddy ##cu ##rre ##nt flow sensors [SEP] flow sensors with voltage and temperature [MASK] ##out evaluation bo ##ron car ##bid ##e and euro ##pia absorb ##er materials various temperatures and flux [MASK] twenty [MASK] ##s with holy ar ##d temperature read ##out performance and reliability [MASK] ##powered core neutron flux [MASK] performance gasp ##ower ##ed inc ##ore neutron flux sensors acoustic ##ener ##gy measurements with pie ##zo ##ele ##ctric trans ##du ##cer [SEP]\n",
            "I0628 04:51:33.932474 140126984816512 create_pretraining_data.py:161] input_ids: 101 1996 4555 7712 4658 4630 4860 2306 1996 7551 2181 12981 103 1996 103 13365 4860 103 1996 13365 16639 1996 3078 103 9625 13365 103 1996 7885 3740 2005 4297 4140 2795 7885 103 2005 4297 4140 13617 3231 20868 103 18963 2944 3231 3941 3430 13308 103 1061 103 2836 1998 103 16645 10841 14343 3372 4834 13907 102 4834 13907 2007 10004 1998 4860 103 5833 9312 8945 4948 2482 17062 2063 1998 9944 19312 16888 2121 4475 2536 7715 1998 19251 103 3174 103 2015 2007 4151 12098 2094 4860 3191 5833 2836 1998 15258 103 27267 4563 20393 19251 103 2836 12008 25114 2098 4297 5686 20393 19251 13907 6490 24454 6292 11702 2007 11345 6844 12260 22601 9099 8566 17119 102\n",
            "I0628 04:51:33.932589 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.932706 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.932784 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 3 12 14 17 23 26 35 42 46 49 50 51 54 68 86 88 91 100 105 0\n",
            "I0628 04:51:33.932864 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 13365 2306 9625 2043 4951 7201 3740 12173 3941 3216 1061 7677 15258 3191 3798 18269 3778 2969 13907 0\n",
            "I0628 04:51:33.932974 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.933047 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:33.933514 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.933640 140126984816512 create_pretraining_data.py:151] tokens: [CLS] but many the available concepts for doing this have already been rather carefully examined and was concluded that they were either too difficult costly incorporate the design that they would result unacceptable degradation the neutron [MASK] tabitha system [SEP] he ##ae [MASK] ##e he [MASK] france ##yles ##r [MASK] ##is fia ##vre bc ##ock any epa ##rt ##ment z [MASK] date fran ##as aw ##ary ##ers job [SEP]\n",
            "I0628 04:51:33.933762 140126984816512 create_pretraining_data.py:161] input_ids: 101 2021 2116 1996 2800 8474 2005 2725 2023 2031 2525 2042 2738 5362 8920 1998 2001 5531 2008 2027 2020 2593 2205 3697 17047 13265 1996 2640 2008 2027 2052 2765 21873 16627 1996 20393 103 21581 2291 102 2002 6679 103 2063 2002 103 2605 26274 2099 103 2483 19807 12229 4647 7432 2151 19044 5339 3672 1062 103 3058 23151 3022 22091 5649 2545 3105 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.994262 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.994570 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.994699 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 5 36 37 42 45 47 49 52 59 60 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.994802 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 8474 4610 1996 2019 11431 9617 3726 12229 1062 2378 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:33.994956 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0628 04:51:33.995067 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:33.995874 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.996142 140126984816512 create_pretraining_data.py:151] tokens: [CLS] ##l interaction analysis elements [MASK] ##cture ##s date jun ##cture [MASK] per ra ##dian bait inch lbs shear force per ra ##dian lbs the above values may [MASK] ##v u ##bt ##ain [MASK] ci ##rc inches [MASK] [MASK] mean radius [MASK] ##s mod ##ulus psi motions [MASK] thin element total radial displacement inches total [MASK] displacement _ _ _ _ ra ##dian ##s motions for thick element [MASK] radial ol ##sp ##lace ##ment inches total angular sp ##lace ##ment ra ##dian ##s combined pressure membrane [MASK] interaction stresses for the thin element tn ##st ##de surface stress [SEP] tension mer ##idi ##onal [MASK] [MASK] sc ##f [MASK] without [MASK] ##f ps ##t ee ##e mer ##idi ##onal stress with sc ##f psi ci ##rc ##um ##fer [SEP]\n",
            "I0628 04:51:33.996351 140126984816512 create_pretraining_data.py:161] input_ids: 101 2140 8290 4106 3787 103 14890 2015 3058 12022 14890 103 2566 10958 11692 17395 4960 20702 18330 2486 2566 10958 11692 20702 1996 2682 5300 2089 103 2615 1057 19279 8113 103 25022 11890 5282 103 103 2812 12177 103 2015 16913 11627 17816 15323 103 4857 5783 2561 15255 13508 5282 2561 103 13508 1035 1035 1035 1035 10958 11692 2015 15323 2005 4317 5783 103 15255 19330 13102 19217 3672 5282 2561 16108 11867 19217 3672 10958 11692 2015 4117 3778 10804 103 8290 23253 2005 1996 4857 5783 28286 3367 3207 3302 6911 102 6980 21442 28173 16026 103 103 8040 2546 103 2302 103 2546 8827 2102 25212 2063 21442 28173 16026 6911 2007 8040 2546 17816 25022 11890 2819 7512 102\n",
            "I0628 04:51:33.996536 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.996709 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.996839 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 5 11 19 20 28 33 37 38 41 42 47 55 68 82 86 103 104 107 109 0\n",
            "I0628 04:51:33.996990 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 12022 2617 2486 2566 4487 2566 12022 14890 2402 2015 2005 16108 2561 2015 1998 6911 2302 6911 8040 0\n",
            "I0628 04:51:33.997117 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.997223 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:33.997999 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.998182 140126984816512 create_pretraining_data.py:151] tokens: [CLS] through totally ##im ##mers ##ed cylinder [MASK] the [MASK] ##e for some [MASK] [MASK] [MASK] primary sodium components are given [MASK] f ##zo ##m these numerical values might in ##fer ##red that for the [MASK] sodium components e ##bri ##t sounds [MASK] frequencies are transmitted [MASK] through the [MASK] ##im ##mers [MASK] walls the e ##bri ##i primary cool ##ant system acoustic ##ally [MASK] compared the simple cylinders assumed this analysis and the conclusion uniform audio transmission has restricted accordingly [MASK] geo ##met ##ries the [MASK] exam ##pies e ##bri ##i [MASK] details indicate that many cases sound transmission will [MASK] ##ten [SEP] the core e [MASK] [MASK] approximately sodium and metal pl ##e ceramics volume this will [MASK] mu ##ffle ##rl ##ike at ##ten ##uation [SEP]\n",
            "I0628 04:51:33.998325 140126984816512 create_pretraining_data.py:161] input_ids: 101 2083 6135 5714 16862 2098 7956 103 1996 103 2063 2005 2070 103 103 103 3078 13365 6177 2024 2445 103 1042 6844 2213 2122 15973 5300 2453 1999 7512 5596 2008 2005 1996 103 13365 6177 1041 23736 2102 4165 103 13139 2024 11860 103 2083 1996 103 5714 16862 103 3681 1996 1041 23736 2072 3078 4658 4630 2291 6490 3973 103 4102 1996 3722 18729 5071 2023 4106 1998 1996 7091 6375 5746 6726 2038 7775 11914 103 20248 11368 5134 1996 103 11360 13046 1041 23736 2072 103 4751 5769 2008 2116 3572 2614 6726 2097 103 6528 102 1996 4563 1041 103 103 3155 13365 1998 3384 20228 2063 17314 3872 2023 2097 103 14163 18142 12190 17339 2012 6528 14505 102\n",
            "I0628 04:51:33.998453 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.998579 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:33.998665 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 7 9 13 14 15 21 35 42 46 49 52 64 81 86 92 101 107 108 119 0\n",
            "I0628 04:51:33.998747 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 6726 2765 1041 23736 2072 2795 2312 5746 12192 6381 2098 3375 21304 2206 2810 2012 23736 2072 2599 0\n",
            "I0628 04:51:33.998835 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:33.998929 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:33.999516 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:33.999675 140126984816512 create_pretraining_data.py:151] tokens: [CLS] during e ##bri ##i shut ##down broadband sound level [MASK] against primary [MASK] [MASK] rate [MASK] removed filtering out low frequencies the wave turkey with its comb ##like [MASK] [MASK] above [MASK] [MASK] out the lower frequencies the hold down rigid ##ly attached https reactor structure vi ##brates over wide frequency range [MASK] therefore ex ##hi ##bi high ambient noise background relative full [SEP] axial ##er [MASK] ##utz ##one lei ##st ##ung der radial ##en br [MASK] ##one geo [MASK] ##rie he ##hen spa ##lt ##zen ##e un ##ter ##e axial ##e br ##utz ##one obe [MASK] ex ##ial ##e br [MASK] ##one gas ##sp ##ei ##cher a ##qui ##valent [MASK] aus ##end ##ur ##ch ##mes ##ser spa ##lt ##zone [MASK] ##e br ##utz ##one vol [SEP]\n",
            "I0628 04:51:33.999806 140126984816512 create_pretraining_data.py:161] input_ids: 101 2076 1041 23736 2072 3844 7698 19595 2614 2504 103 2114 3078 103 103 3446 103 3718 22910 2041 2659 13139 1996 4400 4977 2007 2049 22863 10359 103 103 2682 103 103 2041 1996 2896 13139 1996 2907 2091 11841 2135 4987 16770 13308 3252 6819 25258 2058 2898 6075 2846 103 3568 4654 4048 5638 2152 17093 5005 4281 5816 2440 102 26819 2121 103 20267 5643 26947 3367 5575 4315 15255 2368 7987 103 5643 20248 103 7373 2002 10222 12403 7096 10431 2063 4895 3334 2063 26819 2063 7987 20267 5643 15578 103 4654 4818 2063 7987 103 5643 3806 13102 7416 7474 1037 15549 24879 103 17151 10497 3126 2818 7834 8043 12403 7096 15975 103 2063 7987 20267 5643 5285 102\n",
            "I0628 04:51:33.999944 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.000069 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.000150 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 5 10 13 14 16 24 29 30 32 33 44 53 67 77 80 97 102 111 121 0\n",
            "I0628 04:51:34.000233 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 3844 27347 13365 4834 2064 28582 6075 3433 26096 17736 1996 1998 7987 20267 11368 2890 20267 2121 15255 0\n",
            "I0628 04:51:34.000320 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.000391 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:51:34.000875 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.001049 140126984816512 create_pretraining_data.py:151] tokens: [CLS] apex reactors general ti ##d fast ##per ##io ##d [MASK] safety fuse tests stil ##well [SEP] sub reel june [MASK] states air force contract united [MASK] [MASK] [MASK] commission contract general electric atomic products division aircraft nuclear [MASK] department cincinnati ohio published technical publications sub ##section may ac ##k ##now ##led ##gm ##ent the completion this fuse program [MASK] made possible the assistance and cooperation an ##pd [MASK] personnel even ##dale [MASK] and the idaho test station excellent cooperation running the reactor excursion ##s was given personnel the sp ##ert [MASK] national reactor ##runner station [MASK] the direction the [MASK] interest [MASK] math ##eson metal and controls corporation at ##tle ##boro massachusetts led the production [MASK] the ##rm ##osta ##ts based results obtained during the [MASK] [SEP]\n",
            "I0628 04:51:34.001177 140126984816512 create_pretraining_data.py:161] input_ids: 101 13450 22223 2236 14841 2094 3435 4842 3695 2094 103 3808 19976 5852 25931 4381 102 4942 15934 2238 103 2163 2250 2486 3206 2142 103 103 103 3222 3206 2236 3751 9593 3688 2407 2948 4517 103 2533 7797 4058 2405 4087 5523 4942 29015 2089 9353 2243 19779 3709 21693 4765 1996 6503 2023 19976 2565 103 2081 2825 1996 5375 1998 6792 2019 17299 103 5073 2130 5634 103 1998 1996 9795 3231 2276 6581 6792 2770 1996 13308 26144 2015 2001 2445 5073 1996 11867 8743 103 2120 13308 23195 2276 103 1996 3257 1996 103 3037 103 8785 21421 3384 1998 7711 3840 2012 9286 12691 4404 2419 1996 2537 103 1996 10867 28696 3215 2241 3463 4663 2076 1996 103 102\n",
            "I0628 04:51:34.001295 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.001416 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.001500 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 10 18 20 26 27 28 38 45 59 68 72 91 94 96 100 102 104 116 126 0\n",
            "I0628 04:51:34.001583 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 13308 29015 2142 2163 9593 2943 16404 4942 2001 3330 4058 2609 5604 2104 3161 3253 21421 4517 11867 0\n",
            "I0628 04:51:34.001668 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.001739 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.002219 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.002358 140126984816512 create_pretraining_data.py:151] tokens: [CLS] however the slug model always provided stiff ##er and slower responding system than the wave model which consistent [MASK] physical [MASK] the rise time the [MASK] decreased the difference between criteria slug and the [MASK] 仁 became greater especially for [MASK] smaller press ##urized region [SEP] both models [MASK] toward the infinite ##hei ##ght 陳 the rise time the pulse decreased energy source simple model the initial verification the m ##fc ##i model the straw code [MASK] accomplished comparing calculations made rex ##co ##ht for similar [MASK] and several initial conditions [SEP]\n",
            "I0628 04:51:34.002506 140126984816512 create_pretraining_data.py:161] input_ids: 101 2174 1996 23667 2944 2467 3024 10551 2121 1998 12430 14120 2291 2084 1996 4400 2944 2029 8335 103 3558 103 1996 4125 2051 1996 103 10548 1996 4489 2090 9181 23667 1998 1996 103 1758 2150 3618 2926 2005 103 3760 2811 28405 2555 102 2119 4275 103 2646 1996 10709 26036 13900 1972 1996 4125 2051 1996 8187 10548 2943 3120 3722 2944 1996 3988 22616 1996 1049 11329 2072 2944 1996 13137 3642 103 8885 13599 16268 2081 10151 3597 11039 2005 2714 103 1998 2195 3988 3785 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.002650 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.002784 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.002866 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 19 21 26 31 35 36 41 49 55 59 67 77 80 87 0 0 0 0 0 0\n",
            "I0628 04:51:34.002978 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 2007 26406 8187 1996 4400 4275 1996 11121 5391 1996 3988 2001 16268 9563 0 0 0 0 0 0\n",
            "I0628 04:51:34.003067 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0628 04:51:34.003140 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.003614 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.003732 140126984816512 create_pretraining_data.py:151] tokens: [CLS] the steps are sufficiently small that small errors resulted from linear inter ##pol ##ation and [MASK] these errors corrections [MASK] applied [SEP] the adi ##aba ##tic expansion calculations were carried out reduced coordinates permit [MASK] general [MASK] the results within the limits uncertainty [MASK] with critical [MASK] ##press ##ibility [MASK] [SEP]\n",
            "I0628 04:51:34.003854 140126984816512 create_pretraining_data.py:161] input_ids: 101 1996 4084 2024 12949 2235 2008 2235 10697 4504 2013 7399 6970 18155 3370 1998 103 2122 10697 20983 103 4162 102 1996 27133 19736 4588 4935 16268 2020 3344 2041 4359 12093 9146 103 2236 103 1996 3463 2306 1996 6537 12503 103 2007 4187 103 20110 13464 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.003993 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.004113 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.004194 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 10 16 20 35 37 44 47 50 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.004276 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 2013 2005 2020 2200 4646 3378 4012 3643 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.004359 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0628 04:51:34.004430 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.004961 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.005115 140126984816512 create_pretraining_data.py:151] tokens: [CLS] ##ke pole face cross section showed breakaway force which was decreased ne ##gli ##gible value when the [MASK] [MASK] the yo [MASK] was heated [MASK] vicinity thus not necessary drive the [MASK] yo ##ke above the cu ##rie temperature sy ##ro ##h o [MASK] ##i ##w jun ##iv ##yad ##ws ##l j ##wil h ##lon ##sy ##ls yo ##ke height height yo ##ke [SEP] ##iv ##yi ##dm ##wil jun [MASK] ##vy ##sd ##wl no ##ilo ##nn ##s [MASK] ##tiv ##wy ##d on ##y [MASK] [MASK] [MASK] ##ti ##g ##w ##vi [MASK] [MASK] [MASK] ##43 one temperature dependence curves show that rocker re ##man ##ence decreases with increasing temperature that the [MASK] level [MASK] reactor cool ##ant the magnet will retain approximately its room temperature magnet ##ization [SEP]\n",
            "I0628 04:51:34.005244 140126984816512 create_pretraining_data.py:161] input_ids: 101 3489 6536 2227 2892 2930 3662 26321 2486 2029 2001 10548 11265 25394 18507 3643 2043 1996 103 103 1996 10930 103 2001 9685 103 9884 2947 2025 4072 3298 1996 103 10930 3489 2682 1996 12731 7373 4860 25353 3217 2232 1051 103 2072 2860 12022 12848 25152 9333 2140 1046 29602 1044 7811 6508 4877 10930 3489 4578 4578 10930 3489 102 12848 10139 22117 29602 12022 103 10736 16150 13668 2053 22360 10695 2015 103 29068 18418 2094 2006 2100 103 103 103 3775 2290 2860 5737 103 103 103 23777 2028 4860 18642 10543 2265 2008 24779 2128 2386 10127 17913 2007 4852 4860 2008 1996 103 2504 103 13308 4658 4630 1996 16853 2097 9279 3155 2049 2282 4860 16853 3989 102\n",
            "I0628 04:51:34.005360 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.005480 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.005561 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 5 18 19 22 25 32 44 70 78 84 85 86 91 92 93 94 101 111 113 0\n",
            "I0628 04:51:34.005642 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 2930 8278 2391 3489 1996 2972 28765 2140 20118 2053 2100 4862 18418 2094 7173 10736 8060 4082 1996 0\n",
            "I0628 04:51:34.005728 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.005798 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.006330 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.006490 140126984816512 create_pretraining_data.py:151] tokens: [CLS] examination mount [MASK] other suitable room [MASK] setting ep ##ox ##y resin grind mounted [MASK] grit silicon car ##bid ##e paper using water lu ##bri ##can ##t until [MASK] surface obtained sample relatively this procedure [MASK] property ba ##bc ##ock wilcox and intended for internal use subject [MASK] without notice and [MASK] company cannot [MASK] liability for its complete ##ness accuracy date smooth and flat this step may omitted continue grinding [MASK] silicon [MASK] ##bid ##e paper [MASK] smooth surface clean [MASK] minutes water using [MASK] ##sonic [SEP] polish syn ##tron bowl polish ##er using micro ##n diamond [MASK] [MASK] ##sen ##e lu ##bri ##can ##t use minimum setting vi ##bra ##tor control maintain specimen travel around the bowl rpm load fairness [MASK] placed the [MASK] [SEP]\n",
            "I0628 04:51:34.098612 140126984816512 create_pretraining_data.py:161] input_ids: 101 7749 4057 103 2060 7218 2282 103 4292 4958 11636 2100 24604 23088 5614 103 24842 13773 2482 17062 2063 3259 2478 2300 11320 23736 9336 2102 2127 103 3302 4663 7099 4659 2023 7709 103 3200 8670 9818 7432 23926 1998 3832 2005 4722 2224 3395 103 2302 5060 1998 103 2194 3685 103 14000 2005 2049 3143 2791 10640 3058 5744 1998 4257 2023 3357 2089 16647 3613 16153 103 13773 103 17062 2063 3259 103 5744 3302 4550 103 2781 2300 2478 103 18585 102 3907 19962 15312 4605 3907 2121 2478 12702 2078 6323 103 103 5054 2063 11320 23736 9336 2102 2224 6263 4292 6819 10024 4263 2491 5441 11375 3604 2105 1996 4605 11575 7170 26935 103 2872 1996 103 102\n",
            "I0628 04:51:34.098971 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.099166 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.099322 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 3 7 15 29 36 48 52 55 72 74 78 79 82 86 99 100 122 123 126 0\n",
            "I0628 04:51:34.099447 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 7099 4860 7099 4257 1996 2689 1996 7868 24842 2482 6855 5744 2005 11087 1998 11087 3155 20372 4057 0\n",
            "I0628 04:51:34.099575 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.099679 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.100527 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.100768 140126984816512 create_pretraining_data.py:151] tokens: [CLS] offset han ##olin ##g me ##ch ass ##y rotating hold ##down el ##ug [SEP] tank either the gas cooling system the ventilation the reactor compartment the stainless steel thermal [MASK] and the bo ##rated graph [MASK] [MASK] together with the blanket form the [MASK] ##l shield system and at ##ten representative the ratings [MASK] ##s factor approximately totally contained within the primary [MASK] tank the primary shield system for the [MASK] reactor vessel consists [MASK] thermal shield and inches bo ##rated [MASK] ##ite materials type [MASK] steel will used throughout the [MASK] [MASK] except few components where dimensional stability prime re ##quisite the support plates hold ##down plate and control rod [MASK] tubes fall into this category and gulf type stainless ##uri the primary shield [MASK] [SEP]\n",
            "I0628 04:51:34.101002 140126984816512 create_pretraining_data.py:161] input_ids: 101 16396 7658 18861 2290 2033 2818 4632 2100 13618 2907 7698 3449 15916 102 4951 2593 1996 3806 11520 2291 1996 19536 1996 13308 15273 1996 18676 3886 9829 103 1998 1996 8945 9250 10629 103 103 2362 2007 1996 8768 2433 1996 103 2140 6099 2291 1998 2012 6528 4387 1996 8599 103 2015 5387 3155 6135 4838 2306 1996 3078 103 4951 1996 3078 6099 2291 2005 1996 103 13308 6258 3774 103 9829 6099 1998 5282 8945 9250 103 4221 4475 2828 103 3886 2097 2109 2802 1996 103 103 3272 2261 6177 2073 8789 9211 3539 2128 24871 1996 2490 7766 2907 7698 5127 1998 2491 8473 103 10868 2991 2046 2023 4696 1998 6084 2828 18676 9496 1996 3078 6099 103 102\n",
            "I0628 04:51:34.101197 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.101370 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.101504 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 30 36 37 44 51 53 54 56 63 71 75 82 86 92 93 112 119 122 126 0\n",
            "I0628 04:51:34.101625 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 6099 4221 9014 21877 20598 4563 20393 5387 6099 3356 4960 10629 18676 13308 6258 5009 2097 3886 4951 0\n",
            "I0628 04:51:34.101749 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.101856 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.102639 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.102856 140126984816512 create_pretraining_data.py:151] tokens: [CLS] li [MASK] ##tain ##en chemical reactions identical arise publication chapter vol the technology nuclear reactor safety mit press vogel fluid ##bed flu ##ori [MASK] vol ##ati ##lity processing reactor fuel materials accepted for publication chapter pro ##gr energy ser [MASK] process chemistry vol [SEP] ##ity na ##f ##nac [MASK] ##al eu [MASK] ##tic accepted for publication stein ##dler the reaction [MASK] [MASK] bro ##mine [MASK] ##ta ##fl ##uo [MASK] with [MASK] compounds the reactions with u ##oz and accepted for publication in [MASK] ko ##ppel dynamics and control batch reactor [MASK] for publication ind eng che ##m process design develop johnson the reaction magnesium metal [MASK] magnesium chloride accepted for [MASK] ph ##ys ar ##nt ##zen removal nitrogen [unused459] [MASK] ##gon with titanium ##met ##al sponge [SEP]\n",
            "I0628 04:51:34.103049 140126984816512 create_pretraining_data.py:161] input_ids: 101 5622 103 18249 2368 5072 9597 7235 13368 4772 3127 5285 1996 2974 4517 13308 3808 10210 2811 27063 8331 8270 19857 10050 103 5285 10450 18605 6364 13308 4762 4475 3970 2005 4772 3127 4013 16523 2943 14262 103 2832 6370 5285 102 3012 6583 2546 18357 103 2389 7327 103 4588 3970 2005 4772 14233 21222 1996 4668 103 103 22953 11233 103 2696 10258 19098 103 2007 103 10099 1996 9597 2007 1057 18153 1998 3970 2005 4772 1999 103 12849 27877 10949 1998 2491 14108 13308 103 2005 4772 27427 25540 18178 2213 2832 2640 4503 3779 1996 4668 24983 3384 103 24983 19057 3970 2005 103 6887 7274 12098 3372 10431 8208 14114 464 103 7446 2007 23431 11368 2389 25742 102\n",
            "I0628 04:51:34.103181 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.103305 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.103389 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 2 7 8 24 40 49 52 61 62 65 69 71 83 91 106 111 112 119 120 0\n",
            "I0628 04:51:34.103475 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 9581 3970 2005 3207 5665 19666 26557 3806 14769 7279 15637 14247 21759 3970 2007 4772 6887 2013 12098 0\n",
            "I0628 04:51:34.103562 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.103636 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.104136 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.104288 140126984816512 create_pretraining_data.py:151] tokens: [CLS] shut ##down data taken during [MASK] operation figures and indicates good [MASK] the mal ##fu [MASK] was reported detail the attached equipment [MASK] report ct ##c during reactor run about april after days full reactor power the rs ##n again developed assassinated low imp ##edance emilia ##fu ##nction the mal ##fu ##nction was successfully corrected may [MASK] the annual [MASK] shut ##down the [SEP] days full reactor [MASK] the rs ##n again [MASK] the [MASK] imp [MASK] mal ##fu ##nction the mal ##fu ##nction could only partly [MASK] july prior increasing the test temperature comparison shut ##down data taken [MASK] the correct [MASK] action figures and shut ##down data taken during previous operation [MASK] and indicates about one decade increase the signal leak ##age [MASK] the [SEP]\n",
            "I0628 04:51:34.104417 140126984816512 create_pretraining_data.py:161] input_ids: 101 3844 7698 2951 2579 2076 103 3169 4481 1998 7127 2204 103 1996 15451 11263 103 2001 2988 6987 1996 4987 3941 103 3189 14931 2278 2076 13308 2448 2055 2258 2044 2420 2440 13308 2373 1996 12667 2078 2153 2764 16370 2659 17727 29605 20417 11263 27989 1996 15451 11263 27989 2001 5147 13371 2089 103 1996 3296 103 3844 7698 1996 102 2420 2440 13308 103 1996 12667 2078 2153 103 1996 103 17727 103 15451 11263 27989 1996 15451 11263 27989 2071 2069 6576 103 2251 3188 4852 1996 3231 4860 7831 3844 7698 2951 2579 103 1996 6149 103 2895 4481 1998 3844 7698 2951 2579 2076 3025 3169 103 1998 7127 2055 2028 5476 3623 1996 4742 17271 4270 103 1996 102\n",
            "I0628 04:51:34.104536 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.104654 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.104734 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 6 12 16 23 42 46 57 60 68 69 73 75 77 88 96 100 103 114 125 0\n",
            "I0628 04:51:34.104815 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 3025 3820 27989 4945 1996 15451 2076 6032 2373 1996 2764 2659 29605 13371 3844 2044 3512 4481 2783 0\n",
            "I0628 04:51:34.104923 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.105000 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.105487 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.105633 140126984816512 create_pretraining_data.py:151] tokens: [CLS] rec ##hner [MASK] vo ##rber ##eit ##ungen zur kern ##aus [MASK] [MASK] re ##ak ##tor ##dur ##ch ##re [MASK] ##nu ##ng rec ##hen ##gen ##au ##ig [MASK] [MASK] [SEP] zur er ##ste ##ll [MASK] der [MASK] ##dim ##ens ##ional ##en aus ##leg ##ung ##sr ##ech ##nu ##ngen [MASK] den er ##ford ##er ##liche ##n date ##na ##uf ##ber ##eit ##ung [MASK] und aus ##wer ##tung ##sp ##has ##en das z ##wei ##dim ##ens ##ional ##e diffusion ##sp ##ro [MASK] ##m pd [MASK] [MASK] ko ##nt ##roll ##e ein ##iger ein ##dim [MASK] ##ional [MASK] ##won ##nen [MASK] re ##ak ##tiv ##it ##dt ##sw ##ert ##e ein ##ige times ##hari ##ng ##pro ##gram [MASK] zur br ##ut ##rate ##nu ##nd lei ##st ##ung ##san ##aly [MASK] so [SEP]\n",
            "I0628 04:51:34.105759 140126984816512 create_pretraining_data.py:161] input_ids: 101 28667 28989 103 29536 20473 20175 23239 17924 22762 20559 103 103 2128 4817 4263 24979 2818 2890 103 11231 3070 28667 10222 6914 4887 8004 103 103 102 17924 9413 13473 3363 103 4315 103 22172 6132 19301 2368 17151 23115 5575 21338 15937 11231 25997 103 7939 9413 3877 2121 27412 2078 3058 2532 16093 5677 20175 5575 103 6151 17151 13777 21847 13102 14949 2368 8695 1062 19845 22172 6132 19301 2063 19241 13102 3217 103 2213 22851 103 103 12849 3372 28402 2063 16417 17071 16417 22172 103 19301 103 19291 10224 103 2128 4817 29068 4183 11927 26760 8743 2063 16417 25538 2335 18428 3070 21572 13113 103 17924 7987 4904 11657 11231 4859 26947 3367 5575 8791 20766 103 2061 102\n",
            "I0628 04:51:34.105876 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.106020 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0628 04:51:34.106103 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 3 11 12 19 27 28 34 36 48 50 61 79 82 83 92 94 97 113 125 0\n",
            "I0628 04:51:34.106193 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 13719 23115 5575 2818 29501 2102 5575 16417 10210 9413 2015 13113 4160 17924 6132 16216 2121 4168 3366 0\n",
            "I0628 04:51:34.106278 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0628 04:51:34.106349 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0628 04:51:34.106852 140126984816512 create_pretraining_data.py:149] *** Example ***\n",
            "I0628 04:51:34.107027 140126984816512 create_pretraining_data.py:151] tokens: [CLS] the delayed [MASK] ##ut ##ron fraction ##s were re ##eva ##lu ##ated for the cores with stainless steel [MASK] ##or succeeding [MASK] which caused the change for [MASK] and table e [MASK] [MASK] delayed ##ne ##ut [MASK] parameters sec b [MASK] ##ues used before delicately site ##ted [MASK] when been multiplied en ##e career an ##ew me ##ee come ##r ee ##ns pm ##rm ##ent ee ##e i ##had ##ap ##ls ##ase ##it su ##s appendix feedback ##rea ##ct ##ivity curves the [MASK] this appendix show normal ##ized power and speak activity function time [SEP] time sec fig [MASK] and feedback react ##ivity start run mw ##t [SEP]\n",
            "I0628 04:51:34.107156 140126984816512 create_pretraining_data.py:161] input_ids: 101 1996 8394 103 4904 4948 12884 2015 2020 2128 13331 7630 4383 2005 1996 25562 2007 18676 3886 103 2953 13034 103 2029 3303 1996 2689 2005 103 1998 2795 1041 103 103 8394 2638 4904 103 11709 10819 1038 103 15808 2109 2077 28814 2609 3064 103 2043 2042 28608 4372 2063 2476 2019 7974 2033 4402 2272 2099 25212 3619 7610 10867 4765 25212 2063 1045 16102 9331 4877 11022 4183 10514 2015 22524 12247 16416 6593 7730 10543 1996 103 2023 22524 2265 3671 3550 2373 1998 3713 4023 3853 2051 102 2051 10819 20965 103 1998 12247 10509 7730 2707 2448 12464 2102 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.107275 140126984816512 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.107393 140126984816512 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0628 04:51:34.107475 140126984816512 create_pretraining_data.py:161] masked_lm_positions: 3 19 22 28 32 33 37 41 45 48 49 81 83 91 99 102 0 0 0 0\n",
            "I0628 04:51:34.107558 140126984816512 create_pretraining_data.py:161] masked_lm_ids: 2638 8339 3216 2448 23736 2072 4948 10175 2448 5300 2031 10543 10543 12247 2373 10509 0 0 0 0\n",
            "I0628 04:51:34.107643 140126984816512 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "I0628 04:51:34.107713 140126984816512 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0628 04:52:06.910187 140126984816512 create_pretraining_data.py:166] Wrote 100433 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh-umioj72xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"ayushjain1144-bucket\"\n",
        "MODEL_DIR = \"bert_model\"\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"Warning: no bucket\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAwgehFAEEbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = \"bert_model\"\n",
        "tf.gfile.MkDir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28sBjWx_Rrxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameters for BERT BASE\n",
        "\n",
        "bert_base_config = {\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"directionality\": \"bidi\",\n",
        "    \"hidden_act\": \"gelu\",\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"hidden_size\": 768,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"intermediate_size\": 3072,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"pooler_fc_size\": 768,\n",
        "    \"pooler_num_attention_heads\": 12,\n",
        "    \"pooler_num_fc_layers\": 3,\n",
        "    \"pooler_size_per_head\": 128,\n",
        "    \"pooler_type\": \"first_token_transform\",\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX5ci_dk9g9e",
        "colab_type": "code",
        "outputId": "03f35bae-ae48-4147-88f6-4be61d52493e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "\n",
        "!cp $BERT_CONFIG $MODEL_DIR/\n",
        "!cp $CHKPT_DIR $MODEL_DIR/\n",
        "!ls $MODEL_DIR/\n",
        "    \n",
        "with open(\"{}/bert_vocab.txt\".format(MODEL_DIR), \"w\") as vocab:\n",
        "    vocab_bert = open(VOCAB_FILE, 'r').read()\n",
        "    vocab.write(vocab_bert)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json\t\t     bert_model.ckpt.index  bert_vocab\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta   bert_vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbzY0cjyL27Q",
        "colab_type": "code",
        "outputId": "6f1c96e7-f938-487a-d72d-1acae892f3df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!cp -r $MODEL_DIR $PRETRAINING_DIR /mydrive/\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME\n",
        "else:\n",
        "  print(\"Not able to copy\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_model/bert_config.json [Content-Type=application/json]...\n",
            "Copying file://bert_model/bert_model.ckpt.index [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/bert_vocab.txt [Content-Type=text/plain]...\n",
            "Copying file://bert_model/bert_vocab [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0000.tfrecord [Content-Type=application/octet-stream]...\n",
            "/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \rCopying file://bert_model/bert_model.ckpt.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/bert_model.ckpt.meta [Content-Type=application/octet-stream]...\n",
            "/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r/ [0/7 files][    0.0 B/500.9 MiB]   0% Done                                    \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "|\n",
            "Operation completed over 7 objects/500.9 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgZ3QCkILhPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TO DO\n",
        "#code to transfer latest checkpoint from another directory to new directory\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_7D763pTxup",
        "colab_type": "code",
        "outputId": "f09b743e-a641-4c61-d6c0-8e92d5e77577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "TRAIN_BATCH_SIZE = 128\n",
        "MAX_PREDICTIONS =20\n",
        "MAX_SEQ_LENGTH = 128\n",
        "MASKED_LM_PROB = 0.15\n",
        "\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 1000\n",
        "SAVE_CHECKPOINTS_STEPS = 100\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "BERT_DRIVE_DIR = \"{}/{}\".format('/mydrive', MODEL_DIR)\n",
        "DATA_DRIVE_DIR = \"{}/{}\".format('/mydrive', PRETRAINING_DIR)\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  print(\"bucket name not found\")\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "PATH_TO_CHECKPOINT = os.path.join(BERT_GCS_DIR, \"bert_model.ckpt\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "\n",
        "if INIT_CHECKPOINT == None:\n",
        "    print(\"no checkpoint found, loading the default\")\n",
        "    INIT_CHECKPOINT = PATH_TO_CHECKPOINT\n",
        "\n",
        "\n",
        "\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, \"bert_vocab.txt\")\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR, '*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no checkpoint found, loading the default\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-28 04:58:30,870 :     Using checkpoint: gs://ayushjain1144-bucket/bert_model/bert_model.ckpt\n",
            "I0628 04:58:30.870596 139821928843136 interactiveshell.py:2882] Using checkpoint: gs://ayushjain1144-bucket/bert_model/bert_model.ckpt\n",
            "2019-06-28 04:58:30,873 :     Using 1 data shards\n",
            "I0628 04:58:30.873953 139821928843136 interactiveshell.py:2882] Using 1 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8CRUnlpV09M",
        "colab_type": "code",
        "outputId": "976cfb80-c88a-442e-da5f-faf86ce97650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config = bert_config,\n",
        "    init_checkpoint= INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=TRAIN_STEPS,\n",
        "    num_warmup_steps=10,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "            cluster=tpu_cluster_resolver,\n",
        "            model_dir=BERT_GCS_DIR,\n",
        "            save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "            tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "            num_shards=NUM_TPU_CORES,\n",
        "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "\n",
        "train_input_fn = input_fn_builder(\n",
        "    input_files=input_files,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "    is_training=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-28 04:58:38,160 :     Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2a829f9510>) includes params argument, but params are not passed to Estimator.\n",
            "W0628 04:58:38.160904 139821928843136 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2a829f9510>) includes params argument, but params are not passed to Estimator.\n",
            "2019-06-28 04:58:38,164 :     Using config: {'_model_dir': 'gs://ayushjain1144-bucket/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.111.60.10:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2a829fd898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.111.60.10:8470', '_evaluation_master': 'grpc://10.111.60.10:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2a829fde48>}\n",
            "I0628 04:58:38.164319 139821928843136 estimator.py:209] Using config: {'_model_dir': 'gs://ayushjain1144-bucket/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.111.60.10:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2a829fd898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.111.60.10:8470', '_evaluation_master': 'grpc://10.111.60.10:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f2a829fde48>}\n",
            "2019-06-28 04:58:38,168 :     _TPUContext: eval_on_tpu True\n",
            "I0628 04:58:38.168208 139821928843136 tpu_context.py:209] _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOdgIx2aIcCa",
        "colab_type": "code",
        "outputId": "9868cb0b-fc85-421d-d853-d7ff6172f4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "estimator.train(input_fn=train_input_fn, max_steps = TRAIN_STEPS )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-28 04:58:46,619 :     Querying Tensorflow master (grpc://10.111.60.10:8470) for TPU system metadata.\n",
            "I0628 04:58:46.619452 139821928843136 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.111.60.10:8470) for TPU system metadata.\n",
            "2019-06-28 04:58:46,643 :     Found TPU system:\n",
            "I0628 04:58:46.643442 139821928843136 tpu_system_metadata.py:148] Found TPU system:\n",
            "2019-06-28 04:58:46,645 :     *** Num TPU Cores: 8\n",
            "I0628 04:58:46.645551 139821928843136 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "2019-06-28 04:58:46,651 :     *** Num TPU Workers: 1\n",
            "I0628 04:58:46.651442 139821928843136 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "2019-06-28 04:58:46,655 :     *** Num TPU Cores Per Worker: 8\n",
            "I0628 04:58:46.655404 139821928843136 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "2019-06-28 04:58:46,658 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 986085526709126796)\n",
            "I0628 04:58:46.658172 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 986085526709126796)\n",
            "2019-06-28 04:58:46,669 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9055219791481840568)\n",
            "I0628 04:58:46.669036 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9055219791481840568)\n",
            "2019-06-28 04:58:46,672 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 477804016729294455)\n",
            "I0628 04:58:46.672863 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 477804016729294455)\n",
            "2019-06-28 04:58:46,675 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6739432155540554814)\n",
            "I0628 04:58:46.675179 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6739432155540554814)\n",
            "2019-06-28 04:58:46,677 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17939608832318429569)\n",
            "I0628 04:58:46.677802 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17939608832318429569)\n",
            "2019-06-28 04:58:46,680 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10782541880676517441)\n",
            "I0628 04:58:46.680865 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10782541880676517441)\n",
            "2019-06-28 04:58:46,687 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11758119439433591509)\n",
            "I0628 04:58:46.687263 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11758119439433591509)\n",
            "2019-06-28 04:58:46,691 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6193873827924217361)\n",
            "I0628 04:58:46.691027 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6193873827924217361)\n",
            "2019-06-28 04:58:46,694 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5885673937413125599)\n",
            "I0628 04:58:46.694411 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5885673937413125599)\n",
            "2019-06-28 04:58:46,697 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9367825329896198678)\n",
            "I0628 04:58:46.697806 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9367825329896198678)\n",
            "2019-06-28 04:58:46,701 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14242891016635184247)\n",
            "I0628 04:58:46.701179 139821928843136 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14242891016635184247)\n",
            "2019-06-28 04:58:46,762 :     Calling model_fn.\n",
            "I0628 04:58:46.762849 139821928843136 estimator.py:1145] Calling model_fn.\n",
            "2019-06-28 04:58:46,917 :     *** Features ***\n",
            "I0628 04:58:46.917818 139821928843136 run_pretraining.py:117] *** Features ***\n",
            "2019-06-28 04:58:46,920 :       name = input_ids, shape = (16, 128)\n",
            "I0628 04:58:46.920499 139821928843136 run_pretraining.py:119]   name = input_ids, shape = (16, 128)\n",
            "2019-06-28 04:58:46,932 :       name = input_mask, shape = (16, 128)\n",
            "I0628 04:58:46.932158 139821928843136 run_pretraining.py:119]   name = input_mask, shape = (16, 128)\n",
            "2019-06-28 04:58:46,934 :       name = masked_lm_ids, shape = (16, 20)\n",
            "I0628 04:58:46.934621 139821928843136 run_pretraining.py:119]   name = masked_lm_ids, shape = (16, 20)\n",
            "2019-06-28 04:58:46,936 :       name = masked_lm_positions, shape = (16, 20)\n",
            "I0628 04:58:46.936784 139821928843136 run_pretraining.py:119]   name = masked_lm_positions, shape = (16, 20)\n",
            "2019-06-28 04:58:46,941 :       name = masked_lm_weights, shape = (16, 20)\n",
            "I0628 04:58:46.941063 139821928843136 run_pretraining.py:119]   name = masked_lm_weights, shape = (16, 20)\n",
            "2019-06-28 04:58:46,945 :       name = next_sentence_labels, shape = (16, 1)\n",
            "I0628 04:58:46.945415 139821928843136 run_pretraining.py:119]   name = next_sentence_labels, shape = (16, 1)\n",
            "2019-06-28 04:58:46,949 :       name = segment_ids, shape = (16, 128)\n",
            "I0628 04:58:46.949718 139821928843136 run_pretraining.py:119]   name = segment_ids, shape = (16, 128)\n",
            "2019-06-28 04:58:50,969 :     **** Trainable Variables ****\n",
            "I0628 04:58:50.969051 139821928843136 run_pretraining.py:167] **** Trainable Variables ****\n",
            "2019-06-28 04:58:50,976 :       name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.976625 139821928843136 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:50,980 :       name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.980766 139821928843136 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:50,990 :       name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.990313 139821928843136 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:50,993 :       name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.993519 139821928843136 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:50,995 :       name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.995826 139821928843136 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:50,999 :       name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:50.999294 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,003 :       name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.003414 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,008 :       name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.008190 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,013 :       name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.013149 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,015 :       name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.015760 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,019 :       name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.019175 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,024 :       name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.024669 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,027 :       name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.027291 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,031 :       name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.031392 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,039 :       name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.039014 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,044 :       name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.044931 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,052 :       name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.052321 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,058 :       name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.058066 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,073 :       name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.073142 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,077 :       name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.077512 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,082 :       name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.082022 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,086 :       name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.086691 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,089 :       name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.089945 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,092 :       name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.092406 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,095 :       name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.095084 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,098 :       name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.098609 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,103 :       name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.103441 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,107 :       name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.107241 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,111 :       name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.111788 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,116 :       name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.116562 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,120 :       name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.120724 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,125 :       name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.125519 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,128 :       name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.128652 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,132 :       name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.132049 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,134 :       name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.134788 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,137 :       name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.137830 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,140 :       name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.140543 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,144 :       name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.144210 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,148 :       name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.148207 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,152 :       name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.152449 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,157 :       name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.157099 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,161 :       name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.161716 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,164 :       name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.164419 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,168 :       name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.168226 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,171 :       name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.171241 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,173 :       name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.173598 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,177 :       name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.177724 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,182 :       name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.182347 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,187 :       name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.187091 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,191 :       name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.191581 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,197 :       name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.197794 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,204 :       name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.204164 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,208 :       name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.208341 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,217 :       name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.217782 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,221 :       name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.221793 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,225 :       name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.225014 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,228 :       name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.228266 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,230 :       name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.230926 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,234 :       name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.234158 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,239 :       name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.239529 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,241 :       name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.241776 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,244 :       name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.244957 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,247 :       name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.247936 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,250 :       name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.250405 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,253 :       name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.253381 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,255 :       name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.255727 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,258 :       name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.258354 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,260 :       name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.260502 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,262 :       name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.262984 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,265 :       name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.265517 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,267 :       name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.267724 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,270 :       name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.270215 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,273 :       name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.273066 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,275 :       name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.275595 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,278 :       name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.278299 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,280 :       name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.280930 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,283 :       name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.283642 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,286 :       name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.286240 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,288 :       name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.288963 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,291 :       name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.291196 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,293 :       name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.293930 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,296 :       name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.296562 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,299 :       name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.299565 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,302 :       name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.302210 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,304 :       name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.304984 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,307 :       name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.307802 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,310 :       name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.310343 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,312 :       name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.312581 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,315 :       name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.315650 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,318 :       name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.318660 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,321 :       name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.321509 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,323 :       name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.323688 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,326 :       name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.326278 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,329 :       name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.329156 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,331 :       name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.331180 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,334 :       name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.334811 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,337 :       name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.337916 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,340 :       name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.340450 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,342 :       name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.342676 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,345 :       name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.345344 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,348 :       name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.348727 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,351 :       name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.351823 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,354 :       name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.354881 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,358 :       name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.358464 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,361 :       name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.361573 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,364 :       name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.364986 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,369 :       name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.369142 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,373 :       name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.373239 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,376 :       name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.376384 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,379 :       name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.379494 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,382 :       name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.382834 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,385 :       name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.385822 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,390 :       name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.390235 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,393 :       name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.393143 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,396 :       name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.396310 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,398 :       name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.398498 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,401 :       name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.401620 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,404 :       name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.404162 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,407 :       name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.407142 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,409 :       name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.409185 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,412 :       name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.412357 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,415 :       name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.415077 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,417 :       name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.417665 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,420 :       name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.420136 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,422 :       name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.422337 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,425 :       name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.425760 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,428 :       name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.428437 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,430 :       name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.430879 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,434 :       name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.434483 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,436 :       name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.436855 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,439 :       name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.439689 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,442 :       name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.442117 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,444 :       name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.444946 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,448 :       name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.448120 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,451 :       name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.451244 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,453 :       name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.453487 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,456 :       name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.456827 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,459 :       name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.459590 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,462 :       name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.462479 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,464 :       name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.464864 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,467 :       name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.467574 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,470 :       name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.470613 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,473 :       name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.473619 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,476 :       name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.476225 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,479 :       name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.479351 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,482 :       name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.482584 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,484 :       name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.484801 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,487 :       name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.487678 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,490 :       name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.490107 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,492 :       name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.492924 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,496 :       name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.496182 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,498 :       name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.498835 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,502 :       name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.502582 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,505 :       name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.505127 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,507 :       name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.507549 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,510 :       name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.510817 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,513 :       name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.513044 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,515 :       name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.515648 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,518 :       name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.518772 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,521 :       name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.521764 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,524 :       name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.524150 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,527 :       name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.527305 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,530 :       name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.530074 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,533 :       name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.533400 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,541 :       name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.541164 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,544 :       name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.544259 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,548 :       name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.548042 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,550 :       name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.550848 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,554 :       name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.554525 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,557 :       name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.557112 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,559 :       name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.559365 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,562 :       name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.562288 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,564 :       name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.564739 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,568 :       name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.568302 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,570 :       name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.570725 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,573 :       name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.573858 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,577 :       name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.577269 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,580 :       name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.580359 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,583 :       name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.583645 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,585 :       name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.585824 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,589 :       name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.589447 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,592 :       name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.592327 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,594 :       name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.594386 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,597 :       name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.597633 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,600 :       name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.600299 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,603 :       name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.603092 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,606 :       name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.606443 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,610 :       name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.610174 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,612 :       name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.612864 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,616 :       name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.616316 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,619 :       name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.619451 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,622 :       name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.622114 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,624 :       name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.624193 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,627 :       name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.627404 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,629 :       name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.629977 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,632 :       name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.632557 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,635 :       name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.635383 139821928843136 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,638 :       name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.638231 139821928843136 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,641 :       name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.641309 139821928843136 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,643 :       name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.643513 139821928843136 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,646 :       name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.646946 139821928843136 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,649 :       name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.649418 139821928843136 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,652 :       name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.652196 139821928843136 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,655 :       name = cls/predictions/output_bias:0, shape = (30522,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.655578 139821928843136 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,658 :       name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.658377 139821928843136 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:58:51,660 :       name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "I0628 04:58:51.660872 139821928843136 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "2019-06-28 04:59:08,731 :     From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0628 04:59:08.731500 139821928843136 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2019-06-28 04:59:09,758 :     Create CheckpointSaverHook.\n",
            "I0628 04:59:09.758689 139821928843136 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "2019-06-28 04:59:10,192 :     Done calling model_fn.\n",
            "I0628 04:59:10.192792 139821928843136 estimator.py:1147] Done calling model_fn.\n",
            "2019-06-28 04:59:10,200 :     TPU job name worker\n",
            "I0628 04:59:10.200624 139821928843136 tpu_estimator.py:499] TPU job name worker\n",
            "2019-06-28 04:59:12,062 :     Graph was finalized.\n",
            "I0628 04:59:12.062145 139821928843136 monitored_session.py:240] Graph was finalized.\n",
            "2019-06-28 04:59:24,428 :     Running local_init_op.\n",
            "I0628 04:59:24.428116 139821928843136 session_manager.py:500] Running local_init_op.\n",
            "2019-06-28 04:59:25,123 :     Done running local_init_op.\n",
            "I0628 04:59:25.123774 139821928843136 session_manager.py:502] Done running local_init_op.\n",
            "2019-06-28 04:59:36,852 :     Saving checkpoints for 0 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 04:59:36.852787 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 04:59:58,136 :     From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0628 04:59:58.136089 139821928843136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2019-06-28 04:59:59,592 :     Initialized dataset iterators in 0 seconds\n",
            "I0628 04:59:59.592379 139821928843136 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "2019-06-28 04:59:59,597 :     Installing graceful shutdown hook.\n",
            "I0628 04:59:59.597461 139821928843136 session_support.py:332] Installing graceful shutdown hook.\n",
            "2019-06-28 04:59:59,607 :     Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0628 04:59:59.607614 139821928843136 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2019-06-28 04:59:59,621 :     Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0628 04:59:59.621157 139821928843136 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2019-06-28 04:59:59,627 :     Init TPU system\n",
            "I0628 04:59:59.627944 139821928843136 tpu_estimator.py:557] Init TPU system\n",
            "2019-06-28 05:00:07,035 :     Initialized TPU in 7 seconds\n",
            "I0628 05:00:07.035859 139821928843136 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "2019-06-28 05:00:07,039 :     Starting infeed thread controller.\n",
            "I0628 05:00:07.039316 139820202440448 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "2019-06-28 05:00:07,047 :     Starting outfeed thread controller.\n",
            "I0628 05:00:07.047831 139820194047744 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "2019-06-28 05:00:07,753 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:00:07.753633 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:00:07,756 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:00:07.756799 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:00:42,526 :     Outfeed finished for iteration (0, 0)\n",
            "I0628 05:00:42.526626 139820194047744 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "2019-06-28 05:00:54,044 :     Saving checkpoints for 100 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:00:54.044703 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 100 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:01:15,877 :     loss = 3.738514, step = 100\n",
            "I0628 05:01:15.877481 139821928843136 basic_session_run_hooks.py:262] loss = 3.738514, step = 100\n",
            "2019-06-28 05:01:15,888 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:01:15.888380 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:01:15,892 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:01:15.892919 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:01:35,512 :     Saving checkpoints for 200 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:01:35.512123 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 200 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:01:56,835 :     loss = 3.2400565, step = 200 (40.958 sec)\n",
            "I0628 05:01:56.835118 139821928843136 basic_session_run_hooks.py:260] loss = 3.2400565, step = 200 (40.958 sec)\n",
            "2019-06-28 05:01:56,844 :     global_step/sec: 2.44158\n",
            "I0628 05:01:56.844756 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.44158\n",
            "2019-06-28 05:01:56,851 :     examples/sec: 312.522\n",
            "I0628 05:01:56.851142 139821928843136 tpu_estimator.py:2160] examples/sec: 312.522\n",
            "2019-06-28 05:01:56,859 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:01:56.859484 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:01:56,866 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:01:56.866797 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:01:58,044 :     Outfeed finished for iteration (2, 0)\n",
            "I0628 05:01:58.044528 139820194047744 tpu_estimator.py:275] Outfeed finished for iteration (2, 0)\n",
            "2019-06-28 05:02:09,514 :     Saving checkpoints for 300 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:02:09.514864 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 300 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:02:32,473 :     loss = 3.67097, step = 300 (35.639 sec)\n",
            "I0628 05:02:32.473834 139821928843136 basic_session_run_hooks.py:260] loss = 3.67097, step = 300 (35.639 sec)\n",
            "2019-06-28 05:02:32,479 :     global_step/sec: 2.8062\n",
            "I0628 05:02:32.479523 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.8062\n",
            "2019-06-28 05:02:32,481 :     examples/sec: 359.194\n",
            "I0628 05:02:32.481783 139821928843136 tpu_estimator.py:2160] examples/sec: 359.194\n",
            "2019-06-28 05:02:32,487 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:02:32.487267 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:02:32,491 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:02:32.491274 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:02:45,193 :     Saving checkpoints for 400 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:02:45.193461 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 400 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:03:12,238 :     loss = 3.642254, step = 400 (39.764 sec)\n",
            "I0628 05:03:12.238135 139821928843136 basic_session_run_hooks.py:260] loss = 3.642254, step = 400 (39.764 sec)\n",
            "2019-06-28 05:03:12,242 :     global_step/sec: 2.51488\n",
            "I0628 05:03:12.242807 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.51488\n",
            "2019-06-28 05:03:12,248 :     examples/sec: 321.905\n",
            "I0628 05:03:12.248192 139821928843136 tpu_estimator.py:2160] examples/sec: 321.905\n",
            "2019-06-28 05:03:12,253 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:03:12.253252 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:03:12,257 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:03:12.257729 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:03:13,414 :     Outfeed finished for iteration (4, 0)\n",
            "I0628 05:03:13.414680 139820194047744 tpu_estimator.py:275] Outfeed finished for iteration (4, 0)\n",
            "2019-06-28 05:03:24,956 :     Saving checkpoints for 500 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:03:24.956428 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 500 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:03:44,610 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0628 05:03:44.610366 139821928843136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2019-06-28 05:03:48,126 :     loss = 3.3727186, step = 500 (35.888 sec)\n",
            "I0628 05:03:48.126145 139821928843136 basic_session_run_hooks.py:260] loss = 3.3727186, step = 500 (35.888 sec)\n",
            "2019-06-28 05:03:48,130 :     global_step/sec: 2.7865\n",
            "I0628 05:03:48.130011 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.7865\n",
            "2019-06-28 05:03:48,138 :     examples/sec: 356.672\n",
            "I0628 05:03:48.138285 139821928843136 tpu_estimator.py:2160] examples/sec: 356.672\n",
            "2019-06-28 05:03:48,144 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:03:48.144646 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:03:48,148 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:03:48.148838 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:04:00,829 :     Saving checkpoints for 600 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:04:00.829336 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 600 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:04:20,954 :     loss = 3.5376894, step = 600 (32.829 sec)\n",
            "I0628 05:04:20.954963 139821928843136 basic_session_run_hooks.py:260] loss = 3.5376894, step = 600 (32.829 sec)\n",
            "2019-06-28 05:04:20,962 :     global_step/sec: 3.04579\n",
            "I0628 05:04:20.962339 139821928843136 tpu_estimator.py:2159] global_step/sec: 3.04579\n",
            "2019-06-28 05:04:20,969 :     examples/sec: 389.861\n",
            "I0628 05:04:20.969343 139821928843136 tpu_estimator.py:2160] examples/sec: 389.861\n",
            "2019-06-28 05:04:20,974 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:04:20.974139 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:04:20,976 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:04:20.976569 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:04:22,224 :     Outfeed finished for iteration (6, 0)\n",
            "I0628 05:04:22.224868 139820194047744 tpu_estimator.py:275] Outfeed finished for iteration (6, 0)\n",
            "2019-06-28 05:04:33,740 :     Saving checkpoints for 700 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:04:33.740926 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 700 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:04:56,637 :     loss = 4.1141877, step = 700 (35.683 sec)\n",
            "I0628 05:04:56.637928 139821928843136 basic_session_run_hooks.py:260] loss = 4.1141877, step = 700 (35.683 sec)\n",
            "2019-06-28 05:04:56,642 :     global_step/sec: 2.8027\n",
            "I0628 05:04:56.642062 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.8027\n",
            "2019-06-28 05:04:56,649 :     examples/sec: 358.745\n",
            "I0628 05:04:56.649586 139821928843136 tpu_estimator.py:2160] examples/sec: 358.745\n",
            "2019-06-28 05:04:56,658 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:04:56.658634 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:04:56,661 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:04:56.661428 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:05:09,315 :     Saving checkpoints for 800 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:05:09.315428 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 800 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:05:33,896 :     loss = 3.0927358, step = 800 (37.259 sec)\n",
            "I0628 05:05:33.896435 139821928843136 basic_session_run_hooks.py:260] loss = 3.0927358, step = 800 (37.259 sec)\n",
            "2019-06-28 05:05:33,907 :     global_step/sec: 2.68349\n",
            "I0628 05:05:33.907084 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.68349\n",
            "2019-06-28 05:05:33,912 :     examples/sec: 343.487\n",
            "I0628 05:05:33.912444 139821928843136 tpu_estimator.py:2160] examples/sec: 343.487\n",
            "2019-06-28 05:05:33,916 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:05:33.916412 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:05:33,918 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:05:33.918540 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:05:35,106 :     Outfeed finished for iteration (8, 0)\n",
            "I0628 05:05:35.106981 139820194047744 tpu_estimator.py:275] Outfeed finished for iteration (8, 0)\n",
            "2019-06-28 05:05:46,636 :     Saving checkpoints for 900 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:05:46.636707 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 900 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:06:08,448 :     loss = 3.6156018, step = 900 (34.552 sec)\n",
            "I0628 05:06:08.448052 139821928843136 basic_session_run_hooks.py:260] loss = 3.6156018, step = 900 (34.552 sec)\n",
            "2019-06-28 05:06:08,452 :     global_step/sec: 2.89477\n",
            "I0628 05:06:08.452085 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.89477\n",
            "2019-06-28 05:06:08,455 :     examples/sec: 370.53\n",
            "I0628 05:06:08.455595 139821928843136 tpu_estimator.py:2160] examples/sec: 370.53\n",
            "2019-06-28 05:06:08,465 :     Enqueue next (100) batch(es) of data to infeed.\n",
            "I0628 05:06:08.465400 139821928843136 tpu_estimator.py:590] Enqueue next (100) batch(es) of data to infeed.\n",
            "2019-06-28 05:06:08,469 :     Dequeue next (100) batch(es) of data from outfeed.\n",
            "I0628 05:06:08.469306 139821928843136 tpu_estimator.py:594] Dequeue next (100) batch(es) of data from outfeed.\n",
            "2019-06-28 05:06:21,268 :     Saving checkpoints for 1000 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "I0628 05:06:21.268429 139821928843136 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into gs://ayushjain1144-bucket/bert_model/model.ckpt.\n",
            "2019-06-28 05:06:42,235 :     loss = 3.243185, step = 1000 (33.788 sec)\n",
            "I0628 05:06:42.235633 139821928843136 basic_session_run_hooks.py:260] loss = 3.243185, step = 1000 (33.788 sec)\n",
            "2019-06-28 05:06:42,245 :     global_step/sec: 2.9592\n",
            "I0628 05:06:42.245104 139821928843136 tpu_estimator.py:2159] global_step/sec: 2.9592\n",
            "2019-06-28 05:06:42,248 :     examples/sec: 378.778\n",
            "I0628 05:06:42.248432 139821928843136 tpu_estimator.py:2160] examples/sec: 378.778\n",
            "2019-06-28 05:06:42,863 :     Stop infeed thread controller\n",
            "I0628 05:06:42.863510 139821928843136 tpu_estimator.py:598] Stop infeed thread controller\n",
            "2019-06-28 05:06:42,869 :     Shutting down InfeedController thread.\n",
            "I0628 05:06:42.869347 139821928843136 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
            "2019-06-28 05:06:42,875 :     InfeedController received shutdown signal, stopping.\n",
            "I0628 05:06:42.875152 139820202440448 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
            "2019-06-28 05:06:42,879 :     Infeed thread finished, shutting down.\n",
            "I0628 05:06:42.879800 139820202440448 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
            "2019-06-28 05:06:42,885 :     infeed marked as finished\n",
            "I0628 05:06:42.885519 139821928843136 error_handling.py:96] infeed marked as finished\n",
            "2019-06-28 05:06:42,890 :     Stop output thread controller\n",
            "I0628 05:06:42.890224 139821928843136 tpu_estimator.py:602] Stop output thread controller\n",
            "2019-06-28 05:06:42,893 :     Shutting down OutfeedController thread.\n",
            "I0628 05:06:42.893626 139821928843136 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
            "2019-06-28 05:06:42,896 :     OutfeedController received shutdown signal, stopping.\n",
            "I0628 05:06:42.896391 139820194047744 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
            "2019-06-28 05:06:42,915 :     Outfeed thread finished, shutting down.\n",
            "I0628 05:06:42.915299 139820194047744 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
            "2019-06-28 05:06:42,918 :     outfeed marked as finished\n",
            "I0628 05:06:42.918537 139821928843136 error_handling.py:96] outfeed marked as finished\n",
            "2019-06-28 05:06:42,921 :     Shutdown TPU system.\n",
            "I0628 05:06:42.921876 139821928843136 tpu_estimator.py:606] Shutdown TPU system.\n",
            "2019-06-28 05:06:44,463 :     Loss for final step: 3.243185.\n",
            "I0628 05:06:44.463072 139821928843136 estimator.py:368] Loss for final step: 3.243185.\n",
            "2019-06-28 05:06:44,466 :     training_loop marked as finished\n",
            "I0628 05:06:44.466605 139821928843136 error_handling.py:96] training_loop marked as finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x7f2a7c543080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrGT700d2p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZj4zT6qiyl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}