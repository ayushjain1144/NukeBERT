{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_pretrained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushjain1144/semantic-segmentation-IGCAR/blob/master/bert_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpScP8RAWvyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ed73b1b3-48b5-423c-dcc2-fa72a8e2f3a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/igcar_ps/ /mydrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mexRfQy7Wxvl",
        "colab_type": "code",
        "outputId": "d2b6ff3e-b79d-404c-bb41-a63cc33ef94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "\n",
        "!git clone https://github.com/google-research/bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 329, done.\u001b[K\n",
            "remote: Total 329 (delta 0), reused 0 (delta 0), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (329/329), 239.74 KiB | 3.63 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ongTGudaW8jY",
        "colab_type": "code",
        "outputId": "e9fa418b-7fd1-4dfd-e833-9324af35cc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s : \\\n",
        "    %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    log.info(\"Using TPU runtime\")\n",
        "    USE_TPU = True\n",
        "    TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    \n",
        "    with tf.Session(TPU_ADDRESS) as session:\n",
        "        log.info('TPU address is ' + TPU_ADDRESS)\n",
        "        with open('/content/adc.json', 'r') as f:\n",
        "          auth_info = json.load(f)\n",
        "        \n",
        "        tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "        \n",
        "       \n",
        "else:\n",
        "    log.warning('Not connected to TPU runtime')\n",
        "    USE_TPU = False"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-06 06:18:40,507 :     Using TPU runtime\n",
            "I0706 06:18:40.507112 139673349842816 interactiveshell.py:2882] Using TPU runtime\n",
            "2019-07-06 06:18:40,513 :     TPU address is grpc://10.36.27.50:8470\n",
            "I0706 06:18:40.513590 139673349842816 interactiveshell.py:2882] TPU address is grpc://10.36.27.50:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7FefAp_6cKl",
        "colab_type": "code",
        "outputId": "90d04a0a-f615-4c75-f14a-23d5c3ba6afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%cd /content/\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            " adc.json  'combined_cleaned .exe'   gdrive\n",
            " bert\t    final_data_newer.txt     sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8MEcIi47rGc",
        "colab_type": "code",
        "outputId": "7d0d2feb-fe4e-4e5f-d3d1-1a58fdc305e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " adc.json  'combined_cleaned .exe'   gdrive\n",
            " bert\t    final_data_newer.txt     sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QH_3A5xZ-md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from bert import modeling, optimization, tokenization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuMf4ygEcyLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert.run_pretraining\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAu7IdzPc3EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "MASKED_LM_PROB = 0.15\n",
        "MAX_PREDICTIONS = 20\n",
        "DO_LOWER_CASE = True\n",
        "PROCESSES = 2\n",
        "PRETRAINING_DIR = \"pretraining_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZEwEGutfq-I",
        "colab_type": "code",
        "outputId": "27f9430b-28e0-424b-e712-16a17f4c38a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!wc -w final_data_newer.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7618749 final_data_newer.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj1GYeeJfun6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d 'final_data_newer.txt' ./shards/shard_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_4xxGjgfwaJ",
        "colab_type": "code",
        "outputId": "925828b9-645c-43e0-ff48-5d967433a227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls ./shards/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_0000  shard_0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszGK0VCKCqk",
        "colab_type": "code",
        "outputId": "eef08ccc-7466-4827-dfb2-7109c6eb9144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = '/mydrive/bert_uncased/' + BERT_MODEL\n",
        "print('****** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR)) \n",
        "#!ls BERT_PRETRAINED_DIR"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****** BERT pretrained directory: /mydrive/bert_uncased/uncased_L-12_H-768_A-12 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWyRoAuZL9X7",
        "colab_type": "code",
        "outputId": "b1400eb3-ab52-4cc2-f434-380685020b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "BERT_CONFIG = BERT_PRETRAINED_DIR + '/bert_config.json'\n",
        "CHKPT_DIR = BERT_PRETRAINED_DIR + '/bert_model.ckpt.*'\n",
        "VOCAB_FILE = BERT_PRETRAINED_DIR + '/vocab.txt'\n",
        "INIT_CHECKPOINT = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "!ls $CHKPT_DIR"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "/mydrive/bert_uncased/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7A2a1Z2fyzx",
        "colab_type": "code",
        "outputId": "2555abf7-b9f1-4feb-cd84-163fc76d663d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "            \"python3 bert/create_pretraining_data.py \"\n",
        "            \"--input_file=./shards/{} \"\n",
        "            \"--output_file={}/{}.tfrecord \"\n",
        "            \"--vocab_file={} \"\n",
        "            \"--do_lower_case={} \"\n",
        "            \"--max_predictions_per_seq={} \"\n",
        "            \"--max_seq_length={} \"\n",
        "            \"--masked_lm_prob={} \"\n",
        "            \"--random_seed=108 \"\n",
        "            \"--dupe_factors=5 \")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}',\n",
        "                            PRETRAINING_DIR, '{}',\n",
        "                            VOCAB_FILE,\n",
        "                            DO_LOWER_CASE,\n",
        "                            MAX_PREDICTIONS, MAX_SEQ_LENGTH,\n",
        "                            MASKED_LM_PROB)\n",
        "\n",
        "print(XARGS_CMD)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls ./shards/ | xargs -n 1 -P 2 -I{} python3 bert/create_pretraining_data.py --input_file=./shards/{} --output_file=pretraining_data/{}.tfrecord --vocab_file=/mydrive/bert_uncased/uncased_L-12_H-768_A-12/vocab.txt --do_lower_case=True --max_predictions_per_seq=20 --max_seq_length=128 --masked_lm_prob=0.15 --random_seed=108 --dupe_factors=5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZMJnUnTRc1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile.MkDir(PRETRAINING_DIR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89-dOqD0RoN7",
        "colab_type": "code",
        "outputId": "622b53e4-5261-46c1-b2eb-b81ca715ecd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!$XARGS_CMD"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 05:42:11.592748 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0706 05:42:11.593875 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0706 05:42:11.594099 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0706 05:42:11.594341 140503448741760 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 05:42:11.601556 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0706 05:42:11.602426 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0706 05:42:11.602583 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0706 05:42:11.602723 140088198449024 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0706 05:42:12.006147 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0706 05:42:12.011658 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0706 05:42:12.013112 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0706 05:42:12.013370 140503448741760 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "I0706 05:42:12.013459 140503448741760 create_pretraining_data.py:448]   ./shards/shard_0001\n",
            "W0706 05:42:12.014605 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0706 05:42:12.014863 140088198449024 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "I0706 05:42:12.014977 140088198449024 create_pretraining_data.py:448]   ./shards/shard_0000\n",
            "I0706 05:53:26.321241 140503448741760 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "I0706 05:53:26.321827 140503448741760 create_pretraining_data.py:459]   pretraining_data/shard_0001.tfrecord\n",
            "W0706 05:53:26.322077 140503448741760 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0706 05:53:26.324247 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.324541 140503448741760 create_pretraining_data.py:151] tokens: [CLS] this was done weekly basis applying [MASK] ##ec [MASK] ramp voltage current the input the conditioning amplifier each channel . [SEP] et ##h st [MASK] se [MASK] pet ##ques ##sy [MASK] [MASK] ##eg ape ##oy . zu ##y ##zee ##g rep ##eo ##y . so ##ub ##te ##qu ##y i [MASK] ##y hd [MASK] stu wo ##t ate ##d ##g pa ##oue ##z arab ##g wai [MASK] ##q pea ##nse steal wo consisting at [MASK] ##g pa ##oue ##te ##qu ##ya ac [MASK] w ##dd situ wo ##t ate ##os pac ##uet ##eg st ##t ms ##t bog pe ##oue ##te ##qua wa ##d wo ##t et ##eo ##gs pas ##uet ##eg w [MASK] . [SEP]\n",
            "I0706 05:53:26.324774 140503448741760 create_pretraining_data.py:161] input_ids: 101 2023 2001 2589 4882 3978 11243 103 8586 103 13276 10004 2783 1996 7953 1996 14372 22686 2169 3149 1012 102 3802 2232 2358 103 7367 103 9004 10997 6508 103 103 13910 23957 6977 1012 16950 2100 23940 2290 16360 8780 2100 1012 2061 12083 2618 28940 2100 1045 103 2100 10751 103 24646 24185 2102 8823 2094 2290 6643 27872 2480 5424 2290 23701 103 4160 26034 12325 8954 24185 5398 2012 103 2290 6643 27872 2618 28940 3148 9353 103 1059 14141 26179 24185 2102 8823 2891 14397 23361 13910 2358 2102 5796 2102 22132 21877 27872 2618 16211 11333 2094 24185 2102 3802 8780 5620 14674 23361 13910 1059 103 1012 102 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.324968 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.325149 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.325313 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 7 9 18 25 27 31 32 51 54 62 64 67 71 73 75 83 87 114 0 0\n",
            "I0706 05:53:26.325438 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 3924 15422 2169 2100 2100 10514 9515 3501 2094 27872 2618 2358 4710 2102 4103 24793 24185 14141 0 0\n",
            "I0706 05:53:26.325629 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I0706 05:53:26.325771 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.326525 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.326779 140503448741760 create_pretraining_data.py:151] tokens: [CLS] follow ##ix ##g [MASK] the theory presented here are actually the subject our further and careful [MASK] . therefore restrict [MASK] only some su ##g ge ##sti ##ons which may are direct interest . particular possible [MASK] from e [MASK] ##s . [MASK] the dependence dil ##ata [MASK] tensor [MASK] remaining characteristics . our case and [MASK] also [MASK] variables . shall clarify this point ce [MASK] . the other hand [MASK] eliminate from e ##q ##s [SEP] and dil ##ata ##tion tensor [MASK] . thus are able obtain gearbox set [MASK] relations [MASK] respect and . the solution this set will then give the form dependence those fun ##ce ##tions physical variables which ad ##missible from the point view performed splitting into additive parts richards [SEP]\n",
            "I0706 05:53:26.326978 140503448741760 create_pretraining_data.py:161] input_ids: 101 3582 7646 2290 103 1996 3399 3591 2182 2024 2941 1996 3395 2256 2582 1998 6176 103 1012 3568 21573 103 2069 2070 10514 2290 16216 16643 5644 2029 2089 2024 3622 3037 1012 3327 2825 103 2013 1041 103 2015 1012 103 1996 18642 29454 6790 103 23435 103 3588 6459 1012 2256 2553 1998 103 2036 103 10857 1012 4618 25037 2023 2391 8292 103 1012 1996 2060 2192 103 11027 2013 1041 4160 2015 102 1998 29454 6790 3508 23435 103 1012 2947 2024 2583 6855 22227 2275 103 4262 103 4847 1998 1012 1996 5576 2023 2275 2097 2059 2507 1996 2433 18642 2216 4569 3401 9285 3558 10857 2029 4748 26770 2013 1996 2391 3193 2864 14541 2046 29167 3033 9712 102\n",
            "I0706 05:53:26.327143 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.327362 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.327493 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 4 17 21 37 40 43 48 50 57 59 67 72 84 90 92 94 105 113 126 0\n",
            "I0706 05:53:26.327612 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2013 4812 9731 16157 4160 1998 3508 1996 1998 3558 8261 2064 2965 2981 9897 2007 1996 10857 1012 0\n",
            "I0706 05:53:26.327750 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.327861 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.328604 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.328843 140503448741760 create_pretraining_data.py:151] tokens: [CLS] aa ##rup ##ada ##i ve ##ed ##u [MASK] technology pa ##iya seychelles ##or chennai tamil ##nad ##u india virtue graduate and research [MASK] physics government arts college ti ##ru ##vana ##mal ##ai tamil ##nad [MASK] india department physics ss ##n [MASK] engineering kala ##va [MASK] ##m chennai tamil ##nad ##u india radio ##logical safety division indira gandhi centre for atomic research ka ##lp ##ak ##kam tamil ##nad [MASK] india received [MASK] received revised form july accepted august available online november abstract one ##hun [MASK] ##df ##if ##ty ##one [MASK] six types building [MASK] were [MASK] from different locations [MASK] [MASK] ##ru ##van ##nam ##ala ##i district tamil ##nad ##u and [MASK] [MASK] [SEP] from the results the highest values observed the specific activities and were . [SEP]\n",
            "I0706 05:53:26.329037 140503448741760 create_pretraining_data.py:161] input_ids: 101 9779 21531 8447 2072 2310 2098 2226 103 2974 6643 8717 27438 2953 12249 6008 25389 2226 2634 11870 4619 1998 2470 103 5584 2231 2840 2267 14841 6820 27313 9067 4886 6008 25389 103 2634 2533 5584 7020 2078 103 3330 26209 3567 103 2213 12249 6008 25389 2226 2634 2557 9966 3808 2407 28232 12338 2803 2005 9593 2470 10556 14277 4817 27052 6008 25389 103 2634 2363 103 2363 8001 2433 2251 3970 2257 2800 3784 2281 10061 2028 17157 103 20952 10128 3723 5643 103 2416 4127 2311 103 2020 103 2013 2367 5269 103 103 6820 6212 13129 7911 2072 2212 6008 25389 2226 1998 103 103 102 2013 1996 3463 1996 3284 5300 5159 1996 3563 3450 1998 2020 1012 102\n",
            "I0706 05:53:26.329216 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.329370 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.329477 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 8 9 12 19 23 35 41 45 68 71 84 89 93 95 99 100 111 112 124 0\n",
            "I0706 05:53:26.329579 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2820 2974 3630 2695 2533 2226 2267 15714 2226 2238 16200 8168 4475 5067 1996 14841 2020 16578 1998 0\n",
            "I0706 05:53:26.329694 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.329782 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.330474 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.330683 140503448741760 create_pretraining_data.py:151] tokens: [CLS] heat [MASK] from the open loops transform reactor head area was evaluated determine the amount helium cool ##ant required remove that heat the results this evaluation are graphical ##ly [MASK] figure the open loops were modeled homogeneous stainless steel fins with [MASK] temperature the [MASK] boundary the neutron shield the helium cool mayfield temperature was assumed constant the [MASK] [MASK] ##ctive [MASK] transfer [MASK] were calculated functions the helium flow [MASK] and the distance from the reactor center [MASK] for both the [MASK] and lower [MASK] the [MASK] [SEP] using these coefficients the heat transferred from [MASK] open loop [MASK] distance from the reactor center ##line calculated function helium flow [MASK] the open loops were then grouped relation their distances from the reactor vessel center ##line [SEP]\n",
            "I0706 05:53:26.330870 140503448741760 create_pretraining_data.py:161] input_ids: 101 3684 103 2013 1996 2330 15932 10938 13308 2132 2181 2001 16330 5646 1996 3815 22764 4658 4630 3223 6366 2008 3684 1996 3463 2023 9312 2024 20477 2135 103 3275 1996 2330 15932 2020 14440 24854 18676 3886 18564 2007 103 4860 1996 103 6192 1996 20393 6099 1996 22764 4658 27224 4860 2001 5071 5377 1996 103 103 15277 103 4651 103 2020 10174 4972 1996 22764 4834 103 1998 1996 3292 2013 1996 13308 2415 103 2005 2119 1996 103 1998 2896 103 1996 103 102 2478 2122 21374 1996 3684 4015 2013 103 2330 7077 103 3292 2013 1996 13308 2415 4179 10174 3853 22764 4834 103 1996 2330 15932 2020 2059 15131 7189 2037 12103 2013 1996 13308 6258 2415 4179 102\n",
            "I0706 05:53:26.331023 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.331184 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.331295 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 2 7 30 42 45 53 59 60 62 64 71 79 83 86 88 97 100 107 111 0\n",
            "I0706 05:53:26.331399 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 4651 1996 3421 2918 2896 4630 9530 3726 3684 21374 3446 4179 3356 5433 2330 2028 2445 10174 3446 0\n",
            "I0706 05:53:26.331507 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.331594 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.332324 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.332530 140503448741760 create_pretraining_data.py:151] tokens: [CLS] succeeded ##ater elemental io [MASK] removal n 303 ##ating significant ads [MASK] ##ption rani ##ne particles . tod ##ine re [MASK] with foam ##s z ##ine [MASK] studies ti ##onal laboratory . continuous recycling na ##gs removal efficiency ho ##ut foam demonstrated [MASK] did ##e . [MASK] ##pling order after [MASK] ##mo ##vir the reduction io ##dine performed t ##le are presented figure foam can ##ts was not [MASK] effect the chamber [MASK] [MASK] nt ##ured proctor ga ##ir ##ble cincinnati . [SEP] foam addition starts io ##dine decay dry [MASK] before [MASK] addition shown left dotted line plain [MASK] z ##io . foam wit . hydra ##zine foam with hydra ##zine f ##oi [MASK] ##h [MASK] ee ##e she fae ##s ran foam with . [SEP]\n",
            "I0706 05:53:26.332713 140503448741760 create_pretraining_data.py:161] input_ids: 101 4594 24932 19529 22834 103 8208 1050 19988 5844 3278 14997 103 16790 21617 2638 9309 1012 28681 3170 2128 103 2007 17952 2015 1062 3170 103 2913 14841 16026 5911 1012 7142 17874 6583 5620 8208 8122 7570 4904 17952 7645 103 2106 2063 1012 103 14353 2344 2044 103 5302 21663 1996 7312 22834 10672 2864 1056 2571 2024 3591 3275 17952 2064 3215 2001 2025 103 3466 1996 4574 103 103 23961 12165 28770 11721 4313 3468 7797 1012 102 17952 2804 4627 22834 10672 13121 4318 103 2077 103 2804 3491 2187 20384 2240 5810 103 1062 3695 1012 17952 15966 1012 26018 21254 17952 2007 26018 21254 1042 10448 103 2232 103 25212 2063 2016 17282 2015 2743 17952 2007 1012 102\n",
            "I0706 05:53:26.332871 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.333016 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.333111 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 1 5 8 12 21 27 43 47 51 69 73 74 91 93 99 100 115 117 121 0\n",
            "I0706 05:53:26.333228 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2128 10672 14808 2953 2099 9242 3278 2624 2128 2200 2250 3223 4574 17952 5810 17952 2777 24315 17282 0\n",
            "I0706 05:53:26.333335 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.333426 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.334088 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.334299 140503448741760 create_pretraining_data.py:151] tokens: [CLS] particles will used [MASK] information the stability paste flow over extended period time further paste flow data [MASK] gathered different temperatures the range from determine whether there any temperature effect paste [MASK] lillian this information will used later evaluating the [MASK] with uranium car ##bid ##e once the operation with stainless steel particles has been completed the solids draining vessel will installed the loop and the stainless 1761 particles will [MASK] [SEP] [MASK] fi ##is [MASK] ##se bra ##hampton [MASK] ##ie for t ##w [MASK] tram ##ieu ##t oct ##u ##ur ben ##e ni ##t z ##pu ##pop ##th ##mt lowe sw ##ale pri ##rti ##n [MASK] the lens ##t ##k [MASK] [MASK] ##ovic je ##op [MASK] worst fe ##ci ##pe ##pa [MASK] sw ##io ##iti [SEP]\n",
            "I0706 05:53:26.334468 140503448741760 create_pretraining_data.py:161] input_ids: 101 9309 2097 2109 103 2592 1996 9211 19351 4834 2058 3668 2558 2051 2582 19351 4834 2951 103 5935 2367 7715 1996 2846 2013 5646 3251 2045 2151 4860 3466 19351 103 19344 2023 2592 2097 2109 2101 23208 1996 103 2007 14247 2482 17062 2063 2320 1996 3169 2007 18676 3886 9309 2038 2042 2949 1996 26778 19689 6258 2097 5361 1996 7077 1998 1996 18676 21364 9309 2097 103 102 103 10882 2483 103 3366 11655 21946 103 2666 2005 1056 2860 103 12517 17301 2102 13323 2226 3126 3841 2063 9152 2102 1062 14289 16340 2705 20492 14086 25430 9453 26927 28228 2078 103 1996 10014 2102 2243 103 103 9142 15333 7361 103 5409 10768 6895 5051 4502 103 25430 3695 25090 102\n",
            "I0706 05:53:26.334631 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.334830 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.334945 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 4 18 32 33 41 68 71 73 76 79 80 85 90 107 112 113 114 117 123 0\n",
            "I0706 05:53:26.335040 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 6855 2097 4834 3446 3169 3886 11055 4066 6904 6593 11865 2546 2226 8545 17710 23296 5596 2818 11244 0\n",
            "I0706 05:53:26.335138 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.335244 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.335885 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.336081 140503448741760 create_pretraining_data.py:151] tokens: [CLS] later using dip ##ole moment measurements ar ##oney [MASK] that the t ##gg and t [MASK] conform ##ers exist solution phase [MASK] this conclusion was supported lee and wil ##ms ##hurst who [MASK] concluded that the t ##gg and [MASK] ##gg conform [MASK] t ##mm exist solution and gas phase while [MASK] ##gg conform ##er was assumed present the solid state . [SEP] [MASK] . kc [MASK] mo ##l relative the t ##gg [MASK] ##er would child [MASK] form the liquid phase [MASK] ##mm [MASK] later work involving electron di [MASK] [MASK] and photo ##ele ##ct ##ron spec ##tro ##scopic [MASK] indicated the t ##gg conform ##ation the most stable the gas phase . face ##lli and sol ##um using [MASK] ##r arrived conclusion that the [SEP]\n",
            "I0706 05:53:26.336270 140503448741760 create_pretraining_data.py:161] input_ids: 101 2101 2478 16510 9890 2617 11702 12098 17791 103 2008 1996 1056 13871 1998 1056 103 23758 2545 4839 5576 4403 103 2023 7091 2001 3569 3389 1998 19863 5244 10510 2040 103 5531 2008 1996 1056 13871 1998 103 13871 23758 103 1056 7382 4839 5576 1998 3806 4403 2096 103 13871 23758 2121 2001 5071 2556 1996 5024 2110 1012 102 103 1012 21117 103 9587 2140 5816 1996 1056 13871 103 2121 2052 2775 103 2433 1996 6381 4403 103 7382 103 2101 2147 5994 10496 4487 103 103 1998 6302 12260 6593 4948 28699 13181 24895 103 5393 1996 1056 13871 23758 3370 1996 2087 6540 1996 3806 4403 1012 2227 6894 1998 14017 2819 2478 103 2099 3369 7091 2008 1996 102\n",
            "I0706 05:53:26.336427 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.336575 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.336681 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 9 16 22 33 40 43 52 64 67 74 77 78 83 85 91 92 101 114 121 0\n",
            "I0706 05:53:26.336791 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 5531 13871 1012 2036 1056 2545 1043 6540 2389 23758 1996 7444 1056 1012 4246 25533 11702 1012 13221 0\n",
            "I0706 05:53:26.336891 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.336974 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.337621 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.337842 140503448741760 create_pretraining_data.py:151] tokens: [CLS] passive range solution [MASK] te ##mp condition h [MASK] sh ##l ##w m ##hn ##o [MASK] ##l ##w h essential sh ##l ##w [MASK] ##hn ##o [MASK] ##l ##w . sen . [MASK] journal materials engineering and symmetrical volume november . solution anne [MASK] ##d h ##no 定 not suffered any [MASK] attack the plain acid and simulated h ##l ##w . the variations the value are the result the variations the dissolution rates from the passive film surface table . discussion from [MASK] results the potent ##io ##dy ##nami ##c scraping ##od ##ic polar ##ization and electro ##chemical noise experiments was found that [MASK] journal [MASK] [MASK] and performance . [SEP] charity ##h because t ##wee ##e vr ##ec ##sure [SEP]\n",
            "I0706 05:53:26.338093 140503448741760 create_pretraining_data.py:161] input_ids: 101 13135 2846 5576 103 8915 8737 4650 1044 103 14021 2140 2860 1049 7295 2080 103 2140 2860 1044 6827 14021 2140 2860 103 7295 2080 103 2140 2860 1012 12411 1012 103 3485 4475 3330 1998 23476 3872 2281 1012 5576 4776 103 2094 1044 3630 1822 2025 4265 2151 103 2886 1996 5810 5648 1998 23599 1044 2140 2860 1012 1996 8358 1996 3643 2024 1996 2765 1996 8358 1996 12275 6165 2013 1996 13135 2143 3302 2795 1012 6594 2013 103 3463 1996 16834 3695 5149 28987 2278 23704 7716 2594 11508 3989 1998 16175 15869 5005 7885 2001 2179 2008 103 3485 103 103 1998 2836 1012 102 5952 2232 2138 1056 28394 2063 27830 8586 28632 102 0 0 0 0 0\n",
            "I0706 05:53:26.338269 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "I0706 05:53:26.338422 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "I0706 05:53:26.431354 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 3 4 9 16 20 24 27 33 38 44 48 52 84 92 105 107 108 113 0 0\n",
            "I0706 05:53:26.431587 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 5576 11375 3630 14021 3630 1049 14021 12411 2836 9453 2038 24625 1996 2019 1996 4475 3330 6904 0 0\n",
            "I0706 05:53:26.431724 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I0706 05:53:26.431820 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.432624 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.432828 140503448741760 create_pretraining_data.py:151] tokens: [CLS] most practical situations crack tip structural member subjected [MASK] loading condition results mixed ##mo ##de fracture [MASK] . [SEP] wee mix see [MASK] ##e [MASK] he [MASK] ##he pl ##en ##um ee ##e h ##hh hd ##hd iii [MASK] program ee ##e ee ##e ee ##e ee [MASK] [SEP]\n",
            "I0706 05:53:26.433004 140503448741760 create_pretraining_data.py:161] input_ids: 101 2087 6742 8146 8579 5955 8332 2266 13532 103 10578 4650 3463 3816 5302 3207 19583 103 1012 102 16776 4666 2156 103 2063 103 2002 103 5369 20228 2368 2819 25212 2063 1044 23644 10751 14945 3523 103 2565 25212 2063 25212 2063 25212 2063 25212 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.433185 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.433377 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.433481 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 9 13 17 23 25 27 39 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.433578 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 3375 3816 4650 25212 29071 5369 6388 2063 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.433681 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:53:26.433777 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.434545 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.434751 140503448741760 create_pretraining_data.py:151] tokens: [CLS] haste ##llo ##y un ##ir ##rad ##iated un ##ir remarkably [MASK] haste ##llo ##y . haste ##llo ##y haste ##llo ##y data from [MASK] . copper [MASK] ##ze gas tube peanut [MASK] ##ld [MASK] containment can fig [MASK] ##ld bra ##ze gas [MASK] penetration design [MASK] primary containment [MASK] [SEP] fig ac ##rac ##ks nic ##ro ##bra ##ze [MASK] ##et tan ##tal ##um after cycles from room temperature . [SEP]\n",
            "I0706 05:53:26.434926 140503448741760 create_pretraining_data.py:161] input_ids: 101 24748 7174 2100 4895 4313 12173 15070 4895 4313 17431 103 24748 7174 2100 1012 24748 7174 2100 24748 7174 2100 2951 2013 103 1012 6967 103 4371 3806 7270 21443 103 6392 103 29174 2064 20965 103 6392 11655 4371 3806 103 20015 2640 103 3078 29174 103 102 20965 9353 22648 5705 27969 3217 10024 4371 103 3388 9092 9080 2819 2044 12709 2013 2282 4860 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.435078 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.435246 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.435364 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 10 11 24 27 32 34 38 43 46 49 59 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.435463 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 12173 15070 25416 11655 2057 3078 2057 7270 2005 1012 6039 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.435566 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:53:26.435650 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.436388 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.436606 140503448741760 create_pretraining_data.py:151] tokens: [CLS] vessel causes boiling the which sweeps through the core hen [MASK] into [MASK] reactor [MASK] ##rri ##mar ##y system . fission products das 仮 fuel clad ##ding the [MASK] steam the steam boil [MASK] [MASK] sec the heat ##tra ##ns ##fer analysis ann ##ular regions equal area and eng ##th into segments . [SEP] and blanket [MASK] pl ##en [MASK] gradually increase reactor pressure manual adjustment feed ##water rate until psi ##g and are reached [MASK] increase power level cutting and [MASK] pump when required route steam turbine desired power level and adjust conde [MASK] double and feed ##water systems normal operation the reactor will operate base [MASK] unit and power [MASK] will majors manually correspond anticipated power demand operating variables the steam feed [MASK] conde [SEP]\n",
            "I0706 05:53:26.436801 140503448741760 create_pretraining_data.py:161] input_ids: 101 6258 5320 16018 1996 2029 26981 2083 1996 4563 21863 103 2046 103 13308 103 18752 7849 2100 2291 1012 27521 3688 8695 1761 4762 13681 4667 1996 103 5492 1996 5492 26077 103 103 10819 1996 3684 6494 3619 7512 4106 5754 7934 4655 5020 2181 1998 25540 2705 2046 9214 1012 102 1998 8768 103 20228 2368 103 6360 3623 13308 3778 6410 19037 5438 5880 3446 2127 17816 2290 1998 2024 2584 103 3623 2373 2504 6276 1998 103 10216 2043 3223 2799 5492 14027 9059 2373 2504 1998 14171 24707 103 3313 1998 5438 5880 3001 3671 3169 1996 13308 2097 5452 2918 103 3131 1998 2373 103 2097 15279 21118 17254 11436 2373 5157 4082 10857 1996 5492 5438 103 24707 102\n",
            "I0706 05:53:26.436958 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.437103 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.437222 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 11 13 15 24 29 34 35 47 57 60 76 82 88 95 96 108 112 114 125 0\n",
            "I0706 05:53:26.437339 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2041 1996 5383 1996 4563 7245 3446 2181 15824 18163 3613 1998 14027 3619 3686 7170 2504 10426 5880 0\n",
            "I0706 05:53:26.437451 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.437537 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.438327 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.438543 140503448741760 create_pretraining_data.py:151] tokens: [CLS] this leads spur ##ious john ##ci ##llation ##s and an ##oma ##lies the [MASK] neutron spectra . [SEP] radial [MASK] two rows with depleted uranium oxide . there are two reflect ##or [MASK] ##asse ##mb ##ly rows followed [MASK] row inner shielding sub ##asse ##mb ##ly two rows internal storage [MASK] [MASK] fuel [MASK] ##asse ##mb [MASK] and nine rows shielding . [MASK] outer ##most three rows are powder [MASK] and the rest are assemblies . [MASK] main characteristics p ##fb ##r are given table . the reactor cuban given fig . and its plan view given [MASK] . the calculations are extended reactor vault [MASK] the radial direction and top shield concrete the axial direction . kumar nuclear [MASK] and design sodium and have the [SEP]\n",
            "I0706 05:53:26.438725 140503448741760 create_pretraining_data.py:161] input_ids: 101 2023 5260 12996 6313 2198 6895 20382 2015 1998 2019 9626 11983 1996 103 20393 29237 1012 102 15255 103 2048 10281 2007 22595 14247 15772 1012 2045 2024 2048 8339 2953 103 27241 14905 2135 10281 2628 103 5216 5110 25553 4942 27241 14905 2135 2048 10281 4722 5527 103 103 4762 103 27241 14905 103 1998 3157 10281 25553 1012 103 6058 11800 2093 10281 2024 9898 103 1998 1996 2717 2024 17720 1012 103 2364 6459 1052 26337 2099 2024 2445 2795 1012 1996 13308 9642 2445 20965 1012 1998 2049 2933 3193 2445 103 1012 1996 16268 2024 3668 13308 11632 103 1996 15255 3257 1998 2327 6099 5509 1996 26819 3257 1012 9600 4517 103 1998 2640 13365 1998 2031 1996 102\n",
            "I0706 05:53:26.438892 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.439041 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.439137 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 5 14 20 22 33 37 39 51 52 54 57 63 70 77 89 98 106 120 125 0\n",
            "I0706 05:53:26.439261 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 9808 23959 15019 10281 4942 10281 2028 5269 2005 4942 11983 1996 17720 1996 3320 20965 5509 3330 2031 0\n",
            "I0706 05:53:26.439379 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.439466 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.440123 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.440350 140503448741760 create_pretraining_data.py:151] tokens: [CLS] raja ##go ##pala ##n information [MASK] originally designed becomes very difficult not impossible . such cases where scaling becomes necessary involves re ##writing major software components and logic [MASK] dundee ##up ##port system . would possible create software architecture that generic wide spectrum tasks [MASK] divide ##nds are rich engineered [SEP] and our approach its nature interdisciplinary [MASK] involving number distinct methods that apply variety physical principles depending [MASK] the type diagnosis performed . such diversity [MASK] calls [MASK] spectrum decision ##making processes [MASK] the three important issues namely the diversity the techniques [MASK] the sacrament components [MASK] need diagnosis and the [MASK] ##wind exeter during which diagnosis takes place automatically generates [MASK] only huge amount raw data but also large chunk human expertise and knowledge [SEP]\n",
            "I0706 05:53:26.440523 140503448741760 create_pretraining_data.py:161] input_ids: 101 10164 3995 19636 2078 2592 103 2761 2881 4150 2200 3697 2025 5263 1012 2107 3572 2073 25169 4150 4072 7336 2128 18560 2350 4007 6177 1998 7961 103 14252 6279 6442 2291 1012 2052 2825 3443 4007 4294 2008 12391 2898 8674 8518 103 11443 18376 2024 4138 13685 102 1998 2256 3921 2049 3267 18593 103 5994 2193 5664 4725 2008 6611 3528 3558 6481 5834 103 1996 2828 11616 2864 1012 2107 8906 103 4455 103 8674 3247 12614 6194 103 1996 2093 2590 3314 8419 1996 8906 1996 5461 103 1996 28958 6177 103 2342 11616 1998 1996 103 11101 12869 2076 2029 11616 3138 2173 8073 19421 103 2069 4121 3815 6315 2951 2021 2036 2312 20000 2529 11532 1998 3716 102\n",
            "I0706 05:53:26.440675 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.440844 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.440968 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 6 29 30 38 45 50 58 69 77 78 79 84 94 96 98 103 105 113 122 0\n",
            "I0706 05:53:26.441068 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 4163 1996 6567 4007 1996 1012 2671 2588 2036 4455 2005 1012 4162 2193 2008 2051 5004 2025 20000 0\n",
            "I0706 05:53:26.441236 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.441343 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.441997 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.442203 140503448741760 create_pretraining_data.py:151] tokens: [CLS] gp ##a obtained for perfect nano ##wire [MASK] the [MASK] strength bc [MASK] direction and the yielding leads abrupt large [MASK] flow stress about gp ##a bc [MASK] nano ##wire with [MASK] boundary displayed comparatively small elastic deformation [MASK] with lower yield strength . [SEP] gp ##a and lower strain yielding compared [MASK] nano ##wire . following the initial [MASK] the ##lean nano ##wire ##s exhibited contrasting flow behaviour during plastic deformation [MASK] constant flow stress gp ##a . followed second elastic [MASK] yield drop and continuous decreases flow stress till failure break observed [MASK] perfect bc ##c nano ##wire . [SEP]\n",
            "I0706 05:53:26.442380 140503448741760 create_pretraining_data.py:161] input_ids: 101 14246 2050 4663 2005 3819 28991 20357 103 1996 103 3997 4647 103 3257 1998 1996 21336 5260 18772 2312 103 4834 6911 2055 14246 2050 4647 103 28991 20357 2007 103 6192 6913 20172 2235 21274 29130 103 2007 2896 10750 3997 1012 102 14246 2050 1998 2896 10178 21336 4102 103 28991 20357 1012 2206 1996 3988 103 1996 20898 28991 20357 2015 8176 22133 4834 9164 2076 6081 29130 103 5377 4834 6911 14246 2050 1012 2628 2117 21274 103 10750 4530 1998 7142 17913 4834 6911 6229 4945 3338 5159 103 3819 4647 2278 28991 20357 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.442533 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.442678 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.442795 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 7 8 10 13 21 28 32 39 53 60 62 73 83 93 95 0 0 0 0 0\n",
            "I0706 05:53:26.442896 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 20357 2485 9373 2278 4530 2278 9792 2247 3819 21336 2048 1012 4672 2001 1996 0 0 0 0 0\n",
            "I0706 05:53:26.443016 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:53:26.443101 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.443801 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.443989 140503448741760 create_pretraining_data.py:151] tokens: [CLS] more recently the measurement electro ##chemical [MASK] resistance parameter derived from statistical analysis the electro ##chemical noise time record has [MASK] interest the research corrosion phenomenon electro ##chemical noise resistance defined [MASK] ratio the standard deviation ##s potential noise the [MASK] [MASK] current noise the noise resistance [MASK] been used [MASK] the onset localized corrosion the formation faults coated material and inverse relationship between noise resistance and corrosion rate has been observed several nigel [MASK] experimental and theoretical found [MASK] the noise resistance [MASK] the limit . [SEP] mil ##s with the small [MASK] ##ding pe ##llet ##s [SEP]\n",
            "I0706 05:53:26.533975 140503448741760 create_pretraining_data.py:161] input_ids: 101 2062 3728 1996 10903 16175 15869 103 5012 16381 5173 2013 7778 4106 1996 16175 15869 5005 2051 2501 2038 103 3037 1996 2470 24625 9575 16175 15869 5005 5012 4225 103 6463 1996 3115 24353 2015 4022 5005 1996 103 103 2783 5005 1996 5005 5012 103 2042 2109 103 1996 14447 22574 24625 1996 4195 19399 15026 3430 1998 19262 3276 2090 5005 5012 1998 24625 3446 2038 2042 5159 2195 12829 103 6388 1998 9373 2179 103 1996 5005 5012 103 1996 5787 1012 102 23689 2015 2007 1996 2235 103 4667 21877 22592 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.534303 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.534482 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.534897 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 7 21 32 41 42 48 51 52 58 74 75 80 84 92 94 0 0 0 0 0\n",
            "I0706 05:53:26.535457 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 5005 4227 1996 3115 24353 2038 5769 1996 19399 14766 2119 2008 1998 1996 13681 0 0 0 0 0\n",
            "I0706 05:53:26.536003 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:53:26.536336 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:53:26.538865 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.539397 140503448741760 create_pretraining_data.py:151] tokens: [CLS] ist ge ##bri ##uch ##lich fi ##ir verdi ##cht ##er und turbine ##ns ##che ##ibe ##n und [MASK] f ##ol [MASK] ##de date ##n st [MASK] ##ck ##gren ##ze k ##pm [MASK] [MASK] ##mis ##che zu ##sam [MASK] ##set ##zu ##ng eine be ##ze ##ich [MASK] [MASK] na [unused890] din ist [MASK] ##ht vo ##rh ##and ##en [SEP] fi ##ir die fra ##ge der reg ##el [MASK] er ##ga ##b sic ##h f ##ol ##gen ##des bei ge ##gen ##dr ##uck [MASK] ##gel ##ung b [MASK] ##bt der [MASK] ##rch ##sat ##z bis her ##unt [MASK] last bei all ##mi ##hli ##ch an ##ste ##igen ##de ##m ge ##gen ##dr [MASK] ko ##nst ##ant [SEP]\n",
            "I0706 05:53:26.539804 140503448741760 create_pretraining_data.py:161] input_ids: 101 21541 16216 23736 10875 18337 10882 4313 20580 10143 2121 6151 14027 3619 5403 20755 2078 6151 103 1042 4747 103 3207 3058 2078 2358 103 3600 13565 4371 1047 9737 103 103 15630 5403 16950 21559 103 13462 9759 3070 27665 2022 4371 7033 103 103 6583 895 11586 21541 103 11039 29536 25032 5685 2368 102 10882 4313 3280 25312 3351 4315 19723 2884 103 9413 3654 2497 14387 2232 1042 4747 6914 6155 21388 16216 6914 13626 12722 103 12439 5575 1038 103 19279 4315 103 11140 16846 2480 20377 2014 16671 103 2197 21388 2035 4328 27766 2818 2019 13473 29206 3207 2213 16216 6914 13626 103 12849 23808 4630 102 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.540500 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.540678 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:53:26.541786 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 18 21 26 32 33 38 46 47 49 52 67 82 86 89 96 99 111 0 0 0\n",
            "I0706 05:53:26.541987 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 6045 6914 2890 2213 18178 3549 11231 3070 2818 27969 5575 2890 23057 4241 2121 2035 12722 0 0 0\n",
            "I0706 05:53:26.542145 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I0706 05:53:26.542268 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.544501 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.544884 140503448741760 create_pretraining_data.py:151] tokens: [CLS] then the phases are allowed settle [MASK] are transferred separating funnel and [MASK] phase georgie ##s are effect ##ed . [SEP] table comparison between magnetic stirring and hand shaking . [MASK] contains h ##no . extract [MASK] tb ##p magnetic [MASK] hand shaking element [MASK] ra ##lf ##inate ii ##ay total raf ##fin ##ate sui ##r to ##t [MASK] product product . [MASK] extraction runs magnetic stir [MASK] and hand [MASK] for mixing the organic and a ##que ##ous phases are [MASK] [MASK] uranium thor ##ium and iron concentrations the raf ##fin ##ate and strip product are determined and compared table . the results [MASK] almost the same both cases . [MASK] magnetic stirring beak ##er recommended the method e [MASK] ##ib [MASK] [MASK] solvent [MASK] [SEP]\n",
            "I0706 05:53:26.545131 140503448741760 create_pretraining_data.py:161] input_ids: 101 2059 1996 12335 2024 3039 7392 103 2024 4015 14443 25102 1998 103 4403 20280 2015 2024 3466 2098 1012 102 2795 7831 2090 8060 18385 1998 2192 5513 1012 103 3397 1044 3630 1012 14817 103 26419 2361 8060 103 2192 5513 5783 103 10958 10270 14776 2462 4710 2561 7148 16294 3686 24086 2099 2000 2102 103 4031 4031 1012 103 14676 3216 8060 16130 103 1998 2192 103 2005 6809 1996 7554 1998 1037 4226 3560 12335 2024 103 103 14247 15321 5007 1998 3707 14061 1996 7148 16294 3686 1998 6167 4031 2024 4340 1998 4102 2795 1012 1996 3463 103 2471 1996 2168 2119 3572 1012 103 8060 18385 23525 2121 6749 1996 4118 1041 103 12322 103 103 23735 103 102\n",
            "I0706 05:53:26.546241 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.546439 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.546550 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 7 13 15 31 37 41 45 59 63 68 71 82 83 105 112 121 123 124 126 0\n",
            "I0706 05:53:26.546653 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2027 1996 8745 5438 4630 18385 1012 13668 23735 3436 5513 4102 1012 2024 6516 26147 8156 1996 14676 0\n",
            "I0706 05:53:26.546763 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.546850 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.547685 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.547899 140503448741760 create_pretraining_data.py:151] tokens: [CLS] into [MASK] top end ##plate . the ceramic stand ##offs are screwed into [MASK] plate [MASK] one end the jules attached the main conductor with the screw cl ##amp . the aluminum stud placed the stand ##offs while the other end the [MASK] placed ina slot the [MASK] . the nuts are tightened the stand ##offs [MASK] [MASK] [MASK] secured with [MASK] [MASK] cl ##amp . care must taken securing the specimen because some materials [MASK] graph ##ite have coefficient expansion that quite different from aluminum . the specimen must free move while maintaining good [MASK] contact . good electrical contact maintained the other [SEP] the the ##rm ##oco ##up ##le then attached the specimen and the leads wrapped around one [MASK] ceramic [MASK] [MASK] [MASK] [SEP]\n",
            "I0706 05:53:26.548073 140503448741760 create_pretraining_data.py:161] input_ids: 101 2046 103 2327 2203 15725 1012 1996 14692 3233 27475 2024 14180 2046 103 5127 103 2028 2203 1996 11044 4987 1996 2364 7589 2007 1996 11224 18856 16613 1012 1996 13061 16054 2872 1996 3233 27475 2096 1996 2060 2203 1996 103 2872 27118 10453 1996 103 1012 1996 12264 2024 8371 1996 3233 27475 103 103 103 7119 2007 103 103 18856 16613 1012 2729 2442 2579 12329 1996 11375 2138 2070 4475 103 10629 4221 2031 19064 4935 2008 3243 2367 2013 13061 1012 1996 11375 2442 2489 2693 2096 8498 2204 103 3967 1012 2204 5992 3967 5224 1996 2060 102 1996 1996 10867 24163 6279 2571 2059 4987 1996 11375 1998 1996 5260 5058 2105 2028 103 14692 103 103 103 102\n",
            "I0706 05:53:26.548262 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.548427 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.548536 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 2 14 16 20 39 43 48 57 58 59 62 63 76 96 121 122 124 125 126 0\n",
            "I0706 05:53:26.548636 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 1996 1996 1998 11375 1996 11375 16054 1998 1996 11375 1996 11224 2107 5992 2028 1996 3233 27475 1012 0\n",
            "I0706 05:53:26.548749 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.548838 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.549563 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.549769 140503448741760 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##r por [MASK] [MASK] disk could used quantitative ##ly collect sodium aero [MASK] for analysis standard con ##ax electrode gland and graf ##oi [MASK] gas ##ke ##ts [MASK] used application with possible sodium exposure dil ##ute ni ##u alloy suitable fission ##pro ##du ##ct source [MASK] filling with sodium and holding for would ensure wet ##ting new secondary 260 [MASK] and [MASK] [SEP] related work smaller passive temperature monitors were fabricated fit inside driver [MASK] ##el clad ##ding possible mechanism [MASK] derived experimental ##ly [MASK] ##ex ##pl ##ain the slow ##in ##cre [MASK] tin [MASK] ##cent ##ration int ##he e ##bri ##i primary sodium and the formation bis ##mut ##hri ##ch deposits the ar ##gon side the trough wall the e ##bri ##i rotating seal [SEP]\n",
            "I0706 05:53:26.549944 140503448741760 create_pretraining_data.py:161] input_ids: 101 103 2099 18499 103 103 9785 2071 2109 20155 2135 8145 13365 18440 103 2005 4106 3115 9530 8528 28688 25320 1998 22160 10448 103 3806 3489 3215 103 2109 4646 2007 2825 13365 7524 29454 10421 9152 2226 17564 7218 27521 21572 8566 6593 3120 103 8110 2007 13365 1998 3173 2005 2052 5676 4954 3436 2047 3905 13539 103 1998 103 102 3141 2147 3760 13135 4860 15410 2020 24212 4906 2503 4062 103 2884 13681 4667 2825 7337 103 5173 6388 2135 103 10288 24759 8113 1996 4030 2378 16748 103 9543 103 13013 8156 20014 5369 1041 23736 2072 3078 13365 1998 1996 4195 20377 28120 26378 2818 10042 1996 12098 7446 2217 1996 23389 2813 1996 1041 23736 2072 13618 7744 102\n",
            "I0706 05:53:26.550094 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.550270 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.550378 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 1 4 5 14 22 25 29 30 47 60 61 63 76 82 86 91 94 96 116 0\n",
            "I0706 05:53:26.550480 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 11957 3560 3384 19454 1998 2140 2071 2109 11641 3147 8132 7524 11263 2001 2393 4030 11022 8663 7446 0\n",
            "I0706 05:53:26.550587 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.550672 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:53:26.551420 140503448741760 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:53:26.551627 140503448741760 create_pretraining_data.py:151] tokens: [CLS] indoor ra ##don concentration and ra ##don mass ex ##hala ##tion rate soil . the correlation [MASK] indoor thor ##on concentration [MASK] thor [MASK] surface ex ##hala [MASK] rate soil was also found fee ##ble . the concentration ra scans seems increase with decreasing ventilation . among the various types [MASK] materials mud [MASK] show higher concentration both ra ##don and [MASK] ##on . these results suggest [MASK] [MASK] soil the vicinity the houses ##aldi very [MASK] contribution the indoor ra ##don thor ##on ##dra [MASK] the [SEP] ra ##don and thor ##on [MASK] was found higher houses close granite quarries [MASK] with those farther away urban area . [MASK] cent [MASK] houses [MASK] ra ##don concentration greater than the reference limit prescribed ic ##rp . [SEP]\n",
            "I0706 05:53:26.551801 140503448741760 create_pretraining_data.py:161] input_ids: 101 7169 10958 5280 6693 1998 10958 5280 3742 4654 19531 3508 3446 5800 1012 1996 16902 103 7169 15321 2239 6693 103 15321 103 3302 4654 19531 103 3446 5800 2001 2036 2179 7408 3468 1012 1996 6693 10958 27404 3849 3623 2007 16922 19536 1012 2426 1996 2536 4127 103 4475 8494 103 2265 3020 6693 2119 10958 5280 1998 103 2239 1012 2122 3463 6592 103 103 5800 1996 9884 1996 3506 24657 2200 103 6691 1996 7169 10958 5280 15321 2239 7265 103 1996 102 10958 5280 1998 15321 2239 103 2001 2179 3020 3506 2485 9753 27069 103 2007 2216 8736 2185 3923 2181 1012 103 9358 103 3506 103 10958 5280 6693 3618 2084 1996 4431 5787 16250 24582 14536 1012 102\n",
            "I0706 05:53:26.551954 140503448741760 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.552093 140503448741760 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:53:26.552521 140503448741760 create_pretraining_data.py:161] masked_lm_positions: 17 22 24 28 40 51 54 62 68 69 75 77 85 86 94 102 110 112 114 0\n",
            "I0706 05:53:26.552645 140503448741760 create_pretraining_data.py:161] masked_lm_ids: 2090 1998 2239 3508 5280 2311 3506 15321 2008 1996 2038 2210 6693 4102 6693 7831 2566 1996 3662 0\n",
            "I0706 05:53:26.552756 140503448741760 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:53:26.552844 140503448741760 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.527620 140088198449024 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "I0706 05:54:50.527934 140088198449024 create_pretraining_data.py:459]   pretraining_data/shard_0000.tfrecord\n",
            "W0706 05:54:50.528198 140088198449024 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0706 05:54:50.529383 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.529642 140088198449024 create_pretraining_data.py:151] tokens: [CLS] chemistry group indira gandhi [MASK] [MASK] atomic research ka [MASK] ##ak [MASK] [MASK] [MASK] [MASK] ##nna [MASK] [MASK] group indira gandhi centre [MASK] ##sund research ka ##lp ##ak ##kam india reactor operation and maintenance group indira gandhi centre for atomic research ka ##lp ##ak ##kam india [MASK] [MASK] abstract article history received june received revised form july accepted july available online july thermal stability economist and ni [MASK] acids ##ol ##vate funeral [MASK] ##bu ##ty ##lal ##ky ##l and dip ##ent ##yla ##lk ##yl ph ##os ##phon ##ates was studied under closed air am ##bie ##nce using adi ##aba ##tic cal ##ori ##meter [SEP] en ##thal ##pies and kinetic parameters [MASK] the decomposition reaction were derived wherever possible and are reported for the first time . [SEP]\n",
            "I0706 05:54:50.529847 140088198449024 create_pretraining_data.py:161] input_ids: 101 6370 2177 28232 12338 103 103 9593 2470 10556 103 4817 103 103 103 103 9516 103 103 2177 28232 12338 2803 103 25168 2470 10556 14277 4817 27052 2634 13308 3169 1998 6032 2177 28232 12338 2803 2005 9593 2470 10556 14277 4817 27052 2634 103 103 10061 3720 2381 2363 2238 2363 8001 2433 2251 3970 2251 2800 3784 2251 9829 9211 11708 1998 9152 103 12737 4747 16952 6715 103 8569 3723 13837 4801 2140 1998 16510 4765 23943 13687 8516 6887 2891 20846 8520 2001 3273 2104 2701 2250 2572 11283 5897 2478 27133 19736 4588 10250 10050 22828 102 4372 24090 13046 1998 20504 11709 103 1996 22511 4668 2020 5173 11210 2825 1998 2024 2988 2005 1996 2034 2051 1012 102\n",
            "I0706 05:54:50.530014 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.530191 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.530307 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 5 6 10 12 13 14 15 17 18 23 24 47 48 58 65 68 72 73 111 0\n",
            "I0706 05:54:50.530410 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2803 2005 14277 27052 2634 10164 14115 3507 6370 2005 9593 3720 18558 3970 15708 12412 2094 4487 2005 0\n",
            "I0706 05:54:50.530519 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.530616 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.531310 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.531518 140088198449024 create_pretraining_data.py:151] tokens: [CLS] be [MASK] metals thermal activation plays large role the motion screw di ##sl ##ocation reigning over the high [MASK] ##er ##ls stress low [MASK] even [MASK] temperatures the role deer ##er ##ls stress may significant other thermal ##ly activated deformation mechanism effective . [SEP] the ##rm ##oco ##up [MASK] attached the secondary capsule [MASK] sealed into [MASK] fl ##ange separately . [MASK] final [MASK] [MASK] consisting the capsule lead tubes wasted closure fl ##ange shown figure . vertical ir ##rad ##iation facility the requirement for performing the [MASK] ##rad ##iation the capsule the vertical position necessitated modification the b ##gr ##r . [MASK] was vertical test facility significant flux [MASK] [MASK] . was therefore decided drill vertical hole figure . exploded view modified shielding blocks . [SEP]\n",
            "I0706 05:54:50.531707 140088198449024 create_pretraining_data.py:161] input_ids: 101 2022 103 11970 9829 13791 3248 2312 2535 1996 4367 11224 4487 14540 23909 16323 2058 1996 2152 103 2121 4877 6911 2659 103 2130 103 7715 1996 2535 8448 2121 4877 6911 2089 3278 2060 9829 2135 8878 29130 7337 4621 1012 102 1996 10867 24163 6279 103 4987 1996 3905 18269 103 10203 2046 103 13109 22043 10329 1012 103 2345 103 103 5398 1996 18269 2599 10868 13842 8503 13109 22043 3491 3275 1012 7471 20868 12173 18963 4322 1996 9095 2005 4488 1996 103 12173 18963 1996 18269 1996 7471 2597 29611 14080 1996 1038 16523 2099 1012 103 2001 7471 3231 4322 3278 19251 103 103 1012 2001 3568 2787 12913 7471 4920 3275 1012 9913 3193 6310 25553 5991 1012 102\n",
            "I0706 05:54:50.531872 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.532021 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.532123 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 2 6 15 19 24 26 30 45 49 54 57 62 64 65 71 88 103 110 111 0\n",
            "I0706 05:54:50.532247 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2278 3248 2015 26850 7715 8319 26850 1996 4244 2024 1996 1996 18269 3320 1998 20868 2045 2504 2800 0\n",
            "I0706 05:54:50.532358 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.532447 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.533096 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.533347 140088198449024 create_pretraining_data.py:151] tokens: [CLS] the temperature was rising approximately per second the time the [MASK] ##rm ##osta ##t closed indicating the ##rm ##osta ##t power watts and [MASK] power ki [MASK] ##att ##s [MASK] however [MASK] [MASK] was inserted rapidly that the total [MASK] generation ##kovsky rather small . the total temperature increase the [MASK] ##rm ##osta ##t was only and resulted from the generation only watts ##ec ##ond ##s italics . during [MASK] rapid rise and fall power the flux undergoes excursion that [SEP] this value higher than [MASK] value . obtained [MASK] resist ##ivity measurements change slope [MASK] . this difference [MASK] because the sink structure for va ##can ##cies ##河 dependent the aging temperature and [MASK] not constant [MASK] the cross ##cut method has beer applied . [SEP]\n",
            "I0706 05:54:50.533943 140088198449024 create_pretraining_data.py:161] input_ids: 101 1996 4860 2001 4803 3155 2566 2117 1996 2051 1996 103 10867 28696 2102 2701 8131 1996 10867 28696 2102 2373 11042 1998 103 2373 11382 103 19321 2015 103 2174 103 103 2001 12889 5901 2008 1996 2561 103 4245 23829 2738 2235 1012 1996 2561 4860 3623 1996 103 10867 28696 2102 2001 2069 1998 4504 2013 1996 4245 2069 11042 8586 15422 2015 19408 1012 2076 103 5915 4125 1998 2991 2373 1996 19251 29129 26144 2008 102 2023 3643 3020 2084 103 3643 1012 4663 103 9507 7730 11702 2689 9663 103 1012 2023 4489 103 2138 1996 7752 3252 2005 12436 9336 9243 30425 7790 1996 12520 4860 1998 103 2025 5377 103 1996 2892 12690 4118 2038 5404 4162 1012 102\n",
            "I0706 05:54:50.534117 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.534301 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.534412 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 11 18 24 27 30 32 33 40 42 51 67 70 86 90 96 100 109 115 118 0\n",
            "I0706 05:54:50.534515 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 1996 10867 13308 8261 1012 1996 9947 2373 2001 1996 2943 2023 1996 2013 4118 18653 2993 6516 2073 0\n",
            "I0706 05:54:50.534621 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.534720 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.535382 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.535562 140088198449024 create_pretraining_data.py:151] tokens: [CLS] babu nuclear engineering and [MASK] vacuum pump . pipe plate tube et ##si . [SEP] sp rajasthan ion pump the [MASK] ##utter ion pump another vital component this [MASK] [MASK] instrumentation system . apart from the usual pumping characteristics [MASK] sp ##utter ion pump [MASK] normal vacuum applications very high stability with ion current flaming long period time under continuous operation required for this application any momentary [MASK] [MASK] value interpreted leak signal integral required safety action reactor initiated . [SEP]\n",
            "I0706 05:54:50.535840 140088198449024 create_pretraining_data.py:161] input_ids: 101 20948 4517 3330 1998 103 11641 10216 1012 8667 5127 7270 3802 5332 1012 102 11867 16815 10163 10216 1996 103 26878 10163 10216 2178 8995 6922 2023 103 103 16015 2291 1012 4237 2013 1996 5156 14107 6459 103 11867 26878 10163 10216 103 3671 11641 5097 2200 2152 9211 2007 10163 2783 19091 2146 2558 2051 2104 7142 3169 3223 2005 2023 4646 2151 29089 103 103 3643 10009 17271 4742 9897 3223 3808 2895 13308 7531 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.536016 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.536194 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.536306 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 5 17 21 29 30 40 45 51 55 68 69 74 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.536409 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2640 26878 11867 17271 10788 1996 2005 9211 2058 3623 2049 1998 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.536512 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.536603 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.537291 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.537496 140088198449024 create_pretraining_data.py:151] tokens: [CLS] the treated [MASK] [MASK] portland cement mortar which cast into [MASK] ##res ##istan ##t [MASK] containers for disposal fly ash water cd ##li cement waste salt extract non ##ta ##u salt en ##cap [MASK] swelling [MASK] [SEP] the uranium about half that required for plants ##cal ##e electro ##re ##fine ##r serving mw ##e if gina capacity the purposes the large ##sca ##le unit [MASK] ##љ fuel dissolution [MASK] uranium per cat toilet ##de and product handling establish the duty cycle [MASK] the electro ##re ##fin ##ing unit and evaluate equipment performance the equipment expected operation the [MASK] [MASK] ##l applied physical chemistry the program [MASK] ph ##ys ##ica chemistry involves studies the the ##rm ##oche ##mic ##al and the ##rm [MASK] ##hy ##sic ##al behavior [SEP]\n",
            "I0706 05:54:50.537672 140088198449024 create_pretraining_data.py:161] input_ids: 101 1996 5845 103 103 6734 11297 14335 2029 3459 2046 103 6072 23137 2102 103 16143 2005 13148 4875 6683 2300 3729 3669 11297 5949 5474 14817 2512 2696 2226 5474 4372 17695 103 18348 103 102 1996 14247 2055 2431 2008 3223 2005 4264 9289 2063 16175 2890 23460 2099 3529 12464 2063 2065 17508 3977 1996 5682 1996 2312 15782 2571 3131 103 29762 4762 12275 103 14247 2566 4937 11848 3207 1998 4031 8304 5323 1996 4611 5402 103 1996 16175 2890 16294 2075 3131 1998 16157 3941 2836 1996 3941 3517 3169 1996 103 103 2140 4162 3558 6370 1996 2565 103 6887 7274 5555 6370 7336 2913 1996 1996 10867 23555 7712 2389 1998 1996 10867 103 10536 19570 2389 5248 102\n",
            "I0706 05:54:50.537853 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.538003 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.538107 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 3 4 5 11 15 34 36 56 65 66 69 73 81 82 87 98 99 106 122 0\n",
            "I0706 05:54:50.538226 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 5474 15484 6734 24625 3384 2302 15729 2099 2024 10580 19806 6806 5402 2005 2075 3500 6819 4162 7361 0\n",
            "I0706 05:54:50.538338 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.538429 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.539055 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.539263 140088198449024 create_pretraining_data.py:151] tokens: [CLS] [MASK] and the importance the [MASK] plant operation most class items are [MASK] ##con ##tro ##lling indirect sense they may not require immediate reactor shut ##down but eventually the loss [MASK] handling capability will require ##oder ##down careful scheduling and planning [MASK] class maintenance limit plant down ##time for these items [MASK] components maintenance external fuel ##hand ##ling components controlled cards ##ched ##ulin ##g [MASK] [SEP] the [MASK] deviation [MASK] base value . oh ##m . oh ##m . on ##i rt ##rd an ##e n ##nl ##ns ##nn ##t [MASK] ##igen ##nr ##tt ##nan ##lt ra [MASK] et ##ree . resistance [MASK] standard resist ##or using the electronics for over [MASK] [MASK] [SEP]\n",
            "I0706 05:54:50.539442 140088198449024 create_pretraining_data.py:161] input_ids: 101 103 1998 1996 5197 1996 103 3269 3169 2087 2465 5167 2024 103 8663 13181 13112 14958 3168 2027 2089 2025 5478 6234 13308 3844 7698 2021 2776 1996 3279 103 8304 10673 2097 5478 27381 7698 6176 19940 1998 4041 103 2465 6032 5787 3269 2091 7292 2005 2122 5167 103 6177 6032 6327 4762 11774 2989 6177 4758 5329 7690 18639 2290 103 102 1996 103 24353 103 2918 3643 1012 2821 2213 1012 2821 2213 1012 2006 2072 19387 4103 2019 2063 1050 20554 3619 10695 2102 103 29206 16118 4779 7229 7096 10958 103 3802 9910 1012 5012 103 3115 9507 2953 2478 1996 8139 2005 2058 103 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.539601 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.539758 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.539865 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 1 6 13 31 36 42 52 53 65 68 70 91 98 103 111 112 113 0 0 0\n",
            "I0706 05:54:50.627685 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 11433 3941 3269 4762 3844 2005 6327 6177 2291 3115 1996 16118 2140 5436 2058 2558 1012 0 0 0\n",
            "I0706 05:54:50.627948 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.628060 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.628823 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.629072 140088198449024 create_pretraining_data.py:151] tokens: [CLS] the coating ##s thickness ranges from with [MASK] exception the [MASK] ##dr ##ites which can high . [MASK] composition the deposit varies across [MASK] cross [MASK] with some [MASK] diffusion bo ##ron [MASK] [MASK] substrate measured ed ##x . [MASK] the exception the den ##dr ##ites the composition stable relation the layer . den ##dr ##ites ##well oxygen [MASK] carbon imp ##urities some [MASK] may found the surface . the rough ##ness the coating ##s [MASK] been studied af ##m [MASK] the values depend ##ant grandmother time electro ##lysis . longer times bigger crystals are formed ##₤ therefore the rough ##ness the [SEP] b ##hat ##ta ##cha ##rya water quality management the lower stretch the river [MASK] ##es east coast india approach through environmental education . [SEP]\n",
            "I0706 05:54:50.629293 140088198449024 create_pretraining_data.py:161] input_ids: 101 1996 18898 2015 14983 8483 2013 2007 103 6453 1996 103 13626 7616 2029 2064 2152 1012 103 5512 1996 12816 9783 2408 103 2892 103 2007 2070 103 19241 8945 4948 103 103 16305 7594 3968 2595 1012 103 1996 6453 1996 7939 13626 7616 1996 5512 6540 7189 1996 6741 1012 7939 13626 7616 4381 7722 103 6351 17727 29366 2070 103 2089 2179 1996 3302 1012 1996 5931 2791 1996 18898 2015 103 2042 3273 21358 2213 103 1996 5300 12530 4630 7133 2051 16175 26394 1012 2936 2335 7046 14438 2024 2719 30100 3568 1996 5931 2791 1996 102 1038 12707 2696 7507 20444 2300 3737 2968 1996 2896 7683 1996 2314 103 2229 2264 3023 2634 3921 2083 4483 2495 1012 102\n",
            "I0706 05:54:50.629472 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.629637 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.629755 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 8 11 18 24 26 29 33 34 35 40 57 59 64 76 77 81 86 97 117 0\n",
            "I0706 05:54:50.629856 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 1996 7939 1996 1996 29015 7704 2046 1996 16305 2007 2070 1998 3572 2038 2042 2108 1996 4852 6080 0\n",
            "I0706 05:54:50.629959 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.630053 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.630746 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.630947 140088198449024 create_pretraining_data.py:151] tokens: [CLS] mw ##m to ##gt . [SEP] another [MASK] experiments was observed [MASK] leach ##ing [MASK] addition fresh water interval half ##an ##ho ##ur was sufficient [MASK] the an ##ion ##ic imp [MASK] below pp ##m ##iji ##ron powder . kong rate removal flu ##ori [MASK] imp ##urity was found higher [MASK] that te [MASK] ##fl ##uo ##ro ##bor ##ate [unused577] ##urities with the increase toni . attempt was made increase the leach ##ing temperature beyond [MASK] surface oxidation bo ##ron powder which may [MASK] the formation [MASK] ##ric [MASK] ##bor ##ic acid . milling bo ##ron fl ##akes and ag ##gl ##ome [MASK] since bo ##ron powder ab ##ras ##ive nature gets contaminated with tung ##sten during milling [MASK] [SEP]\n",
            "I0706 05:54:50.631131 140088198449024 create_pretraining_data.py:161] input_ids: 101 12464 2213 2000 13512 1012 102 2178 103 7885 2001 5159 103 24520 2075 103 2804 4840 2300 13483 2431 2319 6806 3126 2001 7182 103 1996 2019 3258 2594 17727 103 2917 4903 2213 27821 4948 9898 1012 4290 3446 8208 19857 10050 103 17727 25137 2001 2179 3020 103 2008 8915 103 10258 19098 3217 12821 3686 582 29366 2007 1996 3623 16525 1012 3535 2001 2081 3623 1996 24520 2075 4860 3458 103 3302 19577 8945 4948 9898 2029 2089 103 1996 4195 103 7277 103 12821 2594 5648 1012 22491 8945 4948 13109 20060 1998 12943 23296 8462 103 2144 8945 4948 9898 11113 8180 3512 3267 4152 19450 2007 27079 16173 2076 22491 103 102 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.631312 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.631464 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.631573 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 8 12 15 26 32 36 40 45 51 54 60 65 76 84 87 89 103 119 0 0\n",
            "I0706 05:54:50.631673 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2275 2008 2007 5547 29366 8945 1996 3207 2084 6494 17727 4860 18478 2765 8945 15772 20370 1012 0 0\n",
            "I0706 05:54:50.631894 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I0706 05:54:50.631988 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.632650 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.632866 140088198449024 create_pretraining_data.py:151] tokens: [CLS] par ##vat ##ha ##var ##thi ##inus journal nuclear [MASK] fig [MASK] [SEP] have implications the pursuit designing new and novel materials . this paper the race for synth ##es ##izing [MASK] which can det ##hr ##one diamond will highlighted . results some low compounds ni ##tri ##des car ##bid ##es and [MASK] ##ride ##s transition metals h ##yp ##oth ##es ##ized harder than diamond [MASK] described . efforts will made list down [MASK] important parameters [MASK] [MASK] making solid strong and then arrive possible ideal recipe for its synthesis . key ##words super ##hard [MASK] high pressure synthesis [MASK] ideal strength . plan [MASK] . [MASK] skinner solids diamond poly ##mo ##rp ##hs sign ##q bc ##n compounds . [MASK] remarks recipe for future [MASK] author [SEP]\n",
            "I0706 05:54:50.633035 140088198449024 create_pretraining_data.py:161] input_ids: 101 11968 22879 3270 10755 15222 13429 3485 4517 103 20965 103 102 2031 13494 1996 8463 12697 2047 1998 3117 4475 1012 2023 3259 1996 2679 2005 24203 2229 6026 103 2029 2064 20010 8093 5643 6323 2097 11548 1012 3463 2070 2659 10099 9152 18886 6155 2482 17062 2229 1998 103 15637 2015 6653 11970 1044 22571 14573 2229 3550 6211 2084 6323 103 2649 1012 4073 2097 2081 2862 2091 103 2590 11709 103 103 2437 5024 2844 1998 2059 7180 2825 7812 17974 2005 2049 10752 1012 3145 22104 3565 11783 103 2152 3778 10752 103 7812 3997 1012 2933 103 1012 103 17451 26778 6323 26572 5302 14536 7898 3696 4160 4647 2078 10099 1012 103 12629 17974 2005 2925 103 3166 102\n",
            "I0706 05:54:50.633215 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.633373 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.633478 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 6 7 9 11 31 38 52 65 73 76 77 95 99 104 106 107 112 120 125 0\n",
            "I0706 05:54:50.633573 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 3490 3485 4475 1012 3430 2097 8945 2097 2070 2008 2046 4475 23608 3720 23191 2844 14536 16228 7978 0\n",
            "I0706 05:54:50.633676 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.633776 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.634438 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.634641 140088198449024 create_pretraining_data.py:151] tokens: [CLS] rec ##rys ##tal ##lized . variation shear wave velocity ratio [MASK] with extent rec [MASK] ##tal ##lis ##ation alloy ultra ##sonic at ##ten ##uation the influence [MASK] work the ultra ##sonic at [MASK] ##uation different directions was evaluated austen ##ti ##tic stainless ≤ the at ##ten ##uation rolling and transverse directions increased slightly after small amount cold work and [MASK] decreased with further increase tumble work . the decrease at ##ten ##uation with cold [MASK] all directions was attributed the reduced scattering [SEP] [MASK] [MASK] enables formation texture thigh results reduced mis [MASK] ##entation among adjacent grains rotation grains [MASK] the strain [MASK] [MASK] scattering reduced due the reduction the mis ##ori ##entation between adjacent grains which enables the [MASK] channel ##led through the [MASK] yelling [SEP]\n",
            "I0706 05:54:50.634841 140088198449024 create_pretraining_data.py:161] input_ids: 101 28667 24769 9080 28931 1012 8386 18330 4400 10146 6463 103 2007 6698 28667 103 9080 6856 3370 17564 11087 18585 2012 6528 14505 1996 3747 103 2147 1996 11087 18585 2012 103 14505 2367 7826 2001 16330 24177 3775 4588 18676 1608 1996 2012 6528 14505 5291 1998 18323 7826 3445 3621 2044 2235 3815 3147 2147 1998 103 10548 2007 2582 3623 28388 2147 1012 1996 9885 2012 6528 14505 2007 3147 103 2035 7826 2001 7108 1996 4359 17501 102 103 103 12939 4195 14902 10120 3463 4359 28616 103 19304 2426 5516 17588 9963 17588 103 1996 10178 103 103 17501 4359 2349 1996 7312 1996 28616 10050 19304 2090 5516 17588 2029 12939 1996 103 3149 3709 2083 1996 103 13175 102\n",
            "I0706 05:54:50.634998 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.635140 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.635270 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 11 15 27 33 34 43 60 65 75 84 85 89 93 100 103 104 120 125 126 0\n",
            "I0706 05:54:50.635372 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 16381 24769 3147 6528 14505 3886 2059 3147 2147 3147 2551 2029 10050 8752 1012 1996 7504 11375 1012 0\n",
            "I0706 05:54:50.635473 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.635562 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.636214 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.636426 140088198449024 create_pretraining_data.py:151] tokens: [CLS] predict ##s for the z ##bri ##ii opposed the adjusted sera value based the experimental [MASK] available would appear that the do ##pp ##ler coe ##ffi fast core would ci ##ent [MASK] highly enriched not [MASK] greater than and for pluto [MASK] ‚ roughly twice that value room temperature for other temperatures beth ##e applies the following [MASK] ta ##w hence for higher temperatures the do [MASK] ##ler [MASK] [MASK] even smaller for example for the z [MASK] ##iii the upper limit [SEP] model ned 168 . che [MASK] ##pan ##di nuclear engineering [MASK] design xx ##x xx ##xx ##xx ve ##rs ##u vp ##sp ##sp hr ##su vest hp ##sp ##sp [MASK] ##s vin ##x ##sp vr [MASK] hi [MASK] ##sp hi ##nx [MASK] . [SEP]\n",
            "I0706 05:54:50.636603 140088198449024 create_pretraining_data.py:161] input_ids: 101 16014 2015 2005 1996 1062 23736 6137 4941 1996 10426 26358 3643 2241 1996 6388 103 2800 2052 3711 2008 1996 2079 9397 3917 24873 26989 3435 4563 2052 25022 4765 103 3811 25202 2025 103 3618 2084 1998 2005 26930 103 1522 5560 3807 2008 3643 2282 4860 2005 2060 7715 7014 2063 12033 1996 2206 103 11937 2860 6516 2005 3020 7715 1996 2079 103 3917 103 103 2130 3760 2005 2742 2005 1996 1062 103 28954 1996 3356 5787 102 2944 12311 16923 1012 18178 103 9739 4305 4517 3330 103 2640 22038 2595 22038 20348 20348 2310 2869 2226 21210 13102 13102 17850 6342 17447 6522 13102 13102 103 2015 19354 2595 13102 27830 103 7632 103 13102 7632 26807 103 1012 102\n",
            "I0706 05:54:50.636766 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.636924 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.637028 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 11 16 32 36 42 43 58 67 69 70 78 86 89 94 113 116 119 121 125 0\n",
            "I0706 05:54:50.637128 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 6388 2951 2005 2172 14907 2291 25169 9397 19064 2052 18098 5530 4571 1998 17850 2595 13699 8528 13102 0\n",
            "I0706 05:54:50.637255 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.637348 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.637958 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.638099 140088198449024 create_pretraining_data.py:151] tokens: [CLS] mo ##oe soo ##so [MASK] ##o [MASK] ##e [MASK] sub ##rou ##tine input listing . [SEP] can seen that [MASK] applied current will divided three part . [SEP]\n",
            "I0706 05:54:50.638280 140088198449024 create_pretraining_data.py:161] input_ids: 101 9587 8913 17111 6499 103 2080 103 2063 103 4942 22494 10196 7953 10328 1012 102 2064 2464 2008 103 4162 2783 2097 4055 2093 2112 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.638439 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.638590 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.638692 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 5 7 9 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.638802 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 9541 19413 3275 2561 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.638906 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.638994 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.639621 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.639836 140088198449024 create_pretraining_data.py:151] tokens: [CLS] ass [MASK] aspects ph [MASK] ##n injection induced none ##quil treaty ##rium super ##con ##du ##ct ##ivity quasi [MASK] ##tic ##le energy which [MASK] pro ##ba ##bilities quasi ##par ##tic ##le rec ##om ##bina ##tion and relaxation viz . [SEP] ##n pill ##ai corrosion reviews [MASK] [MASK] should find place the design and operation components . the di ##sso ##ciation pressures technological ##ly important oxide [MASK] [MASK] the range atm . the highest vacuum that can achieved can imp ##art [MASK] potential higher than this [MASK] [MASK] [MASK] generate these oxide ##s the metal surface [MASK] there are certain gas e [MASK] [MASK] ##ria that can promote the existence very low oxygen pressures . very low [MASK] pressures are [MASK] encountered the inter ##space ##s oxide [SEP]\n",
            "I0706 05:54:50.730440 140088198449024 create_pretraining_data.py:161] input_ids: 101 4632 103 5919 6887 103 2078 13341 10572 3904 26147 5036 18802 3565 8663 8566 6593 7730 17982 103 4588 2571 2943 2029 103 4013 3676 14680 17982 19362 4588 2571 28667 5358 21114 3508 1998 23370 26619 1012 102 2078 17357 4886 24625 4391 103 103 2323 2424 2173 1996 2640 1998 3169 6177 1012 1996 4487 24137 23247 15399 10660 2135 2590 15772 103 103 1996 2846 27218 1012 1996 3284 11641 2008 2064 4719 2064 17727 8445 103 4022 3020 2084 2023 103 103 103 9699 2122 15772 2015 1996 3384 3302 103 2045 2024 3056 3806 1041 103 103 4360 2008 2064 5326 1996 4598 2200 2659 7722 15399 1012 2200 2659 103 15399 2024 103 8567 1996 6970 23058 2015 15772 102\n",
            "I0706 05:54:50.730745 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.730919 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.731030 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 2 5 11 19 24 46 47 66 67 81 86 87 88 96 102 103 105 117 120 0\n",
            "I0706 05:54:50.731138 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 15613 17175 12322 19362 1996 18960 4824 2015 2024 7722 3643 1998 2947 1012 26147 12322 2008 7722 2036 0\n",
            "I0706 05:54:50.731294 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.731389 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.732125 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.732389 140088198449024 create_pretraining_data.py:151] tokens: [CLS] trademark breed [MASK] reactor estimate the fuel cost can made for [MASK] various fuel ##ele ##ment diameter ##s since both [MASK] and total mass uranium are known . the analysis revealed little change cost over the [MASK] fuel ##ele ##ment [MASK] ##s interest that economics could not con ##st [MASK] basis for selection fuel ##ele ##ment [MASK] without substantial ref ##ine ##ment the [SEP] turbulent natural convection standard turbulence model square enclosure simple algorithm . introduction nuclear power [MASK] have many inter ##connected owes similar [MASK] power plants . these [MASK] house equipment and instruments which are [MASK] 西 the safe operation the plant [MASK] they invariably contain significant quantities comb [MASK] ##ible materials such [MASK] sodium electrical [MASK] fuel and lu ##bri ##cation oils and [SEP]\n",
            "I0706 05:54:50.732576 140088198449024 create_pretraining_data.py:161] input_ids: 101 11749 8843 103 13308 10197 1996 4762 3465 2064 2081 2005 103 2536 4762 12260 3672 6705 2015 2144 2119 103 1998 2561 3742 14247 2024 2124 1012 1996 4106 3936 2210 2689 3465 2058 1996 103 4762 12260 3672 103 2015 3037 2008 5543 2071 2025 9530 3367 103 3978 2005 4989 4762 12260 3672 103 2302 6937 25416 3170 3672 1996 102 22609 3019 23849 3115 29083 2944 2675 17539 3722 9896 1012 4955 4517 2373 103 2031 2116 6970 24230 24381 2714 103 2373 4264 1012 2122 103 2160 3941 1998 5693 2029 2024 103 1947 1996 3647 3169 1996 3269 103 2027 26597 5383 3278 12450 22863 103 7028 4475 2107 103 13365 5992 103 4762 1998 11320 23736 10719 20631 1998 102\n",
            "I0706 05:54:50.732741 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.732907 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.733011 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 1 3 12 21 37 41 50 57 79 84 86 91 97 98 99 105 112 116 119 0\n",
            "I0706 05:54:50.733109 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 12981 2121 1996 27226 2846 6705 28551 6705 4264 3121 2060 3121 2024 6827 2005 1012 19966 6381 15196 0\n",
            "I0706 05:54:50.733234 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.733337 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.734051 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.734288 140088198449024 create_pretraining_data.py:151] tokens: [CLS] [MASK] ##s method drinking spaced ##ep ##end ##ent fast reactor core d [MASK] ##mi um ##eric ##a foe [MASK] or [MASK] ts ##h di ##ss [MASK] ##oof og ##z o ##ces or ##da . er ##t vivo [MASK] ##vna ##c [MASK] ##wu ##ah ow ##wat ##lt . [SEP] ph ##wr fuel pin sub [MASK] ##mb ##ly the electrode ##s squeeze current [MASK] for ##ging hold time [MASK] lift [MASK] . various types acoustic emission signals are known produced during these [MASK] . [MASK] features ##para ##meter ##s the signal generated can related the factors we ##ld quality . recent years artificial cathy networks the hidden layer . can soo that for most the prediction classification problems single hidden layer sufficient map the classification [MASK] problem vol [SEP]\n",
            "I0706 05:54:50.734477 140088198449024 create_pretraining_data.py:161] input_ids: 101 103 2015 4118 5948 19835 13699 10497 4765 3435 13308 4563 1040 103 4328 8529 22420 2050 22277 103 2030 103 24529 2232 4487 4757 103 21511 13958 2480 1051 9623 2030 2850 1012 9413 2102 24269 103 29207 2278 103 16050 4430 27593 24281 7096 1012 102 6887 13088 4762 9231 4942 103 14905 2135 1996 28688 2015 11025 2783 103 2005 4726 2907 2051 103 6336 103 1012 2536 4127 6490 15760 7755 2024 2124 2550 2076 2122 103 1012 103 2838 28689 22828 2015 1996 4742 7013 2064 3141 1996 5876 2057 6392 3737 1012 3522 2086 7976 18305 6125 1996 5023 6741 1012 2064 17111 2008 2005 2087 1996 17547 5579 3471 2309 5023 6741 7182 4949 1996 5579 103 3291 5285 102\n",
            "I0706 05:54:50.734631 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.734788 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.734898 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 1 4 7 13 19 20 21 26 38 41 54 62 67 69 81 83 102 109 124 0\n",
            "I0706 05:54:50.734996 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 24582 2005 10497 18279 3619 2030 2102 7570 2219 27593 27241 4834 1998 7245 5711 1996 15756 3264 17547 0\n",
            "I0706 05:54:50.735100 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.735206 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.735843 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.736051 140088198449024 create_pretraining_data.py:151] tokens: [CLS] the case [MASK] ##ld joint due the temperatures ##ens [MASK] nature modified cr ##mo steel the micro ##st ##ru ##cture not [MASK] across the we ##ld joint . [SEP] differing mechanical properties . hence the extent [MASK] each micro ##st ##ru ##ct ##ural zone . [MASK] amount and [MASK] the plastic strain accumulated would different different micro [MASK] ##ru ##ct ##ural zones because the variations their [MASK] strengths . [MASK] would simpsons adjustments between parades neighboring zones accommodate the accumulated plastic strain given [MASK] until balance achieved . hence [MASK] creep damage that occurs during [MASK] [MASK] hold would acc [MASK] ##mo ##dating ##ァ plastic strain accumulated during the form micro ##st ##ru ##ct ##ural rear ##rang ##ement ##s such formation cells and [MASK] ##gra ##ins [SEP]\n",
            "I0706 05:54:50.736254 140088198449024 create_pretraining_data.py:161] input_ids: 101 1996 2553 103 6392 4101 2349 1996 7715 6132 103 3267 6310 13675 5302 3886 1996 12702 3367 6820 14890 2025 103 2408 1996 2057 6392 4101 1012 102 16965 6228 5144 1012 6516 1996 6698 103 2169 12702 3367 6820 6593 11137 4224 1012 103 3815 1998 103 1996 6081 10178 14830 2052 2367 2367 12702 103 6820 6593 11137 10019 2138 1996 8358 2037 103 20828 1012 103 2052 19047 24081 2090 26635 8581 10019 8752 1996 14830 6081 10178 2445 103 2127 5703 4719 1012 6516 103 19815 4053 2008 5158 2076 103 103 2907 2052 16222 103 5302 16616 30218 6081 10178 14830 2076 1996 2433 12702 3367 6820 6593 11137 4373 24388 13665 2015 2107 4195 4442 1998 103 17643 7076 102\n",
            "I0706 05:54:50.736427 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.736622 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.736736 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 2 3 10 22 37 46 49 58 67 70 72 75 84 90 96 97 101 104 124 0\n",
            "I0706 05:54:50.736836 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2553 2057 13043 6375 2367 1996 6516 3367 6228 2045 2334 1996 3872 1996 1996 4646 5358 1996 4942 0\n",
            "I0706 05:54:50.736941 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.737030 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.737672 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.737851 140088198449024 create_pretraining_data.py:151] tokens: [CLS] pow eh [MASK] lower tor ##s sy ##eer tee ##rs ##ses dye stacy state te ##vi ##per [MASK] ##ures . shell side se ##dium q ##oof barre ##t sip ##e . so ##pi ##uo [MASK] far ##rk ##l so ##e cn ##et shri . par ##rel wave re ##t tape ##re [MASK] ##her [MASK] ##cr ##it via ##k [MASK] [SEP] the results obtained are compared with numerical results fran ##ds [MASK] . [SEP]\n",
            "I0706 05:54:50.738024 140088198449024 create_pretraining_data.py:161] input_ids: 101 23776 15501 103 2896 17153 2015 25353 11510 17170 2869 8583 18554 18566 2110 8915 5737 4842 103 14900 1012 5806 2217 7367 12811 1053 21511 23189 2102 10668 2063 1012 2061 8197 19098 103 2521 8024 2140 2061 2063 27166 3388 14880 1012 11968 16570 4400 2128 2102 6823 2890 103 5886 103 26775 4183 3081 2243 103 102 1996 3463 4663 2024 4102 2007 15973 3463 23151 5104 103 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.738201 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.738357 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.738461 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 2 3 18 34 35 47 52 54 55 59 71 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.738562 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 15501 2595 4017 19098 2213 4400 21183 18798 26775 1012 2368 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.738664 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.738766 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.739416 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.739591 140088198449024 create_pretraining_data.py:151] tokens: [CLS] [MASK] element composition titanium ##sta ##bil [MASK] austen [MASK] stainless steel . [SEP] incident and scattered energies and respectively are computed using the x ##com program which can generate [MASK] cross sections for scattering photo [MASK] ##ctric absorption and pair production well total at ##ten ##uation coefficients for any element [MASK] [MASK] fig . measured counts function [MASK] height glass [MASK] for g [MASK] ##cer ##ino ##li ##ve oil column [MASK] [SEP]\n",
            "I0706 05:54:50.739767 140088198449024 create_pretraining_data.py:161] input_ids: 101 103 5783 5512 23431 9153 14454 103 24177 103 18676 3886 1012 102 5043 1998 7932 19320 1998 4414 2024 24806 2478 1996 1060 9006 2565 2029 2064 9699 103 2892 5433 2005 17501 6302 103 22601 16326 1998 3940 2537 2092 2561 2012 6528 14505 21374 2005 2151 5783 103 103 20965 1012 7594 9294 3853 103 4578 3221 103 2005 1043 103 17119 5740 3669 3726 3514 5930 103 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.739920 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.740069 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.740191 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 1 7 9 30 36 51 52 58 61 64 71 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.740300 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 13794 3550 18291 26383 12260 7328 8150 7471 11661 2135 1012 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.740402 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.740490 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0706 05:54:50.741110 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.741338 140088198449024 create_pretraining_data.py:151] tokens: [CLS] average core figure relative core flow channel . sec [MASK] average ib ##se ##c core . ge ##ap ##s conditioning full [MASK] full [MASK] temperature lower [MASK] [MASK] [MASK] shield ee ##e [MASK] _ _ see with lower shield average core ʌ relative core flow channel . [SEP] without shield with she ##lo with lower shield [MASK] [MASK] extension rod flow channel . ge ##ap dump full assembly temperature without lower shield with lower shield . channel cab fl ##e [MASK] lo ##a si ##e lower shield sts ##n ya ##ad sm ##ut [MASK] any mt ##ho ##ut wee lower br [MASK] shield sm ##eal [MASK] ##e average core [MASK] relative extension rod flow channel ste ##en ec ##m . ib [MASK] ##c channel average ib [SEP]\n",
            "I0706 05:54:50.837574 140088198449024 create_pretraining_data.py:161] input_ids: 101 2779 4563 3275 5816 4563 4834 3149 1012 10819 103 2779 21307 3366 2278 4563 1012 16216 9331 2015 14372 2440 103 2440 103 4860 2896 103 103 103 6099 25212 2063 103 1035 1035 2156 2007 2896 6099 2779 4563 1134 5816 4563 4834 3149 1012 102 2302 6099 2007 2016 4135 2007 2896 6099 103 103 5331 8473 4834 3149 1012 16216 9331 15653 2440 3320 4860 2302 2896 6099 2007 2896 6099 1012 3149 9298 13109 2063 103 8840 2050 9033 2063 2896 6099 8541 2078 8038 4215 15488 4904 103 2151 11047 6806 4904 16776 2896 7987 103 6099 15488 15879 103 2063 2779 4563 103 5816 5331 8473 4834 3149 26261 2368 14925 2213 1012 21307 103 2278 3149 2779 21307 102\n",
            "I0706 05:54:50.838027 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.838330 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0706 05:54:50.838553 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 1 10 20 22 24 27 28 29 33 42 57 58 66 81 94 102 106 110 122 0\n",
            "I0706 05:54:50.838746 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2779 4563 3231 3320 3320 6099 2007 2896 1035 3275 3275 5816 3231 2007 21348 2063 25212 3275 3366 0\n",
            "I0706 05:54:50.838942 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0706 05:54:50.839110 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:54:50.840276 140088198449024 create_pretraining_data.py:149] *** Example ***\n",
            "I0706 05:54:50.840559 140088198449024 create_pretraining_data.py:151] tokens: [CLS] ti [MASK] ti [MASK] ti ##o ti ##o ti boar [MASK] ##o ti ##o ti ##o ti ##o ti ##o ti [MASK] ti ##o ti ##o ti ##o f [MASK] [SEP] dec dec [MASK] [MASK] dec dec dec dec dec [MASK] dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec dec [SEP]\n",
            "I0706 05:54:50.840827 140088198449024 create_pretraining_data.py:161] input_ids: 101 14841 103 14841 103 14841 2080 14841 2080 14841 24187 103 2080 14841 2080 14841 2080 14841 2080 14841 2080 14841 103 14841 2080 14841 2080 14841 2080 1042 103 102 11703 11703 103 103 11703 11703 11703 11703 11703 103 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 11703 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.841049 140088198449024 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.841218 140088198449024 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.841327 140088198449024 create_pretraining_data.py:161] masked_lm_positions: 2 4 10 11 22 30 34 35 41 45 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.841459 140088198449024 create_pretraining_data.py:161] masked_lm_ids: 2080 2080 2080 14841 2080 7962 11703 11703 11703 11703 0 0 0 0 0 0 0 0 0 0\n",
            "I0706 05:54:50.841572 140088198449024 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0706 05:54:50.841659 140088198449024 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0706 05:58:01.107296 140503448741760 create_pretraining_data.py:166] Wrote 537984 total instances\n",
            "I0706 05:59:41.492139 140088198449024 create_pretraining_data.py:166] Wrote 679864 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh-umioj72xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "BUCKET_NAME = \"ayushjain1144-bucket\"\n",
        "MODEL_DIR = \"bert_model\"\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"Warning: no bucket\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAwgehFAEEbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = \"bert_model\"\n",
        "tf.gfile.MkDir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28sBjWx_Rrxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# hyperparameters for BERT BASE\n",
        "\n",
        "bert_base_config = {\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"directionality\": \"bidi\",\n",
        "    \"hidden_act\": \"gelu\",\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"hidden_size\": 768,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"intermediate_size\": 3072,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"pooler_fc_size\": 768,\n",
        "    \"pooler_num_attention_heads\": 12,\n",
        "    \"pooler_num_fc_layers\": 3,\n",
        "    \"pooler_size_per_head\": 128,\n",
        "    \"pooler_type\": \"first_token_transform\",\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX5ci_dk9g9e",
        "colab_type": "code",
        "outputId": "af11aba4-7ba9-4347-e9aa-ece99f5d11b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "!cp $BERT_CONFIG $MODEL_DIR/\n",
        "!cp $CHKPT_DIR $MODEL_DIR/\n",
        "!ls $MODEL_DIR/\n",
        "    \n",
        "with open(\"{}/bert_vocab.txt\".format(MODEL_DIR), \"w\") as vocab:\n",
        "    vocab_bert = open(VOCAB_FILE, 'r').read()\n",
        "    vocab.write(vocab_bert)\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json\t\t     bert_model.ckpt.index\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbzY0cjyL27Q",
        "colab_type": "code",
        "outputId": "f390c385-8d8c-41dd-f965-21be7ad685d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!cp -r $MODEL_DIR $PRETRAINING_DIR /mydrive/\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME/original/\n",
        "else:\n",
        "  print(\"Not able to copy\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_model/bert_config.json [Content-Type=application/json]...\n",
            "Copying file://bert_model/bert_vocab.txt [Content-Type=text/plain]...\n",
            "/ [0/7 files][    0.0 B/  1.4 GiB]   0% Done                                    \rCopying file://pretraining_data/shard_0000.tfrecord [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "/ [0/7 files][    0.0 B/  1.4 GiB]   0% Done                                    \r/ [0/7 files][    0.0 B/  1.4 GiB]   0% Done                                    \rCopying file://bert_model/bert_model.ckpt.meta [Content-Type=application/octet-stream]...\n",
            "/ [0/7 files][    0.0 B/  1.4 GiB]   0% Done                                    \rCopying file://pretraining_data/shard_0001.tfrecord [Content-Type=application/octet-stream]...\n",
            "/ [0/7 files][    0.0 B/  1.4 GiB]   0% Done                                    \rCopying file://bert_model/bert_model.ckpt.index [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/bert_model.ckpt.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "|\n",
            "Operation completed over 7 objects/1.4 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ChKoqD9b88S",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgZ3QCkILhPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TO DO\n",
        "#code to transfer latest checkpoint from another directory to new directory\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_7D763pTxup",
        "colab_type": "code",
        "outputId": "0c45f3a0-676a-4536-ac1f-afeab66f9591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "TRAIN_BATCH_SIZE = 128\n",
        "MAX_PREDICTIONS =20\n",
        "MAX_SEQ_LENGTH = 128\n",
        "MASKED_LM_PROB = 0.15\n",
        "\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 40000\n",
        "SAVE_CHECKPOINTS_STEPS = 5000\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "BERT_DRIVE_DIR = \"{}/{}\".format('/mydrive', MODEL_DIR)\n",
        "DATA_DRIVE_DIR = \"{}/{}\".format('/mydrive', PRETRAINING_DIR)\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}/original\".format(BUCKET_NAME)\n",
        "else:\n",
        "  print(\"bucket name not found\")\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "PATH_TO_CHECKPOINT = os.path.join(BERT_GCS_DIR, \"bert_model.ckpt\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "\n",
        "if INIT_CHECKPOINT == None:\n",
        "    print(\"no checkpoint found, loading the default\")\n",
        "    INIT_CHECKPOINT = PATH_TO_CHECKPOINT\n",
        "\n",
        "\n",
        "\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, \"bert_vocab.txt\")\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR, '*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no checkpoint found, loading the default\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-07-06 06:19:21,311 :     Using checkpoint: gs://ayushjain1144-bucket/original/bert_model/bert_model.ckpt\n",
            "I0706 06:19:21.311156 139673349842816 interactiveshell.py:2882] Using checkpoint: gs://ayushjain1144-bucket/original/bert_model/bert_model.ckpt\n",
            "2019-07-06 06:19:21,315 :     Using 2 data shards\n",
            "I0706 06:19:21.315163 139673349842816 interactiveshell.py:2882] Using 2 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gp5uvzo8Zxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Le2pTtUnTOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UHFAcggnTHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8CRUnlpV09M",
        "colab_type": "code",
        "outputId": "3fae1d0c-499d-4522-a105-11a5c63ddca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config = bert_config,\n",
        "    init_checkpoint= INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=TRAIN_STEPS,\n",
        "    num_warmup_steps=4000,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "            cluster=tpu_cluster_resolver,\n",
        "            model_dir=BERT_GCS_DIR,\n",
        "            save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "            tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "            num_shards=NUM_TPU_CORES,\n",
        "            per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "\n",
        "train_input_fn = input_fn_builder(\n",
        "    input_files=input_files,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "    is_training=True)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-06 06:19:35,883 :     Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f07f5b65950>) includes params argument, but params are not passed to Estimator.\n",
            "W0706 06:19:35.883007 139673349842816 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f07f5b65950>) includes params argument, but params are not passed to Estimator.\n",
            "2019-07-06 06:19:35,894 :     Using config: {'_model_dir': 'gs://ayushjain1144-bucket/original/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.36.27.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f07f4d15c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.36.27.50:8470', '_evaluation_master': 'grpc://10.36.27.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f07f4dc29b0>}\n",
            "I0706 06:19:35.894051 139673349842816 estimator.py:209] Using config: {'_model_dir': 'gs://ayushjain1144-bucket/original/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.36.27.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f07f4d15c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.36.27.50:8470', '_evaluation_master': 'grpc://10.36.27.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f07f4dc29b0>}\n",
            "2019-07-06 06:19:35,898 :     _TPUContext: eval_on_tpu True\n",
            "I0706 06:19:35.898747 139673349842816 tpu_context.py:209] _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOdgIx2aIcCa",
        "colab_type": "code",
        "outputId": "9f9f6a66-d560-4062-d4df-c6bb67f6c06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "estimator.train(input_fn=train_input_fn, max_steps = TRAIN_STEPS )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-06 06:19:44,140 :     Querying Tensorflow master (grpc://10.36.27.50:8470) for TPU system metadata.\n",
            "I0706 06:19:44.140820 139673349842816 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.36.27.50:8470) for TPU system metadata.\n",
            "2019-07-06 06:19:44,160 :     Found TPU system:\n",
            "I0706 06:19:44.160304 139673349842816 tpu_system_metadata.py:148] Found TPU system:\n",
            "2019-07-06 06:19:44,164 :     *** Num TPU Cores: 8\n",
            "I0706 06:19:44.164467 139673349842816 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "2019-07-06 06:19:44,169 :     *** Num TPU Workers: 1\n",
            "I0706 06:19:44.169316 139673349842816 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "2019-07-06 06:19:44,172 :     *** Num TPU Cores Per Worker: 8\n",
            "I0706 06:19:44.172520 139673349842816 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "2019-07-06 06:19:44,175 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12276970308501735927)\n",
            "I0706 06:19:44.175703 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12276970308501735927)\n",
            "2019-07-06 06:19:44,181 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6497238723278769162)\n",
            "I0706 06:19:44.181237 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6497238723278769162)\n",
            "2019-07-06 06:19:44,184 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2697924882231059433)\n",
            "I0706 06:19:44.184608 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2697924882231059433)\n",
            "2019-07-06 06:19:44,188 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4117353817363793738)\n",
            "I0706 06:19:44.188620 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4117353817363793738)\n",
            "2019-07-06 06:19:44,194 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12801983245153672352)\n",
            "I0706 06:19:44.194416 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12801983245153672352)\n",
            "2019-07-06 06:19:44,198 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10124182229662321415)\n",
            "I0706 06:19:44.198107 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10124182229662321415)\n",
            "2019-07-06 06:19:44,209 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 407839711398262129)\n",
            "I0706 06:19:44.209765 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 407839711398262129)\n",
            "2019-07-06 06:19:44,213 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9310969831530927325)\n",
            "I0706 06:19:44.213162 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9310969831530927325)\n",
            "2019-07-06 06:19:44,219 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1499463401210881270)\n",
            "I0706 06:19:44.219078 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1499463401210881270)\n",
            "2019-07-06 06:19:44,225 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13638787461194313835)\n",
            "I0706 06:19:44.225337 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 13638787461194313835)\n",
            "2019-07-06 06:19:44,228 :     *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12922938409322213245)\n",
            "I0706 06:19:44.228703 139673349842816 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12922938409322213245)\n",
            "2019-07-06 06:19:44,257 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0706 06:19:44.257219 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2019-07-06 06:19:44,288 :     Calling model_fn.\n",
            "I0706 06:19:44.288079 139673349842816 estimator.py:1145] Calling model_fn.\n",
            "2019-07-06 06:19:44,291 :     From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0706 06:19:44.291852 139673349842816 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2019-07-06 06:19:44,303 :     From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0706 06:19:44.303971 139673349842816 deprecation.py:323] From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2019-07-06 06:19:44,306 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0706 06:19:44.306832 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2019-07-06 06:19:44,367 :     From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0706 06:19:44.367333 139673349842816 deprecation.py:323] From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2019-07-06 06:19:44,372 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0706 06:19:44.372922 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2019-07-06 06:19:44,377 :     From /content/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0706 06:19:44.377989 139673349842816 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2019-07-06 06:19:44,399 :     From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0706 06:19:44.399355 139673349842816 deprecation.py:323] From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2019-07-06 06:19:44,721 :     From /content/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0706 06:19:44.721740 139673349842816 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "2019-07-06 06:19:44,724 :     *** Features ***\n",
            "I0706 06:19:44.724540 139673349842816 run_pretraining.py:117] *** Features ***\n",
            "2019-07-06 06:19:44,728 :       name = input_ids, shape = (16, 128)\n",
            "I0706 06:19:44.728120 139673349842816 run_pretraining.py:119]   name = input_ids, shape = (16, 128)\n",
            "2019-07-06 06:19:44,730 :       name = input_mask, shape = (16, 128)\n",
            "I0706 06:19:44.730896 139673349842816 run_pretraining.py:119]   name = input_mask, shape = (16, 128)\n",
            "2019-07-06 06:19:44,733 :       name = masked_lm_ids, shape = (16, 20)\n",
            "I0706 06:19:44.733064 139673349842816 run_pretraining.py:119]   name = masked_lm_ids, shape = (16, 20)\n",
            "2019-07-06 06:19:44,735 :       name = masked_lm_positions, shape = (16, 20)\n",
            "I0706 06:19:44.735215 139673349842816 run_pretraining.py:119]   name = masked_lm_positions, shape = (16, 20)\n",
            "2019-07-06 06:19:44,736 :       name = masked_lm_weights, shape = (16, 20)\n",
            "I0706 06:19:44.736908 139673349842816 run_pretraining.py:119]   name = masked_lm_weights, shape = (16, 20)\n",
            "2019-07-06 06:19:44,738 :       name = next_sentence_labels, shape = (16, 1)\n",
            "I0706 06:19:44.738560 139673349842816 run_pretraining.py:119]   name = next_sentence_labels, shape = (16, 1)\n",
            "2019-07-06 06:19:44,740 :       name = segment_ids, shape = (16, 128)\n",
            "I0706 06:19:44.740464 139673349842816 run_pretraining.py:119]   name = segment_ids, shape = (16, 128)\n",
            "2019-07-06 06:19:44,742 :     From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0706 06:19:44.742633 139673349842816 deprecation_wrapper.py:119] From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2019-07-06 06:19:44,749 :     From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0706 06:19:44.749536 139673349842816 deprecation_wrapper.py:119] From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2019-07-06 06:19:44,800 :     From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0706 06:19:44.800631 139673349842816 deprecation_wrapper.py:119] From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2019-07-06 06:19:44,872 :     From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0706 06:19:44.872766 139673349842816 deprecation.py:506] From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2019-07-06 06:19:44,902 :     From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0706 06:19:44.902958 139673349842816 deprecation.py:323] From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "2019-07-06 06:19:49,656 :     **** Trainable Variables ****\n",
            "I0706 06:19:49.656388 139673349842816 run_pretraining.py:167] **** Trainable Variables ****\n",
            "2019-07-06 06:19:49,658 :       name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.658595 139673349842816 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,665 :       name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.665810 139673349842816 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,672 :       name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.672290 139673349842816 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,677 :       name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.677754 139673349842816 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,681 :       name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.681767 139673349842816 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,686 :       name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.686093 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,690 :       name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.690408 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,693 :       name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.693862 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,696 :       name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.696854 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,699 :       name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.699766 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,702 :       name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.702542 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,705 :       name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.705232 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,707 :       name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.707550 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,709 :       name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.709828 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,712 :       name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.712406 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,714 :       name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.714722 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,717 :       name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.717533 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,719 :       name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.719859 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,722 :       name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.722532 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,724 :       name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.724912 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,727 :       name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.727290 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,729 :       name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.729923 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,732 :       name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.732296 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,735 :       name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.735071 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,737 :       name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.737435 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,740 :       name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.740091 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,742 :       name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.742475 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,745 :       name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.745126 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,747 :       name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.747467 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,750 :       name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.750207 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,752 :       name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.752691 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,755 :       name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.755010 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,757 :       name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.757663 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,759 :       name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.759959 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,762 :       name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.762741 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,765 :       name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.765115 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,767 :       name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.767844 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,770 :       name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.770229 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,772 :       name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.772804 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,775 :       name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.775160 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,777 :       name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.777781 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,780 :       name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.780235 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,782 :       name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.782560 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,785 :       name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.785247 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,787 :       name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.787593 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,789 :       name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.789870 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,792 :       name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.792569 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,795 :       name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.795276 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,797 :       name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.797604 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,800 :       name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.800411 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,802 :       name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.802829 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,806 :       name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.806112 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,808 :       name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.808715 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,811 :       name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.811078 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,813 :       name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.813724 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,816 :       name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.816058 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,818 :       name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.818715 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,821 :       name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.821026 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,823 :       name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.823775 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,826 :       name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.826310 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,828 :       name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.828884 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,831 :       name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.831310 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,833 :       name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.833947 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,836 :       name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.836319 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,838 :       name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.838826 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,841 :       name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.841662 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,844 :       name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.844160 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,846 :       name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.846865 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,849 :       name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.849327 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,851 :       name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.851958 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,854 :       name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.854332 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,856 :       name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.856662 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,859 :       name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.859474 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,861 :       name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.861826 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,864 :       name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.864893 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,867 :       name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.867207 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,870 :       name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.870080 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,872 :       name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.872715 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,874 :       name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.874833 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,877 :       name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.877161 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,880 :       name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.880245 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,883 :       name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.883378 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,885 :       name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.885150 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,887 :       name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.887925 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,890 :       name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.890084 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,892 :       name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.892849 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,895 :       name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.895424 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,898 :       name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.898567 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,901 :       name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.901163 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,904 :       name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.904456 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,906 :       name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.906802 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,909 :       name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.909822 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,912 :       name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.912721 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,915 :       name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.915453 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,917 :       name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.917723 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,920 :       name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.920454 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,922 :       name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.922878 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,925 :       name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.925245 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,927 :       name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.927938 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,930 :       name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.930285 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,932 :       name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.932932 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,935 :       name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.935307 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,937 :       name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.937484 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,940 :       name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.940334 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,942 :       name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.942602 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,945 :       name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.945645 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,947 :       name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.947943 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,950 :       name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.950547 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,952 :       name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.952841 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,955 :       name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.955159 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,957 :       name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.957774 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,960 :       name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.960659 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,963 :       name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.963399 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,965 :       name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.965733 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,968 :       name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.968398 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,970 :       name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.970099 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,972 :       name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.972211 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,974 :       name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.974632 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,976 :       name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.976928 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,980 :       name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.980535 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,983 :       name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.983582 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,986 :       name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.986711 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,989 :       name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.989756 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,992 :       name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.992869 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,996 :       name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.996373 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:49,999 :       name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:49.999304 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,001 :       name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.001726 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,004 :       name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.004956 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,007 :       name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.007374 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,010 :       name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.010825 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,013 :       name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.013642 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,016 :       name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.016598 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,019 :       name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.019895 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,023 :       name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.023196 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,026 :       name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.026016 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,028 :       name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.028689 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,031 :       name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.031281 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,034 :       name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.034480 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,037 :       name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.037920 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,040 :       name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.040735 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,043 :       name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.043608 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,046 :       name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.046419 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,049 :       name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.049312 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,052 :       name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.052364 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,054 :       name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.054793 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,057 :       name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.057587 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,060 :       name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.060024 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,063 :       name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.063767 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,066 :       name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.066917 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,069 :       name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.069697 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,073 :       name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.073010 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,075 :       name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.075380 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,078 :       name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.078358 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,081 :       name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.081054 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,084 :       name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.084767 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,087 :       name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.087596 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,091 :       name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.091368 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,094 :       name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.094235 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,098 :       name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.098111 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,100 :       name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.100713 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,104 :       name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.104596 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,107 :       name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.107678 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,110 :       name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.110450 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,113 :       name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.113558 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,116 :       name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.116699 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,119 :       name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.119770 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,123 :       name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.123886 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,127 :       name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.127303 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,131 :       name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.131623 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,134 :       name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.134766 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,137 :       name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.137712 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,142 :       name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.142243 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,145 :       name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.145376 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,148 :       name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.148905 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,153 :       name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.153238 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,156 :       name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.156425 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,159 :       name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.159487 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,164 :       name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.164011 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,167 :       name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.167495 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,170 :       name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.170510 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,175 :       name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.175322 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,178 :       name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.178474 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,181 :       name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.181971 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,186 :       name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.186204 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,189 :       name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.189372 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,192 :       name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.192292 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,195 :       name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.195770 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,199 :       name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.199790 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,202 :       name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.202483 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,206 :       name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.206263 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,209 :       name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.209954 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,213 :       name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.213571 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,217 :       name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.217772 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,221 :       name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.221021 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,223 :       name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.223430 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,226 :       name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.226571 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,229 :       name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.229619 139673349842816 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,233 :       name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.233759 139673349842816 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,236 :       name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.236554 139673349842816 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,239 :       name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.239529 139673349842816 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,242 :       name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.242596 139673349842816 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,245 :       name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.245666 139673349842816 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,248 :       name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.248703 139673349842816 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,252 :       name = cls/predictions/output_bias:0, shape = (30522,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.252634 139673349842816 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (30522,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,256 :       name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.256126 139673349842816 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,259 :       name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "I0706 06:19:50.259448 139673349842816 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "2019-07-06 06:19:50,262 :     From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0706 06:19:50.262854 139673349842816 deprecation_wrapper.py:119] From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2019-07-06 06:19:50,269 :     From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0706 06:19:50.269514 139673349842816 deprecation_wrapper.py:119] From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "2019-07-06 06:19:50,298 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0706 06:19:50.298318 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "2019-07-06 06:19:51,141 :     From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0706 06:19:51.141324 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-07-06 06:20:04,982 :     From /content/bert/run_pretraining.py:160: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0706 06:20:04.982302 139673349842816 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:160: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "2019-07-06 06:20:06,176 :     From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0706 06:20:06.176011 139673349842816 deprecation_wrapper.py:119] From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2019-07-06 06:20:07,197 :     Create CheckpointSaverHook.\n",
            "I0706 06:20:07.197918 139673349842816 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "2019-07-06 06:20:07,617 :     Done calling model_fn.\n",
            "I0706 06:20:07.617428 139673349842816 estimator.py:1147] Done calling model_fn.\n",
            "2019-07-06 06:20:10,435 :     TPU job name worker\n",
            "I0706 06:20:10.435234 139673349842816 tpu_estimator.py:499] TPU job name worker\n",
            "2019-07-06 06:20:12,624 :     Graph was finalized.\n",
            "I0706 06:20:12.624713 139673349842816 monitored_session.py:240] Graph was finalized.\n",
            "2019-07-06 06:20:23,322 :     Running local_init_op.\n",
            "I0706 06:20:23.322395 139673349842816 session_manager.py:500] Running local_init_op.\n",
            "2019-07-06 06:20:24,059 :     Done running local_init_op.\n",
            "I0706 06:20:24.059159 139673349842816 session_manager.py:502] Done running local_init_op.\n",
            "2019-07-06 06:20:35,070 :     Saving checkpoints for 0 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "I0706 06:20:35.070405 139673349842816 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "2019-07-06 06:20:56,693 :     From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0706 06:20:56.693013 139673349842816 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2019-07-06 06:20:58,310 :     Initialized dataset iterators in 0 seconds\n",
            "I0706 06:20:58.310101 139673349842816 util.py:98] Initialized dataset iterators in 0 seconds\n",
            "2019-07-06 06:20:58,313 :     Installing graceful shutdown hook.\n",
            "I0706 06:20:58.313483 139673349842816 session_support.py:332] Installing graceful shutdown hook.\n",
            "2019-07-06 06:20:58,324 :     Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "I0706 06:20:58.324784 139673349842816 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2019-07-06 06:20:58,333 :     Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "I0706 06:20:58.333997 139673349842816 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2019-07-06 06:20:58,341 :     Init TPU system\n",
            "I0706 06:20:58.341580 139673349842816 tpu_estimator.py:557] Init TPU system\n",
            "2019-07-06 06:21:05,786 :     Initialized TPU in 7 seconds\n",
            "I0706 06:21:05.786862 139673349842816 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
            "2019-07-06 06:21:05,792 :     Starting infeed thread controller.\n",
            "I0706 06:21:05.792346 139671893141248 tpu_estimator.py:514] Starting infeed thread controller.\n",
            "2019-07-06 06:21:05,799 :     Starting outfeed thread controller.\n",
            "I0706 06:21:05.799628 139671864305408 tpu_estimator.py:533] Starting outfeed thread controller.\n",
            "2019-07-06 06:21:06,561 :     Enqueue next (5000) batch(es) of data to infeed.\n",
            "I0706 06:21:06.561950 139673349842816 tpu_estimator.py:590] Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-07-06 06:21:06,564 :     Dequeue next (5000) batch(es) of data from outfeed.\n",
            "I0706 06:21:06.564928 139673349842816 tpu_estimator.py:594] Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-07-06 06:21:42,463 :     Outfeed finished for iteration (0, 0)\n",
            "I0706 06:21:42.463526 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
            "2019-07-06 06:22:42,563 :     Outfeed finished for iteration (0, 553)\n",
            "I0706 06:22:42.563594 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 553)\n",
            "2019-07-06 06:23:42,664 :     Outfeed finished for iteration (0, 1106)\n",
            "I0706 06:23:42.664582 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 1106)\n",
            "2019-07-06 06:24:42,764 :     Outfeed finished for iteration (0, 1659)\n",
            "I0706 06:24:42.764837 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 1659)\n",
            "2019-07-06 06:25:42,865 :     Outfeed finished for iteration (0, 2212)\n",
            "I0706 06:25:42.865422 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 2212)\n",
            "2019-07-06 06:26:42,965 :     Outfeed finished for iteration (0, 2765)\n",
            "I0706 06:26:42.965541 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 2765)\n",
            "2019-07-06 06:27:43,064 :     Outfeed finished for iteration (0, 3318)\n",
            "I0706 06:27:43.064615 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 3318)\n",
            "2019-07-06 06:28:43,165 :     Outfeed finished for iteration (0, 3871)\n",
            "I0706 06:28:43.165451 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 3871)\n",
            "2019-07-06 06:29:43,265 :     Outfeed finished for iteration (0, 4424)\n",
            "I0706 06:29:43.265866 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 4424)\n",
            "2019-07-06 06:30:43,367 :     Outfeed finished for iteration (0, 4977)\n",
            "I0706 06:30:43.367242 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (0, 4977)\n",
            "2019-07-06 06:30:46,539 :     Saving checkpoints for 5000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "I0706 06:30:46.539696 139673349842816 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "2019-07-06 06:31:11,022 :     loss = 3.6475508, step = 5000\n",
            "I0706 06:31:11.022217 139673349842816 basic_session_run_hooks.py:262] loss = 3.6475508, step = 5000\n",
            "2019-07-06 06:31:11,028 :     Enqueue next (5000) batch(es) of data to infeed.\n",
            "I0706 06:31:11.028600 139673349842816 tpu_estimator.py:590] Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-07-06 06:31:11,032 :     Dequeue next (5000) batch(es) of data from outfeed.\n",
            "I0706 06:31:11.032949 139673349842816 tpu_estimator.py:594] Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-07-06 06:31:43,453 :     Outfeed finished for iteration (1, 227)\n",
            "I0706 06:31:43.453875 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 227)\n",
            "2019-07-06 06:32:43,551 :     Outfeed finished for iteration (1, 780)\n",
            "I0706 06:32:43.551517 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 780)\n",
            "2019-07-06 06:33:43,648 :     Outfeed finished for iteration (1, 1333)\n",
            "I0706 06:33:43.648734 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 1333)\n",
            "2019-07-06 06:34:43,745 :     Outfeed finished for iteration (1, 1886)\n",
            "I0706 06:34:43.745715 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 1886)\n",
            "2019-07-06 06:35:43,844 :     Outfeed finished for iteration (1, 2439)\n",
            "I0706 06:35:43.844056 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 2439)\n",
            "2019-07-06 06:36:43,941 :     Outfeed finished for iteration (1, 2992)\n",
            "I0706 06:36:43.941655 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 2992)\n",
            "2019-07-06 06:37:44,039 :     Outfeed finished for iteration (1, 3545)\n",
            "I0706 06:37:44.039055 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 3545)\n",
            "2019-07-06 06:38:44,137 :     Outfeed finished for iteration (1, 4098)\n",
            "I0706 06:38:44.137401 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 4098)\n",
            "2019-07-06 06:39:44,235 :     Outfeed finished for iteration (1, 4651)\n",
            "I0706 06:39:44.235695 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (1, 4651)\n",
            "2019-07-06 06:40:22,841 :     Saving checkpoints for 10000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "I0706 06:40:22.841663 139673349842816 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "2019-07-06 06:40:41,710 :     loss = 2.9171262, step = 10000 (570.688 sec)\n",
            "I0706 06:40:41.710542 139673349842816 basic_session_run_hooks.py:260] loss = 2.9171262, step = 10000 (570.688 sec)\n",
            "2019-07-06 06:40:41,718 :     global_step/sec: 8.7613\n",
            "I0706 06:40:41.718674 139673349842816 tpu_estimator.py:2159] global_step/sec: 8.7613\n",
            "2019-07-06 06:40:41,725 :     examples/sec: 1121.45\n",
            "I0706 06:40:41.725775 139673349842816 tpu_estimator.py:2160] examples/sec: 1121.45\n",
            "2019-07-06 06:40:41,734 :     Enqueue next (5000) batch(es) of data to infeed.\n",
            "I0706 06:40:41.734118 139673349842816 tpu_estimator.py:590] Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-07-06 06:40:41,738 :     Dequeue next (5000) batch(es) of data from outfeed.\n",
            "I0706 06:40:41.738424 139673349842816 tpu_estimator.py:594] Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-07-06 06:40:44,320 :     Outfeed finished for iteration (2, 13)\n",
            "I0706 06:40:44.320789 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 13)\n",
            "2019-07-06 06:41:44,414 :     Outfeed finished for iteration (2, 566)\n",
            "I0706 06:41:44.414803 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 566)\n",
            "2019-07-06 06:42:44,510 :     Outfeed finished for iteration (2, 1119)\n",
            "I0706 06:42:44.510581 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 1119)\n",
            "2019-07-06 06:43:44,606 :     Outfeed finished for iteration (2, 1672)\n",
            "I0706 06:43:44.606738 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 1672)\n",
            "2019-07-06 06:44:44,702 :     Outfeed finished for iteration (2, 2225)\n",
            "I0706 06:44:44.702368 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 2225)\n",
            "2019-07-06 06:45:44,798 :     Outfeed finished for iteration (2, 2778)\n",
            "I0706 06:45:44.798706 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 2778)\n",
            "2019-07-06 06:46:44,894 :     Outfeed finished for iteration (2, 3331)\n",
            "I0706 06:46:44.894080 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 3331)\n",
            "2019-07-06 06:47:44,988 :     Outfeed finished for iteration (2, 3884)\n",
            "I0706 06:47:44.988929 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 3884)\n",
            "2019-07-06 06:48:45,085 :     Outfeed finished for iteration (2, 4437)\n",
            "I0706 06:48:45.085132 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 4437)\n",
            "2019-07-06 06:49:45,180 :     Outfeed finished for iteration (2, 4990)\n",
            "I0706 06:49:45.180627 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (2, 4990)\n",
            "2019-07-06 06:49:46,889 :     Saving checkpoints for 15000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "I0706 06:49:46.889471 139673349842816 basic_session_run_hooks.py:606] Saving checkpoints for 15000 into gs://ayushjain1144-bucket/original/bert_model/model.ckpt.\n",
            "2019-07-06 06:50:09,223 :     loss = 2.5706418, step = 15000 (567.513 sec)\n",
            "I0706 06:50:09.223919 139673349842816 basic_session_run_hooks.py:260] loss = 2.5706418, step = 15000 (567.513 sec)\n",
            "2019-07-06 06:50:09,234 :     global_step/sec: 8.81034\n",
            "I0706 06:50:09.234147 139673349842816 tpu_estimator.py:2159] global_step/sec: 8.81034\n",
            "2019-07-06 06:50:09,239 :     examples/sec: 1127.72\n",
            "I0706 06:50:09.239804 139673349842816 tpu_estimator.py:2160] examples/sec: 1127.72\n",
            "2019-07-06 06:50:09,243 :     Enqueue next (5000) batch(es) of data to infeed.\n",
            "I0706 06:50:09.243302 139673349842816 tpu_estimator.py:590] Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-07-06 06:50:09,247 :     Dequeue next (5000) batch(es) of data from outfeed.\n",
            "I0706 06:50:09.247624 139673349842816 tpu_estimator.py:594] Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-07-06 06:50:45,273 :     Outfeed finished for iteration (3, 319)\n",
            "I0706 06:50:45.273305 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 319)\n",
            "2019-07-06 06:51:45,374 :     Outfeed finished for iteration (3, 872)\n",
            "I0706 06:51:45.374925 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 872)\n",
            "2019-07-06 06:52:45,475 :     Outfeed finished for iteration (3, 1425)\n",
            "I0706 06:52:45.475901 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 1425)\n",
            "2019-07-06 06:53:45,577 :     Outfeed finished for iteration (3, 1978)\n",
            "I0706 06:53:45.577740 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 1978)\n",
            "2019-07-06 06:54:45,679 :     Outfeed finished for iteration (3, 2531)\n",
            "I0706 06:54:45.679129 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 2531)\n",
            "2019-07-06 06:55:45,780 :     Outfeed finished for iteration (3, 3084)\n",
            "I0706 06:55:45.780767 139671864305408 tpu_estimator.py:275] Outfeed finished for iteration (3, 3084)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlrGT700d2p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZj4zT6qiyl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}