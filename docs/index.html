<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>NukeBERT: A Pre-trained language model for Low Resource Nuclear Domain</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
</head>

<body>

<br/>
<br/>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:850px">
  
    <h2 align="center" id="title"><b>NukeBERT: A Pre-trained language model for Low Resource Nuclear Domain</b></h2>
    <br/>
    <p align="center" class="center_text" id="authors">
        <a target="_blank" href="https://ayushjain1144.github.io/">Ayush Jain</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://scholar.google.com/citations?user=milH1wkAAAAJ&hl=en">N.M. Meenachi</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://scholar.google.co.in/citations?hl=en&user=irW1vCgAAAAJ&view_op=list_works&sortby=pubdate">B. Venkatraman</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;

        
    </p>

    <p class="center_text" align="center">
        <sup>1</sup>Bits Pilani
        &nbsp; &nbsp; &nbsp;
        <sup>2</sup>Indira Gandhi Center for Atomic Research
    </p>

    <!-- <p align="center" id="title">Submitted for review</p> -->

    <br>
        <!-- <p align="center" id="title"><b>Submit to our ScanRefer Localization Benchmark <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/">here</a>!</b></p> -->

        <br><center><a href="https://github.com/ayushjain1144"><img src="teaser.png" style="max-width:100%" /></a></center><br>
        
        <h3 class="w3-left-align" id="video"><b>Introduction</b></h3>
        <p>
            Significant advances have been made in recent years on Natural Language Processing with machines surpassing human performance in many tasks, including but not limited to Question Answering. The majority of deep learning methods for Question Answering targets domains with large datasets and highly matured literature. The area of Nuclear and Atomic energy has largely remained unexplored in exploiting available unannotated data for driving industry viable applications. To tackle this issue of lack of quality dataset, this paper intriduces two datasets: NText, a eight million words dataset extracted and preprocessed from nuclear research papers and thesis; and NQuAD, a Nuclear Question Answering Dataset, which contains 700+ nuclear Question Answer pairs developed and verified by expert nuclear researchers. This paper further propose a data efficient technique based on BERT, which improves performance significantly as compared to original BERT baseline on above datasets. Both the datasets, code and pretrained weights will be made publically available, which would hopefully attract more research attraction towards the nuclear domain. 
        </p>

       <!--  <h3 class="w3-left-align" id="video"><b>Video</b></h3>
        <iframe width="850" height="480" src="https://www.youtube.com/embed/T9J5t-UEcNA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

        <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
        Under Review. <br/>
        <a href="https://arxiv.org/abs/2003.13821">arXiv</a> | <a href="https://github.com/ayushjain1144/NukeBERT">Code</a>
        <center>
            <a href="https://github.com/ayushjain1144"><img src="paper.jpg" style="max-width:100%" /></a>
        </center><br>

        If you find our project useful, please consider citing us:
        <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">

@misc{jain2020nukebert,
    title={NukeBERT: A Pre-trained language model for Low Resource Nuclear Domain},
    author={Ayush Jain and Dr. N. M. Meenachi and Dr. B. Venkatraman},
    year={2020},
    eprint={2003.13821},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
    <!-- eprint={6666.6666}, -->
    <!-- archivePrefix={arXiv}, -->
    <!-- primaryClass={cs.CV} -->
<!-- } -->

</pre>

        <h3 class="w3-left-align" id="dataset"><b>Questions</b></h3>

        If you have some questions feel free to <a href="mailto: ayushjain1144@gmail.com">email</a>. We will be happy to help!

    </div>


</div>

<br/>
<br/>

</body>
</html>